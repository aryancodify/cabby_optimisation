{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "11.0\n",
      "0.0\n",
      "3.0542857142857143\n",
      "7.93705306122449\n"
     ]
    }
   ],
   "source": [
    "print(type(Time_matrix))\n",
    "print(Time_matrix.max())\n",
    "print(Time_matrix.min())\n",
    "print(Time_matrix.mean())\n",
    "print(Time_matrix.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "States_track = collections.defaultdict(dict)\n",
    "Q_dict = collections.defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_state(state):\n",
    "    return '-'.join(str(e) for e in state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise states to be tracked\n",
    "def initialise_tracking_states():\n",
    "    sample_q_values = [([1,2,3],(1,3)),([3,5,6],(4,2)),([4,10,2],(3,4)), ([2,7,0],(0,4))]    #select any 4 Q-values\n",
    "    for q_values in sample_q_values:\n",
    "        state = Q_state(q_values[0])\n",
    "        action = q_values[1]\n",
    "        States_track[state][action] = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tracking_states_old():\n",
    "    \"\"\"Saves the states to dictionary\"\"\"\n",
    "    for state in States_track.keys():\n",
    "        for action in States_track[state].keys():\n",
    "            if state in Q_dict and action in Q_dict[state]:\n",
    "                States_track[state][action].append(Q_dict[state][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialise_tracking_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {'1-2-3': {(1, 3): []}, '3-5-6': {(4, 2): []}, '4-10-2': {(3, 4): []}, '2-7-0': {(0, 4): []}})\n"
     ]
    }
   ],
   "source": [
    "print(States_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_track = 0\n",
    "num_train = 0\n",
    "num_track_train = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.06 # 0.06 after fix gave nothing\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_max = 1\n",
    "        #self.epsilon_decay = -0.003 #for 1k\n",
    "        self.epsilon_decay = -0.0007 #for 3k\n",
    "        #self.epsilon_decay = -0.0003 #for 10k\n",
    "        #self.epsilon_decay = -0.0001 #for 20k\n",
    "        #self.epsilon_decay = -0.00003 #for 100k\n",
    "        #self.epsilon_decay = -0.000003 #for 1M\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        self.batch_size = 32      # for 24*1\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.states_tracked = []\n",
    "        #track_input = np.zeros((1, self.state_size))\n",
    "        #track_input[0] = env.state_encod_arch1([0,0,0]).reshape(1,36)\n",
    "        #self.track_state = track_input[0]\n",
    "        self.track_state = np.array(env.state_encod_arch1([0,0,0])).reshape(1, 36)\n",
    "        #print(\"TRACK STATE\")\n",
    "        #print(self.track_state)\n",
    "        self.explore = 0\n",
    "        self.exploit = 0\n",
    "        self.num_track = 0\n",
    "        self.num_train = 0\n",
    "        self.num_train_track = 0\n",
    "        self.hit = False\n",
    "        self.hit_index = 0\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        input_shape = self.state_size\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state):\n",
    "        action_indices, action_list = env.requests(state)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            self.explore += 1\n",
    "            action_list_index = random.randrange(len(action_indices))\n",
    "            action_space_index = action_indices[action_list_index]\n",
    "        else:\n",
    "            self.exploit += 1\n",
    "            state = np.array(env.state_encod_arch1(state)).reshape(1, 36)\n",
    "            q_value = self.model.predict(state)\n",
    "            q_value =[q_value[0][i] for i in action_indices]\n",
    "            action_list_index = np.argmax(q_value)\n",
    "            action_space_index = action_indices[action_list_index]\n",
    "        return action_space_index, action_list[action_list_index]\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in Îµ after we generate each sample from the environment\n",
    "\n",
    "    def append_sample(self, state, action_index, reward, next_state, done):\n",
    "        self.memory.append((state, action_index, reward, next_state, done))\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    \n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            self.num_train += 1\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            # initialise two matrices - update_input and update_output\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            actions, rewards, done = [], [], []\n",
    "\n",
    "            # populate update_input and update_output and the lists rewards, actions, done\n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, done_boolean = mini_batch[i]\n",
    "                update_input[i] = env.state_encod_arch1(state)     \n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = env.state_encod_arch1(next_state)\n",
    "                done.append(done_boolean)\n",
    "\n",
    "            # predict the target q-values from states s\n",
    "            target = self.model.predict(update_input)\n",
    "            # target for q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "\n",
    "\n",
    "            # update the target values\n",
    "            for i in range(self.batch_size):\n",
    "                if done[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "            # model fit\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "    def save_tracking_states(self):\n",
    "        self.num_track += 1\n",
    "        q_value = self.model.predict(self.track_state)\n",
    "        self.states_tracked.append(q_value[0][2])\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    \n",
    "\n",
    "    #Call the DQN agent\n",
    "    \n",
    "    \n",
    "    while !terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 36\n",
    "action_size = 21\n",
    "episode_time = 24*30\n",
    "#n_episodes = 1\n",
    "n_episodes = 3000\n",
    "m = 5\n",
    "t = 24\n",
    "d = 7\n",
    "num_track = 0\n",
    "num_train = 0\n",
    "num_track_train = 0\n",
    "env = CabDriver()\n",
    "agent = DQNAgent(action_size=action_size, state_size=state_size)\n",
    "\n",
    "\n",
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, reward 129.0, memory_length 137, epsilon 0.99999 total_time 723.0 step_num 137\n",
      "episode 1, reward -185.0, memory_length 277, epsilon 0.9992902519403939 total_time 730.0 step_num 140\n",
      "episode 2, reward -49.0, memory_length 428, epsilon 0.9985909935330313 total_time 728.0 step_num 151\n",
      "episode 3, reward -331.0, memory_length 564, epsilon 0.9978922244352755 total_time 725.0 step_num 136\n",
      "episode 4, reward -86.0, memory_length 700, epsilon 0.9971939443047295 total_time 721.0 step_num 136\n",
      "episode 5, reward 110.0, memory_length 847, epsilon 0.9964961527992363 total_time 725.0 step_num 147\n",
      "episode 6, reward -313.0, memory_length 978, epsilon 0.9957988495768779 total_time 725.0 step_num 131\n",
      "episode 7, reward -320.0, memory_length 1120, epsilon 0.9951020342959757 total_time 721.0 step_num 142\n",
      "episode 8, reward -286.0, memory_length 1254, epsilon 0.9944057066150902 total_time 725.0 step_num 134\n",
      "episode 9, reward -172.0, memory_length 1389, epsilon 0.9937098661930208 total_time 722.0 step_num 135\n",
      "episode 10, reward 7.0, memory_length 1543, epsilon 0.9930145126888058 total_time 724.0 step_num 154\n",
      "episode 11, reward -122.0, memory_length 1700, epsilon 0.9923196457617219 total_time 730.0 step_num 157\n",
      "episode 12, reward 159.0, memory_length 1834, epsilon 0.9916252650712842 total_time 726.0 step_num 134\n",
      "episode 13, reward -302.0, memory_length 1970, epsilon 0.9909313702772462 total_time 721.0 step_num 136\n",
      "episode 14, reward -95.0, memory_length 2000, epsilon 0.9902379610395996 total_time 721.0 step_num 142\n",
      "episode 15, reward 110.0, memory_length 2000, epsilon 0.9895450370185737 total_time 725.0 step_num 138\n",
      "episode 16, reward -127.0, memory_length 2000, epsilon 0.9888525978746355 total_time 722.0 step_num 136\n",
      "episode 17, reward -199.0, memory_length 2000, epsilon 0.9881606432684903 total_time 722.0 step_num 155\n",
      "episode 18, reward -194.0, memory_length 2000, epsilon 0.98746917286108 total_time 721.0 step_num 141\n",
      "episode 19, reward -65.0, memory_length 2000, epsilon 0.9867781863135842 total_time 724.0 step_num 137\n",
      "episode 20, reward -204.0, memory_length 2000, epsilon 0.9860876832874194 total_time 723.0 step_num 139\n",
      "episode 21, reward -293.0, memory_length 2000, epsilon 0.9853976634442391 total_time 721.0 step_num 118\n",
      "episode 22, reward -205.0, memory_length 2000, epsilon 0.9847081264459336 total_time 725.0 step_num 135\n",
      "episode 23, reward -158.0, memory_length 2000, epsilon 0.9840190719546298 total_time 721.0 step_num 137\n",
      "episode 24, reward -505.0, memory_length 2000, epsilon 0.9833304996326909 total_time 731.0 step_num 151\n",
      "episode 25, reward -38.0, memory_length 2000, epsilon 0.9826424091427166 total_time 724.0 step_num 142\n",
      "episode 26, reward -102.0, memory_length 2000, epsilon 0.9819548001475423 total_time 726.0 step_num 139\n",
      "episode 27, reward 156.0, memory_length 2000, epsilon 0.9812676723102398 total_time 723.0 step_num 148\n",
      "episode 28, reward 13.0, memory_length 2000, epsilon 0.9805810252941164 total_time 721.0 step_num 141\n",
      "episode 29, reward -308.0, memory_length 2000, epsilon 0.979894858762715 total_time 724.0 step_num 133\n",
      "episode 30, reward 58.0, memory_length 2000, epsilon 0.9792091723798139 total_time 721.0 step_num 138\n",
      "episode 31, reward -595.0, memory_length 2000, epsilon 0.978523965809427 total_time 731.0 step_num 155\n",
      "episode 32, reward -5.0, memory_length 2000, epsilon 0.9778392387158028 total_time 721.0 step_num 140\n",
      "episode 33, reward -113.0, memory_length 2000, epsilon 0.9771549907634253 total_time 721.0 step_num 170\n",
      "episode 34, reward -208.0, memory_length 2000, epsilon 0.9764712216170126 total_time 722.0 step_num 131\n",
      "episode 35, reward -191.0, memory_length 2000, epsilon 0.9757879309415182 total_time 724.0 step_num 138\n",
      "episode 36, reward -149.0, memory_length 2000, epsilon 0.9751051184021294 total_time 721.0 step_num 129\n",
      "episode 37, reward 35.0, memory_length 2000, epsilon 0.9744227836642682 total_time 722.0 step_num 120\n",
      "episode 38, reward -32.0, memory_length 2000, epsilon 0.9737409263935904 total_time 721.0 step_num 132\n",
      "episode 39, reward -73.0, memory_length 2000, epsilon 0.9730595462559861 total_time 722.0 step_num 129\n",
      "episode 40, reward 275.0, memory_length 2000, epsilon 0.9723786429175789 total_time 728.0 step_num 131\n",
      "episode 41, reward -203.0, memory_length 2000, epsilon 0.9716982160447263 total_time 721.0 step_num 125\n",
      "episode 42, reward 94.0, memory_length 2000, epsilon 0.9710182653040188 total_time 721.0 step_num 149\n",
      "episode 43, reward -359.0, memory_length 2000, epsilon 0.9703387903622808 total_time 727.0 step_num 144\n",
      "episode 44, reward -29.0, memory_length 2000, epsilon 0.9696597908865696 total_time 733.0 step_num 131\n",
      "episode 45, reward -271.0, memory_length 2000, epsilon 0.9689812665441752 total_time 722.0 step_num 138\n",
      "episode 46, reward 132.0, memory_length 2000, epsilon 0.9683032170026208 total_time 726.0 step_num 145\n",
      "episode 47, reward 1.0, memory_length 2000, epsilon 0.9676256419296622 total_time 727.0 step_num 152\n",
      "episode 48, reward -223.0, memory_length 2000, epsilon 0.9669485409932874 total_time 725.0 step_num 140\n",
      "episode 49, reward -419.0, memory_length 2000, epsilon 0.9662719138617171 total_time 721.0 step_num 129\n",
      "episode 50, reward -90.0, memory_length 2000, epsilon 0.965595760203404 total_time 729.0 step_num 136\n",
      "episode 51, reward -68.0, memory_length 2000, epsilon 0.9649200796870326 total_time 721.0 step_num 141\n",
      "episode 52, reward -22.0, memory_length 2000, epsilon 0.9642448719815195 total_time 728.0 step_num 146\n",
      "episode 53, reward -757.0, memory_length 2000, epsilon 0.9635701367560131 total_time 722.0 step_num 125\n",
      "episode 54, reward -78.0, memory_length 2000, epsilon 0.9628958736798929 total_time 723.0 step_num 135\n",
      "episode 55, reward 78.0, memory_length 2000, epsilon 0.9622220824227702 total_time 726.0 step_num 113\n",
      "episode 56, reward -173.0, memory_length 2000, epsilon 0.9615487626544871 total_time 724.0 step_num 150\n",
      "episode 57, reward -149.0, memory_length 2000, epsilon 0.9608759140451169 total_time 721.0 step_num 135\n",
      "episode 58, reward -164.0, memory_length 2000, epsilon 0.9602035362649637 total_time 724.0 step_num 137\n",
      "episode 59, reward 121.0, memory_length 2000, epsilon 0.9595316289845627 total_time 730.0 step_num 149\n",
      "episode 60, reward -70.0, memory_length 2000, epsilon 0.9588601918746789 total_time 725.0 step_num 134\n",
      "episode 61, reward -68.0, memory_length 2000, epsilon 0.9581892246063084 total_time 730.0 step_num 147\n",
      "episode 62, reward 36.0, memory_length 2000, epsilon 0.9575187268506771 total_time 729.0 step_num 137\n",
      "episode 63, reward -248.0, memory_length 2000, epsilon 0.9568486982792411 total_time 730.0 step_num 139\n",
      "episode 64, reward -150.0, memory_length 2000, epsilon 0.9561791385636864 total_time 723.0 step_num 127\n",
      "episode 65, reward 134.0, memory_length 2000, epsilon 0.9555100473759288 total_time 722.0 step_num 146\n",
      "episode 66, reward -257.0, memory_length 2000, epsilon 0.9548414243881135 total_time 721.0 step_num 139\n",
      "episode 67, reward -30.0, memory_length 2000, epsilon 0.9541732692726153 total_time 726.0 step_num 142\n",
      "episode 68, reward -103.0, memory_length 2000, epsilon 0.9535055817020379 total_time 728.0 step_num 143\n",
      "episode 69, reward -68.0, memory_length 2000, epsilon 0.9528383613492148 total_time 721.0 step_num 155\n",
      "episode 70, reward -120.0, memory_length 2000, epsilon 0.9521716078872079 total_time 735.0 step_num 148\n",
      "episode 71, reward -119.0, memory_length 2000, epsilon 0.9515053209893078 total_time 724.0 step_num 132\n",
      "episode 72, reward 188.0, memory_length 2000, epsilon 0.9508395003290341 total_time 722.0 step_num 125\n",
      "episode 73, reward 30.0, memory_length 2000, epsilon 0.9501741455801346 total_time 723.0 step_num 116\n",
      "episode 74, reward -248.0, memory_length 2000, epsilon 0.9495092564165853 total_time 721.0 step_num 158\n",
      "episode 75, reward -301.0, memory_length 2000, epsilon 0.9488448325125908 total_time 728.0 step_num 147\n",
      "episode 76, reward -84.0, memory_length 2000, epsilon 0.9481808735425831 total_time 726.0 step_num 141\n",
      "episode 77, reward 129.0, memory_length 2000, epsilon 0.9475173791812225 total_time 723.0 step_num 158\n",
      "episode 78, reward -302.0, memory_length 2000, epsilon 0.9468543491033965 total_time 721.0 step_num 140\n",
      "episode 79, reward -437.0, memory_length 2000, epsilon 0.9461917829842207 total_time 721.0 step_num 130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 80, reward -229.0, memory_length 2000, epsilon 0.9455296804990374 total_time 728.0 step_num 133\n",
      "episode 81, reward -54.0, memory_length 2000, epsilon 0.9448680413234165 total_time 729.0 step_num 114\n",
      "episode 82, reward -186.0, memory_length 2000, epsilon 0.9442068651331547 total_time 723.0 step_num 127\n",
      "episode 83, reward -365.0, memory_length 2000, epsilon 0.9435461516042758 total_time 721.0 step_num 140\n",
      "episode 84, reward -118.0, memory_length 2000, epsilon 0.94288590041303 total_time 722.0 step_num 145\n",
      "episode 85, reward -99.0, memory_length 2000, epsilon 0.9422261112358943 total_time 738.0 step_num 170\n",
      "episode 86, reward 238.0, memory_length 2000, epsilon 0.9415667837495718 total_time 721.0 step_num 121\n",
      "episode 87, reward -231.0, memory_length 2000, epsilon 0.9409079176309924 total_time 732.0 step_num 151\n",
      "episode 88, reward -23.0, memory_length 2000, epsilon 0.9402495125573114 total_time 721.0 step_num 136\n",
      "episode 89, reward -345.0, memory_length 2000, epsilon 0.9395915682059103 total_time 726.0 step_num 133\n",
      "episode 90, reward 121.0, memory_length 2000, epsilon 0.9389340842543964 total_time 721.0 step_num 136\n",
      "episode 91, reward -279.0, memory_length 2000, epsilon 0.9382770603806027 total_time 729.0 step_num 145\n",
      "episode 92, reward -172.0, memory_length 2000, epsilon 0.9376204962625873 total_time 722.0 step_num 143\n",
      "episode 93, reward -140.0, memory_length 2000, epsilon 0.9369643915786338 total_time 721.0 step_num 124\n",
      "episode 94, reward -100.0, memory_length 2000, epsilon 0.9363087460072509 total_time 722.0 step_num 132\n",
      "episode 95, reward 83.0, memory_length 2000, epsilon 0.9356535592271722 total_time 725.0 step_num 140\n",
      "episode 96, reward -266.0, memory_length 2000, epsilon 0.9349988309173565 total_time 721.0 step_num 132\n",
      "episode 97, reward -237.0, memory_length 2000, epsilon 0.9343445607569865 total_time 726.0 step_num 141\n",
      "episode 98, reward -352.0, memory_length 2000, epsilon 0.9336907484254698 total_time 722.0 step_num 135\n",
      "episode 99, reward -104.0, memory_length 2000, epsilon 0.9330373936024389 total_time 721.0 step_num 135\n",
      "episode 100, reward -660.0, memory_length 2000, epsilon 0.9323844959677493 total_time 726.0 step_num 144\n",
      "episode 101, reward -13.0, memory_length 2000, epsilon 0.9317320552014813 total_time 728.0 step_num 143\n",
      "episode 102, reward 76.0, memory_length 2000, epsilon 0.9310800709839391 total_time 721.0 step_num 146\n",
      "episode 103, reward -221.0, memory_length 2000, epsilon 0.9304285429956504 total_time 721.0 step_num 154\n",
      "episode 104, reward -25.0, memory_length 2000, epsilon 0.9297774709173662 total_time 725.0 step_num 135\n",
      "episode 105, reward -154.0, memory_length 2000, epsilon 0.9291268544300614 total_time 722.0 step_num 145\n",
      "episode 106, reward -25.0, memory_length 2000, epsilon 0.928476693214934 total_time 725.0 step_num 137\n",
      "episode 107, reward 130.0, memory_length 2000, epsilon 0.9278269869534047 total_time 721.0 step_num 128\n",
      "episode 108, reward -203.0, memory_length 2000, epsilon 0.9271777353271176 total_time 721.0 step_num 158\n",
      "episode 109, reward 94.0, memory_length 2000, epsilon 0.9265289380179395 total_time 730.0 step_num 127\n",
      "episode 110, reward -347.0, memory_length 2000, epsilon 0.9258805947079594 total_time 730.0 step_num 147\n",
      "episode 111, reward -231.0, memory_length 2000, epsilon 0.9252327050794893 total_time 723.0 step_num 139\n",
      "episode 112, reward -29.0, memory_length 2000, epsilon 0.9245852688150632 total_time 724.0 step_num 147\n",
      "episode 113, reward 24.0, memory_length 2000, epsilon 0.9239382855974373 total_time 726.0 step_num 138\n",
      "episode 114, reward -136.0, memory_length 2000, epsilon 0.9232917551095897 total_time 722.0 step_num 131\n",
      "episode 115, reward 151.0, memory_length 2000, epsilon 0.9226456770347208 total_time 724.0 step_num 135\n",
      "episode 116, reward -331.0, memory_length 2000, epsilon 0.922000051056252 total_time 725.0 step_num 136\n",
      "episode 117, reward -338.0, memory_length 2000, epsilon 0.9213548768578267 total_time 721.0 step_num 141\n",
      "episode 118, reward -51.0, memory_length 2000, epsilon 0.9207101541233095 total_time 723.0 step_num 139\n",
      "episode 119, reward -118.0, memory_length 2000, epsilon 0.9200658825367861 total_time 722.0 step_num 120\n",
      "episode 120, reward -259.0, memory_length 2000, epsilon 0.9194220617825638 total_time 725.0 step_num 151\n",
      "episode 121, reward -297.0, memory_length 2000, epsilon 0.91877869154517 total_time 729.0 step_num 129\n",
      "episode 122, reward -277.0, memory_length 2000, epsilon 0.9181357715093534 total_time 725.0 step_num 132\n",
      "episode 123, reward -28.0, memory_length 2000, epsilon 0.9174933013600833 total_time 731.0 step_num 134\n",
      "episode 124, reward -506.0, memory_length 2000, epsilon 0.9168512807825493 total_time 733.0 step_num 122\n",
      "episode 125, reward -317.0, memory_length 2000, epsilon 0.9162097094621612 total_time 733.0 step_num 157\n",
      "episode 126, reward -279.0, memory_length 2000, epsilon 0.915568587084549 total_time 729.0 step_num 133\n",
      "episode 127, reward 56.0, memory_length 2000, epsilon 0.9149279133355628 total_time 725.0 step_num 158\n",
      "episode 128, reward -181.0, memory_length 2000, epsilon 0.9142876879012724 total_time 722.0 step_num 130\n",
      "episode 129, reward -175.0, memory_length 2000, epsilon 0.9136479104679675 total_time 728.0 step_num 135\n",
      "episode 130, reward -42.0, memory_length 2000, epsilon 0.9130085807221568 total_time 723.0 step_num 130\n",
      "episode 131, reward -126.0, memory_length 2000, epsilon 0.912369698350569 total_time 729.0 step_num 126\n",
      "episode 132, reward -108.0, memory_length 2000, epsilon 0.9117312630401518 total_time 729.0 step_num 131\n",
      "episode 133, reward 29.0, memory_length 2000, epsilon 0.9110932744780716 total_time 725.0 step_num 145\n",
      "episode 134, reward -360.0, memory_length 2000, epsilon 0.9104557323517141 total_time 729.0 step_num 123\n",
      "episode 135, reward -97.0, memory_length 2000, epsilon 0.9098186363486838 total_time 725.0 step_num 121\n",
      "episode 136, reward 2.0, memory_length 2000, epsilon 0.9091819861568033 total_time 725.0 step_num 134\n",
      "episode 137, reward -208.0, memory_length 2000, epsilon 0.9085457814641145 total_time 722.0 step_num 117\n",
      "episode 138, reward -68.0, memory_length 2000, epsilon 0.9079100219588766 total_time 721.0 step_num 134\n",
      "episode 139, reward -31.0, memory_length 2000, epsilon 0.9072747073295676 total_time 728.0 step_num 136\n",
      "episode 140, reward -123.0, memory_length 2000, epsilon 0.9066398372648834 total_time 723.0 step_num 130\n",
      "episode 141, reward 62.0, memory_length 2000, epsilon 0.9060054114537377 total_time 722.0 step_num 136\n",
      "episode 142, reward -94.0, memory_length 2000, epsilon 0.9053714295852616 total_time 728.0 step_num 126\n",
      "episode 143, reward -156.0, memory_length 2000, epsilon 0.9047378913488041 total_time 726.0 step_num 163\n",
      "episode 144, reward -5.0, memory_length 2000, epsilon 0.9041047964339316 total_time 730.0 step_num 126\n",
      "episode 145, reward -61.0, memory_length 2000, epsilon 0.9034721445304273 total_time 725.0 step_num 146\n",
      "episode 146, reward -176.0, memory_length 2000, epsilon 0.902839935328292 total_time 721.0 step_num 142\n",
      "episode 147, reward -104.0, memory_length 2000, epsilon 0.902208168517743 total_time 721.0 step_num 143\n",
      "episode 148, reward -162.0, memory_length 2000, epsilon 0.9015768437892147 total_time 729.0 step_num 138\n",
      "episode 149, reward -205.0, memory_length 2000, epsilon 0.9009459608333578 total_time 734.0 step_num 134\n",
      "episode 150, reward -99.0, memory_length 2000, epsilon 0.9003155193410398 total_time 729.0 step_num 120\n",
      "episode 151, reward -14.0, memory_length 2000, epsilon 0.8996855190033443 total_time 721.0 step_num 136\n",
      "episode 152, reward -140.0, memory_length 2000, epsilon 0.8990559595115711 total_time 730.0 step_num 119\n",
      "episode 153, reward -148.0, memory_length 2000, epsilon 0.898426840557236 total_time 728.0 step_num 133\n",
      "episode 154, reward -335.0, memory_length 2000, epsilon 0.8977981618320708 total_time 724.0 step_num 119\n",
      "episode 155, reward -122.0, memory_length 2000, epsilon 0.8971699230280229 total_time 721.0 step_num 128\n",
      "episode 156, reward -518.0, memory_length 2000, epsilon 0.8965421238372551 total_time 721.0 step_num 142\n",
      "episode 157, reward -263.0, memory_length 2000, epsilon 0.895914763952146 total_time 724.0 step_num 134\n",
      "episode 158, reward -190.0, memory_length 2000, epsilon 0.8952878430652892 total_time 722.0 step_num 146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 159, reward -484.0, memory_length 2000, epsilon 0.8946613608694933 total_time 725.0 step_num 136\n",
      "episode 160, reward 94.0, memory_length 2000, epsilon 0.8940353170577823 total_time 730.0 step_num 148\n",
      "episode 161, reward -64.0, memory_length 2000, epsilon 0.8934097113233944 total_time 722.0 step_num 129\n",
      "episode 162, reward 97.0, memory_length 2000, epsilon 0.8927845433597831 total_time 724.0 step_num 150\n",
      "episode 163, reward 82.0, memory_length 2000, epsilon 0.8921598128606157 total_time 736.0 step_num 130\n",
      "episode 164, reward -93.0, memory_length 2000, epsilon 0.8915355195197746 total_time 726.0 step_num 126\n",
      "episode 165, reward -239.0, memory_length 2000, epsilon 0.8909116630313557 total_time 721.0 step_num 122\n",
      "episode 166, reward -108.0, memory_length 2000, epsilon 0.8902882430896697 total_time 729.0 step_num 135\n",
      "episode 167, reward 197.0, memory_length 2000, epsilon 0.8896652593892407 total_time 722.0 step_num 121\n",
      "episode 168, reward 221.0, memory_length 2000, epsilon 0.8890427116248064 total_time 728.0 step_num 120\n",
      "episode 169, reward 125.0, memory_length 2000, epsilon 0.8884205994913187 total_time 722.0 step_num 130\n",
      "episode 170, reward -371.0, memory_length 2000, epsilon 0.8877989226839426 total_time 724.0 step_num 122\n",
      "episode 171, reward -329.0, memory_length 2000, epsilon 0.8871776808980562 total_time 721.0 step_num 160\n",
      "episode 172, reward -226.0, memory_length 2000, epsilon 0.8865568738292513 total_time 731.0 step_num 112\n",
      "episode 173, reward -123.0, memory_length 2000, epsilon 0.8859365011733322 total_time 723.0 step_num 129\n",
      "episode 174, reward -182.0, memory_length 2000, epsilon 0.8853165626263164 total_time 724.0 step_num 147\n",
      "episode 175, reward -155.0, memory_length 2000, epsilon 0.8846970578844342 total_time 724.0 step_num 133\n",
      "episode 176, reward -168.0, memory_length 2000, epsilon 0.8840779866441278 total_time 723.0 step_num 123\n",
      "episode 177, reward -248.0, memory_length 2000, epsilon 0.8834593486020529 total_time 721.0 step_num 130\n",
      "episode 178, reward -290.0, memory_length 2000, epsilon 0.8828411434550761 total_time 733.0 step_num 124\n",
      "episode 179, reward 48.0, memory_length 2000, epsilon 0.8822233709002775 total_time 732.0 step_num 138\n",
      "episode 180, reward 77.0, memory_length 2000, epsilon 0.8816060306349482 total_time 728.0 step_num 136\n",
      "episode 181, reward 16.0, memory_length 2000, epsilon 0.8809891223565917 total_time 733.0 step_num 137\n",
      "episode 182, reward -69.0, memory_length 2000, epsilon 0.8803726457629226 total_time 723.0 step_num 127\n",
      "episode 183, reward -81.0, memory_length 2000, epsilon 0.8797566005518677 total_time 729.0 step_num 124\n",
      "episode 184, reward -302.0, memory_length 2000, epsilon 0.8791409864215646 total_time 730.0 step_num 136\n",
      "episode 185, reward -22.0, memory_length 2000, epsilon 0.8785258030703623 total_time 728.0 step_num 146\n",
      "episode 186, reward -248.0, memory_length 2000, epsilon 0.8779110501968211 total_time 721.0 step_num 140\n",
      "episode 187, reward -351.0, memory_length 2000, epsilon 0.8772967274997123 total_time 729.0 step_num 124\n",
      "episode 188, reward -325.0, memory_length 2000, epsilon 0.8766828346780173 total_time 722.0 step_num 127\n",
      "episode 189, reward -116.0, memory_length 2000, epsilon 0.876069371430929 total_time 727.0 step_num 138\n",
      "episode 190, reward -210.0, memory_length 2000, epsilon 0.87545633745785 total_time 726.0 step_num 128\n",
      "episode 191, reward -408.0, memory_length 2000, epsilon 0.8748437324583941 total_time 735.0 step_num 126\n",
      "episode 192, reward -378.0, memory_length 2000, epsilon 0.8742315561323846 total_time 729.0 step_num 142\n",
      "episode 193, reward -70.0, memory_length 2000, epsilon 0.873619808179855 total_time 725.0 step_num 145\n",
      "episode 194, reward -208.0, memory_length 2000, epsilon 0.8730084883010488 total_time 722.0 step_num 140\n",
      "episode 195, reward -73.0, memory_length 2000, epsilon 0.8723975961964195 total_time 722.0 step_num 145\n",
      "episode 196, reward -199.0, memory_length 2000, epsilon 0.8717871315666298 total_time 722.0 step_num 137\n",
      "episode 197, reward -86.0, memory_length 2000, epsilon 0.871177094112552 total_time 721.0 step_num 131\n",
      "episode 198, reward -81.0, memory_length 2000, epsilon 0.8705674835352676 total_time 729.0 step_num 146\n",
      "episode 199, reward -131.0, memory_length 2000, epsilon 0.8699582995360676 total_time 730.0 step_num 133\n",
      "episode 200, reward 105.0, memory_length 2000, epsilon 0.8693495418164519 total_time 726.0 step_num 142\n",
      "episode 201, reward 53.0, memory_length 2000, epsilon 0.868741210078129 total_time 722.0 step_num 140\n",
      "episode 202, reward 157.0, memory_length 2000, epsilon 0.8681333040230164 total_time 721.0 step_num 131\n",
      "episode 203, reward 206.0, memory_length 2000, epsilon 0.8675258233532401 total_time 722.0 step_num 134\n",
      "episode 204, reward -109.0, memory_length 2000, epsilon 0.8669187677711347 total_time 722.0 step_num 137\n",
      "episode 205, reward -128.0, memory_length 2000, epsilon 0.8663121369792428 total_time 724.0 step_num 138\n",
      "episode 206, reward -154.0, memory_length 2000, epsilon 0.8657059306803154 total_time 722.0 step_num 113\n",
      "episode 207, reward 229.0, memory_length 2000, epsilon 0.8651001485773113 total_time 721.0 step_num 136\n",
      "episode 208, reward 184.0, memory_length 2000, epsilon 0.8644947903733974 total_time 721.0 step_num 125\n",
      "episode 209, reward 34.0, memory_length 2000, epsilon 0.8638898557719481 total_time 724.0 step_num 124\n",
      "episode 210, reward 200.0, memory_length 2000, epsilon 0.8632853444765453 total_time 725.0 step_num 136\n",
      "episode 211, reward -242.0, memory_length 2000, epsilon 0.8626812561909786 total_time 736.0 step_num 120\n",
      "episode 212, reward 31.0, memory_length 2000, epsilon 0.8620775906192447 total_time 721.0 step_num 119\n",
      "episode 213, reward 37.0, memory_length 2000, epsilon 0.8614743474655475 total_time 727.0 step_num 131\n",
      "episode 214, reward -55.0, memory_length 2000, epsilon 0.8608715264342977 total_time 731.0 step_num 136\n",
      "episode 215, reward -121.0, memory_length 2000, epsilon 0.8602691272301131 total_time 728.0 step_num 141\n",
      "episode 216, reward -88.0, memory_length 2000, epsilon 0.8596671495578181 total_time 725.0 step_num 123\n",
      "episode 217, reward -248.0, memory_length 2000, epsilon 0.8590655931224436 total_time 721.0 step_num 135\n",
      "episode 218, reward 111.0, memory_length 2000, epsilon 0.8584644576292269 total_time 723.0 step_num 135\n",
      "episode 219, reward -302.0, memory_length 2000, epsilon 0.8578637427836115 total_time 721.0 step_num 154\n",
      "episode 220, reward -234.0, memory_length 2000, epsilon 0.8572634482912475 total_time 729.0 step_num 128\n",
      "episode 221, reward 24.0, memory_length 2000, epsilon 0.8566635738579901 total_time 726.0 step_num 121\n",
      "episode 222, reward -32.0, memory_length 2000, epsilon 0.856064119189901 total_time 721.0 step_num 135\n",
      "episode 223, reward 124.0, memory_length 2000, epsilon 0.8554650839932475 total_time 724.0 step_num 122\n",
      "episode 224, reward -176.0, memory_length 2000, epsilon 0.8548664679745023 total_time 730.0 step_num 135\n",
      "episode 225, reward -149.0, memory_length 2000, epsilon 0.8542682708403435 total_time 721.0 step_num 113\n",
      "episode 226, reward -73.0, memory_length 2000, epsilon 0.8536704922976543 total_time 722.0 step_num 142\n",
      "episode 227, reward 8.0, memory_length 2000, epsilon 0.8530731320535238 total_time 722.0 step_num 132\n",
      "episode 228, reward -24.0, memory_length 2000, epsilon 0.8524761898152448 total_time 723.0 step_num 124\n",
      "episode 229, reward -1.0, memory_length 2000, epsilon 0.8518796652903159 total_time 722.0 step_num 136\n",
      "episode 230, reward 123.0, memory_length 2000, epsilon 0.8512835581864401 total_time 726.0 step_num 133\n",
      "episode 231, reward -231.0, memory_length 2000, epsilon 0.8506878682115248 total_time 723.0 step_num 124\n",
      "episode 232, reward -14.0, memory_length 2000, epsilon 0.850092595073682 total_time 721.0 step_num 127\n",
      "episode 233, reward -115.0, memory_length 2000, epsilon 0.8494977384812278 total_time 725.0 step_num 133\n",
      "episode 234, reward -71.0, memory_length 2000, epsilon 0.8489032981426824 total_time 727.0 step_num 120\n",
      "episode 235, reward -212.0, memory_length 2000, epsilon 0.84830927376677 total_time 721.0 step_num 133\n",
      "episode 236, reward 94.0, memory_length 2000, epsilon 0.8477156650624188 total_time 721.0 step_num 133\n",
      "episode 237, reward 66.0, memory_length 2000, epsilon 0.8471224717387604 total_time 723.0 step_num 132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 238, reward 121.0, memory_length 2000, epsilon 0.8465296935051303 total_time 721.0 step_num 136\n",
      "episode 239, reward 131.0, memory_length 2000, epsilon 0.8459373300710668 total_time 728.0 step_num 119\n",
      "episode 240, reward -142.0, memory_length 2000, epsilon 0.845345381146312 total_time 734.0 step_num 132\n",
      "episode 241, reward 17.0, memory_length 2000, epsilon 0.8447538464408108 total_time 731.0 step_num 133\n",
      "episode 242, reward -13.0, memory_length 2000, epsilon 0.8441627256647113 total_time 737.0 step_num 131\n",
      "episode 243, reward 173.0, memory_length 2000, epsilon 0.8435720185283643 total_time 725.0 step_num 122\n",
      "episode 244, reward -266.0, memory_length 2000, epsilon 0.8429817247423231 total_time 721.0 step_num 131\n",
      "episode 245, reward -415.0, memory_length 2000, epsilon 0.842391844017344 total_time 722.0 step_num 144\n",
      "episode 246, reward -312.0, memory_length 2000, epsilon 0.8418023760643853 total_time 723.0 step_num 130\n",
      "episode 247, reward -23.0, memory_length 2000, epsilon 0.8412133205946078 total_time 721.0 step_num 136\n",
      "episode 248, reward -22.0, memory_length 2000, epsilon 0.8406246773193743 total_time 728.0 step_num 127\n",
      "episode 249, reward -298.0, memory_length 2000, epsilon 0.8400364459502493 total_time 722.0 step_num 138\n",
      "episode 250, reward 22.0, memory_length 2000, epsilon 0.8394486261989997 total_time 721.0 step_num 134\n",
      "episode 251, reward 49.0, memory_length 2000, epsilon 0.8388612177775938 total_time 721.0 step_num 123\n",
      "episode 252, reward 144.0, memory_length 2000, epsilon 0.8382742203982012 total_time 729.0 step_num 117\n",
      "episode 253, reward 23.0, memory_length 2000, epsilon 0.8376876337731937 total_time 737.0 step_num 115\n",
      "episode 254, reward 37.0, memory_length 2000, epsilon 0.8371014576151432 total_time 727.0 step_num 132\n",
      "episode 255, reward -131.0, memory_length 2000, epsilon 0.8365156916368238 total_time 721.0 step_num 147\n",
      "episode 256, reward -48.0, memory_length 2000, epsilon 0.83593033555121 total_time 726.0 step_num 135\n",
      "episode 257, reward 353.0, memory_length 2000, epsilon 0.8353453890714774 total_time 725.0 step_num 134\n",
      "episode 258, reward -149.0, memory_length 2000, epsilon 0.8347608519110021 total_time 721.0 step_num 141\n",
      "episode 259, reward -154.0, memory_length 2000, epsilon 0.8341767237833609 total_time 722.0 step_num 138\n",
      "episode 260, reward -320.0, memory_length 2000, epsilon 0.8335930044023312 total_time 721.0 step_num 130\n",
      "episode 261, reward 80.0, memory_length 2000, epsilon 0.8330096934818902 total_time 722.0 step_num 136\n",
      "episode 262, reward -154.0, memory_length 2000, epsilon 0.8324267907362157 total_time 722.0 step_num 122\n",
      "episode 263, reward -14.0, memory_length 2000, epsilon 0.8318442958796854 total_time 721.0 step_num 128\n",
      "episode 264, reward 20.0, memory_length 2000, epsilon 0.8312622086268767 total_time 725.0 step_num 116\n",
      "episode 265, reward -218.0, memory_length 2000, epsilon 0.8306805286925668 total_time 724.0 step_num 120\n",
      "episode 266, reward -137.0, memory_length 2000, epsilon 0.8300992557917326 total_time 724.0 step_num 142\n",
      "episode 267, reward 125.0, memory_length 2000, epsilon 0.8295183896395504 total_time 722.0 step_num 131\n",
      "episode 268, reward -329.0, memory_length 2000, epsilon 0.8289379299513956 total_time 730.0 step_num 139\n",
      "episode 269, reward 85.0, memory_length 2000, epsilon 0.8283578764428432 total_time 721.0 step_num 127\n",
      "episode 270, reward 133.0, memory_length 2000, epsilon 0.8277782288296667 total_time 724.0 step_num 129\n",
      "episode 271, reward -77.0, memory_length 2000, epsilon 0.8271989868278389 total_time 739.0 step_num 117\n",
      "episode 272, reward -305.0, memory_length 2000, epsilon 0.8266201501535313 total_time 727.0 step_num 134\n",
      "episode 273, reward 19.0, memory_length 2000, epsilon 0.8260417185231138 total_time 736.0 step_num 123\n",
      "episode 274, reward 70.0, memory_length 2000, epsilon 0.8254636916531549 total_time 724.0 step_num 119\n",
      "episode 275, reward -111.0, memory_length 2000, epsilon 0.8248860692604214 total_time 726.0 step_num 126\n",
      "episode 276, reward -100.0, memory_length 2000, epsilon 0.8243088510618783 total_time 722.0 step_num 124\n",
      "episode 277, reward -109.0, memory_length 2000, epsilon 0.8237320367746888 total_time 722.0 step_num 127\n",
      "episode 278, reward 80.0, memory_length 2000, epsilon 0.8231556261162136 total_time 731.0 step_num 146\n",
      "episode 279, reward -78.0, memory_length 2000, epsilon 0.822579618804012 total_time 732.0 step_num 140\n",
      "episode 280, reward -257.0, memory_length 2000, epsilon 0.8220040145558398 total_time 721.0 step_num 142\n",
      "episode 281, reward -77.0, memory_length 2000, epsilon 0.8214288130896513 total_time 721.0 step_num 121\n",
      "episode 282, reward -374.0, memory_length 2000, epsilon 0.8208540141235976 total_time 721.0 step_num 143\n",
      "episode 283, reward -154.0, memory_length 2000, epsilon 0.8202796173760273 total_time 731.0 step_num 130\n",
      "episode 284, reward -170.0, memory_length 2000, epsilon 0.8197056225654858 total_time 727.0 step_num 125\n",
      "episode 285, reward -203.0, memory_length 2000, epsilon 0.819132029410716 total_time 730.0 step_num 139\n",
      "episode 286, reward 61.0, memory_length 2000, epsilon 0.8185588376306567 total_time 724.0 step_num 122\n",
      "episode 287, reward -87.0, memory_length 2000, epsilon 0.8179860469444444 total_time 723.0 step_num 145\n",
      "episode 288, reward -172.0, memory_length 2000, epsilon 0.8174136570714114 total_time 722.0 step_num 125\n",
      "episode 289, reward 59.0, memory_length 2000, epsilon 0.8168416677310868 total_time 728.0 step_num 128\n",
      "episode 290, reward 236.0, memory_length 2000, epsilon 0.8162700786431957 total_time 725.0 step_num 132\n",
      "episode 291, reward 76.0, memory_length 2000, epsilon 0.8156988895276595 total_time 721.0 step_num 126\n",
      "episode 292, reward 56.0, memory_length 2000, epsilon 0.8151281001045955 total_time 725.0 step_num 144\n",
      "episode 293, reward 193.0, memory_length 2000, epsilon 0.8145577100943168 total_time 721.0 step_num 127\n",
      "episode 294, reward 49.0, memory_length 2000, epsilon 0.8139877192173323 total_time 721.0 step_num 154\n",
      "episode 295, reward -48.0, memory_length 2000, epsilon 0.8134181271943466 total_time 726.0 step_num 131\n",
      "episode 296, reward -428.0, memory_length 2000, epsilon 0.8128489337462593 total_time 721.0 step_num 121\n",
      "episode 297, reward 355.0, memory_length 2000, epsilon 0.812280138594166 total_time 721.0 step_num 120\n",
      "episode 298, reward -68.0, memory_length 2000, epsilon 0.8117117414593569 total_time 721.0 step_num 133\n",
      "episode 299, reward 25.0, memory_length 2000, epsilon 0.8111437420633173 total_time 724.0 step_num 139\n",
      "episode 300, reward 31.0, memory_length 2000, epsilon 0.8105761401277274 total_time 721.0 step_num 125\n",
      "episode 301, reward 50.0, memory_length 2000, epsilon 0.8100089353744625 total_time 728.0 step_num 120\n",
      "episode 302, reward 259.0, memory_length 2000, epsilon 0.8094421275255921 total_time 724.0 step_num 125\n",
      "episode 303, reward -5.0, memory_length 2000, epsilon 0.8088757163033805 total_time 721.0 step_num 120\n",
      "episode 304, reward 86.0, memory_length 2000, epsilon 0.8083097014302859 total_time 728.0 step_num 134\n",
      "episode 305, reward -176.0, memory_length 2000, epsilon 0.8077440826289614 total_time 721.0 step_num 121\n",
      "episode 306, reward 116.0, memory_length 2000, epsilon 0.8071788596222534 total_time 722.0 step_num 143\n",
      "episode 307, reward 57.0, memory_length 2000, epsilon 0.8066140321332027 total_time 723.0 step_num 132\n",
      "episode 308, reward -139.0, memory_length 2000, epsilon 0.806049599885044 total_time 728.0 step_num 136\n",
      "episode 309, reward -68.0, memory_length 2000, epsilon 0.8054855626012054 total_time 721.0 step_num 131\n",
      "episode 310, reward -240.0, memory_length 2000, epsilon 0.8049219200053085 total_time 732.0 step_num 113\n",
      "episode 311, reward -86.0, memory_length 2000, epsilon 0.8043586718211684 total_time 730.0 step_num 132\n",
      "episode 312, reward -113.0, memory_length 2000, epsilon 0.8037958177727937 total_time 721.0 step_num 127\n",
      "episode 313, reward -141.0, memory_length 2000, epsilon 0.803233357584386 total_time 732.0 step_num 116\n",
      "episode 314, reward 102.0, memory_length 2000, epsilon 0.8026712909803393 total_time 723.0 step_num 143\n",
      "episode 315, reward -17.0, memory_length 2000, epsilon 0.8021096176852414 total_time 727.0 step_num 137\n",
      "episode 316, reward -68.0, memory_length 2000, epsilon 0.8015483374238721 total_time 730.0 step_num 142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 317, reward 166.0, memory_length 2000, epsilon 0.8009874499212043 total_time 730.0 step_num 146\n",
      "episode 318, reward -275.0, memory_length 2000, epsilon 0.8004269549024029 total_time 721.0 step_num 125\n",
      "episode 319, reward -122.0, memory_length 2000, epsilon 0.7998668520928254 total_time 721.0 step_num 108\n",
      "episode 320, reward -356.0, memory_length 2000, epsilon 0.7993071412180214 total_time 721.0 step_num 119\n",
      "episode 321, reward -85.0, memory_length 2000, epsilon 0.7987478220037326 total_time 728.0 step_num 133\n",
      "episode 322, reward -3.0, memory_length 2000, epsilon 0.7981888941758928 total_time 726.0 step_num 123\n",
      "episode 323, reward 74.0, memory_length 2000, epsilon 0.7976303574606269 total_time 725.0 step_num 124\n",
      "episode 324, reward -233.0, memory_length 2000, epsilon 0.7970722115842521 total_time 727.0 step_num 127\n",
      "episode 325, reward 3.0, memory_length 2000, epsilon 0.7965144562732769 total_time 723.0 step_num 135\n",
      "episode 326, reward -177.0, memory_length 2000, epsilon 0.7959570912544014 total_time 723.0 step_num 125\n",
      "episode 327, reward -140.0, memory_length 2000, epsilon 0.7954001162545165 total_time 721.0 step_num 146\n",
      "episode 328, reward -5.0, memory_length 2000, epsilon 0.7948435310007043 total_time 730.0 step_num 121\n",
      "episode 329, reward -103.0, memory_length 2000, epsilon 0.7942873352202383 total_time 728.0 step_num 125\n",
      "episode 330, reward -394.0, memory_length 2000, epsilon 0.7937315286405824 total_time 725.0 step_num 130\n",
      "episode 331, reward -88.0, memory_length 2000, epsilon 0.7931761109893916 total_time 725.0 step_num 126\n",
      "episode 332, reward 43.0, memory_length 2000, epsilon 0.7926210819945108 total_time 733.0 step_num 133\n",
      "episode 333, reward 21.0, memory_length 2000, epsilon 0.7920664413839762 total_time 723.0 step_num 124\n",
      "episode 334, reward 212.0, memory_length 2000, epsilon 0.7915121888860137 total_time 728.0 step_num 139\n",
      "episode 335, reward -113.0, memory_length 2000, epsilon 0.7909583242290396 total_time 721.0 step_num 125\n",
      "episode 336, reward -78.0, memory_length 2000, epsilon 0.7904048471416601 total_time 723.0 step_num 126\n",
      "episode 337, reward 67.0, memory_length 2000, epsilon 0.7898517573526715 total_time 721.0 step_num 136\n",
      "episode 338, reward 83.0, memory_length 2000, epsilon 0.78929905459106 total_time 725.0 step_num 142\n",
      "episode 339, reward -347.0, memory_length 2000, epsilon 0.788746738586001 total_time 721.0 step_num 117\n",
      "episode 340, reward 70.0, memory_length 2000, epsilon 0.7881948090668595 total_time 724.0 step_num 124\n",
      "episode 341, reward -132.0, memory_length 2000, epsilon 0.7876432657631903 total_time 723.0 step_num 123\n",
      "episode 342, reward 49.0, memory_length 2000, epsilon 0.7870921084047371 total_time 721.0 step_num 123\n",
      "episode 343, reward -8.0, memory_length 2000, epsilon 0.7865413367214328 total_time 727.0 step_num 123\n",
      "episode 344, reward 102.0, memory_length 2000, epsilon 0.7859909504433993 total_time 723.0 step_num 122\n",
      "episode 345, reward 6.0, memory_length 2000, epsilon 0.7854409493009471 total_time 726.0 step_num 131\n",
      "episode 346, reward -103.0, memory_length 2000, epsilon 0.7848913330245758 total_time 728.0 step_num 142\n",
      "episode 347, reward 224.0, memory_length 2000, epsilon 0.7843421013449735 total_time 722.0 step_num 128\n",
      "episode 348, reward -113.0, memory_length 2000, epsilon 0.7837932539930165 total_time 721.0 step_num 126\n",
      "episode 349, reward -112.0, memory_length 2000, epsilon 0.7832447906997695 total_time 728.0 step_num 133\n",
      "episode 350, reward -167.0, memory_length 2000, epsilon 0.7826967111964858 total_time 721.0 step_num 146\n",
      "episode 351, reward -309.0, memory_length 2000, epsilon 0.7821490152146062 total_time 726.0 step_num 133\n",
      "episode 352, reward -185.0, memory_length 2000, epsilon 0.7816017024857597 total_time 721.0 step_num 138\n",
      "episode 353, reward 22.0, memory_length 2000, epsilon 0.7810547727417629 total_time 721.0 step_num 125\n",
      "episode 354, reward -113.0, memory_length 2000, epsilon 0.7805082257146205 total_time 721.0 step_num 117\n",
      "episode 355, reward -102.0, memory_length 2000, epsilon 0.7799620611365244 total_time 726.0 step_num 136\n",
      "episode 356, reward 88.0, memory_length 2000, epsilon 0.7794162787398539 total_time 724.0 step_num 147\n",
      "episode 357, reward 93.0, memory_length 2000, epsilon 0.7788708782571753 total_time 732.0 step_num 143\n",
      "episode 358, reward 121.0, memory_length 2000, epsilon 0.7783258594212428 total_time 721.0 step_num 119\n",
      "episode 359, reward 151.0, memory_length 2000, epsilon 0.777781221964997 total_time 724.0 step_num 123\n",
      "episode 360, reward 6.0, memory_length 2000, epsilon 0.7772369656215654 total_time 726.0 step_num 136\n",
      "episode 361, reward -334.0, memory_length 2000, epsilon 0.7766930901242627 total_time 722.0 step_num 125\n",
      "episode 362, reward 114.0, memory_length 2000, epsilon 0.7761495952065897 total_time 726.0 step_num 128\n",
      "episode 363, reward -208.0, memory_length 2000, epsilon 0.7756064806022338 total_time 731.0 step_num 121\n",
      "episode 364, reward 41.0, memory_length 2000, epsilon 0.7750637460450688 total_time 728.0 step_num 122\n",
      "episode 365, reward -122.0, memory_length 2000, epsilon 0.774521391269155 total_time 721.0 step_num 120\n",
      "episode 366, reward -264.0, memory_length 2000, epsilon 0.7739794160087384 total_time 726.0 step_num 131\n",
      "episode 367, reward 14.0, memory_length 2000, epsilon 0.7734378199982511 total_time 728.0 step_num 122\n",
      "episode 368, reward -223.0, memory_length 2000, epsilon 0.7728966029723111 total_time 725.0 step_num 139\n",
      "episode 369, reward -5.0, memory_length 2000, epsilon 0.772355764665722 total_time 721.0 step_num 134\n",
      "episode 370, reward -252.0, memory_length 2000, epsilon 0.771815304813473 total_time 729.0 step_num 123\n",
      "episode 371, reward -14.0, memory_length 2000, epsilon 0.7712752231507389 total_time 721.0 step_num 138\n",
      "episode 372, reward 294.0, memory_length 2000, epsilon 0.7707355194128795 total_time 726.0 step_num 131\n",
      "episode 373, reward -91.0, memory_length 2000, epsilon 0.7701961933354401 total_time 722.0 step_num 137\n",
      "episode 374, reward -53.0, memory_length 2000, epsilon 0.7696572446541509 total_time 736.0 step_num 140\n",
      "episode 375, reward -17.0, memory_length 2000, epsilon 0.7691186731049269 total_time 727.0 step_num 128\n",
      "episode 376, reward 4.0, memory_length 2000, epsilon 0.7685804784238681 total_time 730.0 step_num 146\n",
      "episode 377, reward -122.0, memory_length 2000, epsilon 0.768042660347259 total_time 721.0 step_num 128\n",
      "episode 378, reward 52.0, memory_length 2000, epsilon 0.767505218611569 total_time 733.0 step_num 129\n",
      "episode 379, reward -186.0, memory_length 2000, epsilon 0.7669681529534514 total_time 723.0 step_num 128\n",
      "episode 380, reward -59.0, memory_length 2000, epsilon 0.7664314631097442 total_time 721.0 step_num 130\n",
      "episode 381, reward 78.0, memory_length 2000, epsilon 0.7658951488174691 total_time 726.0 step_num 123\n",
      "episode 382, reward -95.0, memory_length 2000, epsilon 0.7653592098138324 total_time 721.0 step_num 136\n",
      "episode 383, reward -87.0, memory_length 2000, epsilon 0.7648236458362238 total_time 723.0 step_num 129\n",
      "episode 384, reward 13.0, memory_length 2000, epsilon 0.7642884566222169 total_time 721.0 step_num 135\n",
      "episode 385, reward -40.0, memory_length 2000, epsilon 0.763753641909569 total_time 728.0 step_num 137\n",
      "episode 386, reward 132.0, memory_length 2000, epsilon 0.7632192014362209 total_time 726.0 step_num 120\n",
      "episode 387, reward -302.0, memory_length 2000, epsilon 0.7626851349402968 total_time 721.0 step_num 131\n",
      "episode 388, reward 240.0, memory_length 2000, epsilon 0.7621514421601041 total_time 726.0 step_num 124\n",
      "episode 389, reward 192.0, memory_length 2000, epsilon 0.7616181228341334 total_time 723.0 step_num 131\n",
      "episode 390, reward -62.0, memory_length 2000, epsilon 0.761085176701058 total_time 727.0 step_num 110\n",
      "episode 391, reward -145.0, memory_length 2000, epsilon 0.7605526034997344 total_time 722.0 step_num 139\n",
      "episode 392, reward 158.0, memory_length 2000, epsilon 0.7600204029692019 total_time 728.0 step_num 119\n",
      "episode 393, reward 346.0, memory_length 2000, epsilon 0.7594885748486819 total_time 721.0 step_num 121\n",
      "episode 394, reward 312.0, memory_length 2000, epsilon 0.7589571188775789 total_time 726.0 step_num 128\n",
      "episode 395, reward -166.0, memory_length 2000, epsilon 0.7584260347954792 total_time 728.0 step_num 131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 396, reward -10.0, memory_length 2000, epsilon 0.7578953223421517 total_time 722.0 step_num 135\n",
      "episode 397, reward 66.0, memory_length 2000, epsilon 0.7573649812575475 total_time 723.0 step_num 145\n",
      "episode 398, reward 242.0, memory_length 2000, epsilon 0.7568350112817991 total_time 722.0 step_num 131\n",
      "episode 399, reward -6.0, memory_length 2000, epsilon 0.7563054121552215 total_time 732.0 step_num 137\n",
      "episode 400, reward -109.0, memory_length 2000, epsilon 0.7557761836183109 total_time 722.0 step_num 129\n",
      "episode 401, reward -20.0, memory_length 2000, epsilon 0.7552473254117454 total_time 733.0 step_num 127\n",
      "episode 402, reward 94.0, memory_length 2000, epsilon 0.7547188372763846 total_time 721.0 step_num 123\n",
      "episode 403, reward -127.0, memory_length 2000, epsilon 0.754190718953269 total_time 731.0 step_num 109\n",
      "episode 404, reward 17.0, memory_length 2000, epsilon 0.7536629701836209 total_time 722.0 step_num 115\n",
      "episode 405, reward -69.0, memory_length 2000, epsilon 0.7531355907088432 total_time 723.0 step_num 125\n",
      "episode 406, reward -141.0, memory_length 2000, epsilon 0.75260858027052 total_time 723.0 step_num 122\n",
      "episode 407, reward 58.0, memory_length 2000, epsilon 0.7520819386104162 total_time 730.0 step_num 121\n",
      "episode 408, reward -137.0, memory_length 2000, epsilon 0.7515556654704773 total_time 724.0 step_num 124\n",
      "episode 409, reward 218.0, memory_length 2000, epsilon 0.7510297605928297 total_time 725.0 step_num 136\n",
      "episode 410, reward 115.0, memory_length 2000, epsilon 0.7505042237197797 total_time 724.0 step_num 126\n",
      "episode 411, reward -148.0, memory_length 2000, epsilon 0.7499790545938142 total_time 737.0 step_num 138\n",
      "episode 412, reward -415.0, memory_length 2000, epsilon 0.7494542529576007 total_time 722.0 step_num 147\n",
      "episode 413, reward 227.0, memory_length 2000, epsilon 0.748929818553986 total_time 725.0 step_num 135\n",
      "episode 414, reward -116.0, memory_length 2000, epsilon 0.7484057511259975 total_time 727.0 step_num 120\n",
      "episode 415, reward -217.0, memory_length 2000, epsilon 0.747882050416842 total_time 722.0 step_num 141\n",
      "episode 416, reward 112.0, memory_length 2000, epsilon 0.7473587161699061 total_time 721.0 step_num 128\n",
      "episode 417, reward 317.0, memory_length 2000, epsilon 0.746835748128756 total_time 725.0 step_num 129\n",
      "episode 418, reward 13.0, memory_length 2000, epsilon 0.7463131460371376 total_time 721.0 step_num 125\n",
      "episode 419, reward 138.0, memory_length 2000, epsilon 0.7457909096389755 total_time 723.0 step_num 131\n",
      "episode 420, reward 147.0, memory_length 2000, epsilon 0.7452690386783742 total_time 723.0 step_num 149\n",
      "episode 421, reward -41.0, memory_length 2000, epsilon 0.7447475328996168 total_time 721.0 step_num 160\n",
      "episode 422, reward -59.0, memory_length 2000, epsilon 0.7442263920471653 total_time 721.0 step_num 134\n",
      "episode 423, reward -195.0, memory_length 2000, epsilon 0.7437056158656608 total_time 723.0 step_num 133\n",
      "episode 424, reward 21.0, memory_length 2000, epsilon 0.7431852040999231 total_time 723.0 step_num 145\n",
      "episode 425, reward -89.0, memory_length 2000, epsilon 0.7426651564949501 total_time 727.0 step_num 121\n",
      "episode 426, reward 134.0, memory_length 2000, epsilon 0.7421454727959187 total_time 722.0 step_num 133\n",
      "episode 427, reward -35.0, memory_length 2000, epsilon 0.7416261527481839 total_time 727.0 step_num 136\n",
      "episode 428, reward -140.0, memory_length 2000, epsilon 0.7411071960972787 total_time 721.0 step_num 136\n",
      "episode 429, reward 170.0, memory_length 2000, epsilon 0.7405886025889145 total_time 722.0 step_num 139\n",
      "episode 430, reward 76.0, memory_length 2000, epsilon 0.7400703719689802 total_time 721.0 step_num 127\n",
      "episode 431, reward 218.0, memory_length 2000, epsilon 0.7395525039835431 total_time 725.0 step_num 128\n",
      "episode 432, reward -330.0, memory_length 2000, epsilon 0.7390349983788478 total_time 723.0 step_num 131\n",
      "episode 433, reward -194.0, memory_length 2000, epsilon 0.7385178549013164 total_time 730.0 step_num 110\n",
      "episode 434, reward -115.0, memory_length 2000, epsilon 0.7380010732975486 total_time 725.0 step_num 119\n",
      "episode 435, reward 91.0, memory_length 2000, epsilon 0.7374846533143217 total_time 727.0 step_num 106\n",
      "episode 436, reward -141.0, memory_length 2000, epsilon 0.7369685946985896 total_time 723.0 step_num 117\n",
      "episode 437, reward 209.0, memory_length 2000, epsilon 0.7364528971974836 total_time 725.0 step_num 139\n",
      "episode 438, reward 67.0, memory_length 2000, epsilon 0.7359375605583119 total_time 730.0 step_num 122\n",
      "episode 439, reward -132.0, memory_length 2000, epsilon 0.7354225845285597 total_time 732.0 step_num 144\n",
      "episode 440, reward -250.0, memory_length 2000, epsilon 0.7349079688558887 total_time 725.0 step_num 120\n",
      "episode 441, reward 58.0, memory_length 2000, epsilon 0.734393713288137 total_time 721.0 step_num 151\n",
      "episode 442, reward -176.0, memory_length 2000, epsilon 0.7338798175733195 total_time 721.0 step_num 140\n",
      "episode 443, reward -35.0, memory_length 2000, epsilon 0.7333662814596275 total_time 727.0 step_num 121\n",
      "episode 444, reward 48.0, memory_length 2000, epsilon 0.7328531046954279 total_time 723.0 step_num 115\n",
      "episode 445, reward -192.0, memory_length 2000, epsilon 0.7323402870292643 total_time 726.0 step_num 156\n",
      "episode 446, reward -32.0, memory_length 2000, epsilon 0.731827828209856 total_time 721.0 step_num 122\n",
      "episode 447, reward -214.0, memory_length 2000, epsilon 0.7313157279860982 total_time 734.0 step_num 145\n",
      "episode 448, reward -46.0, memory_length 2000, epsilon 0.7308039861070618 total_time 722.0 step_num 141\n",
      "episode 449, reward -379.0, memory_length 2000, epsilon 0.730292602321993 total_time 722.0 step_num 135\n",
      "episode 450, reward 13.0, memory_length 2000, epsilon 0.7297815763803142 total_time 721.0 step_num 120\n",
      "episode 451, reward 11.0, memory_length 2000, epsilon 0.7292709080316223 total_time 725.0 step_num 133\n",
      "episode 452, reward 39.0, memory_length 2000, epsilon 0.7287605970256898 total_time 723.0 step_num 119\n",
      "episode 453, reward -148.0, memory_length 2000, epsilon 0.7282506431124647 total_time 728.0 step_num 128\n",
      "episode 454, reward -9.0, memory_length 2000, epsilon 0.7277410460420691 total_time 729.0 step_num 138\n",
      "episode 455, reward 71.0, memory_length 2000, epsilon 0.7272318055648006 total_time 731.0 step_num 132\n",
      "episode 456, reward 49.0, memory_length 2000, epsilon 0.7267229214311316 total_time 730.0 step_num 156\n",
      "episode 457, reward -122.0, memory_length 2000, epsilon 0.7262143933917085 total_time 730.0 step_num 115\n",
      "episode 458, reward 82.0, memory_length 2000, epsilon 0.7257062211973526 total_time 727.0 step_num 115\n",
      "episode 459, reward -183.0, memory_length 2000, epsilon 0.7251984045990598 total_time 726.0 step_num 126\n",
      "episode 460, reward 61.0, memory_length 2000, epsilon 0.7246909433479997 total_time 724.0 step_num 131\n",
      "episode 461, reward 166.0, memory_length 2000, epsilon 0.7241838371955163 total_time 721.0 step_num 135\n",
      "episode 462, reward -2.0, memory_length 2000, epsilon 0.7236770858931275 total_time 724.0 step_num 127\n",
      "episode 463, reward -88.0, memory_length 2000, epsilon 0.7231706891925254 total_time 725.0 step_num 127\n",
      "episode 464, reward 40.0, memory_length 2000, epsilon 0.7226646468455754 total_time 721.0 step_num 125\n",
      "episode 465, reward 125.0, memory_length 2000, epsilon 0.7221589586043169 total_time 722.0 step_num 140\n",
      "episode 466, reward -274.0, memory_length 2000, epsilon 0.7216536242209626 total_time 728.0 step_num 135\n",
      "episode 467, reward -194.0, memory_length 2000, epsilon 0.7211486434478985 total_time 721.0 step_num 117\n",
      "episode 468, reward 358.0, memory_length 2000, epsilon 0.7206440160376841 total_time 724.0 step_num 122\n",
      "episode 469, reward 338.0, memory_length 2000, epsilon 0.7201397417430522 total_time 728.0 step_num 138\n",
      "episode 470, reward -50.0, memory_length 2000, epsilon 0.719635820316908 total_time 721.0 step_num 141\n",
      "episode 471, reward 96.0, memory_length 2000, epsilon 0.7191322515123301 total_time 726.0 step_num 121\n",
      "episode 472, reward -183.0, memory_length 2000, epsilon 0.7186290350825699 total_time 726.0 step_num 142\n",
      "episode 473, reward 31.0, memory_length 2000, epsilon 0.7181261707810513 total_time 721.0 step_num 127\n",
      "episode 474, reward -158.0, memory_length 2000, epsilon 0.7176236583613707 total_time 721.0 step_num 121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 475, reward 155.0, memory_length 2000, epsilon 0.717121497577297 total_time 725.0 step_num 124\n",
      "episode 476, reward -235.0, memory_length 2000, epsilon 0.7166196881827716 total_time 731.0 step_num 111\n",
      "episode 477, reward -5.0, memory_length 2000, epsilon 0.7161182299319077 total_time 730.0 step_num 134\n",
      "episode 478, reward -88.0, memory_length 2000, epsilon 0.7156171225789908 total_time 725.0 step_num 132\n",
      "episode 479, reward -14.0, memory_length 2000, epsilon 0.7151163658784782 total_time 730.0 step_num 140\n",
      "episode 480, reward -405.0, memory_length 2000, epsilon 0.7146159595849991 total_time 729.0 step_num 136\n",
      "episode 481, reward -115.0, memory_length 2000, epsilon 0.7141159034533547 total_time 725.0 step_num 129\n",
      "episode 482, reward 292.0, memory_length 2000, epsilon 0.7136161972385172 total_time 721.0 step_num 137\n",
      "episode 483, reward 129.0, memory_length 2000, epsilon 0.7131168406956307 total_time 723.0 step_num 131\n",
      "episode 484, reward 125.0, memory_length 2000, epsilon 0.7126178335800103 total_time 722.0 step_num 132\n",
      "episode 485, reward -5.0, memory_length 2000, epsilon 0.7121191756471427 total_time 730.0 step_num 126\n",
      "episode 486, reward 35.0, memory_length 2000, epsilon 0.7116208666526853 total_time 722.0 step_num 133\n",
      "episode 487, reward -175.0, memory_length 2000, epsilon 0.711122906352467 total_time 737.0 step_num 121\n",
      "episode 488, reward -109.0, memory_length 2000, epsilon 0.7106252945024868 total_time 722.0 step_num 140\n",
      "episode 489, reward 145.0, memory_length 2000, epsilon 0.7101280308589153 total_time 727.0 step_num 127\n",
      "episode 490, reward 384.0, memory_length 2000, epsilon 0.7096311151780931 total_time 726.0 step_num 136\n",
      "episode 491, reward 13.0, memory_length 2000, epsilon 0.7091345472165315 total_time 721.0 step_num 119\n",
      "episode 492, reward -112.0, memory_length 2000, epsilon 0.7086383267309122 total_time 728.0 step_num 126\n",
      "episode 493, reward 50.0, memory_length 2000, epsilon 0.7081424534780872 total_time 728.0 step_num 142\n",
      "episode 494, reward 38.0, memory_length 2000, epsilon 0.7076469272150786 total_time 725.0 step_num 133\n",
      "episode 495, reward -217.0, memory_length 2000, epsilon 0.7071517476990785 total_time 722.0 step_num 135\n",
      "episode 496, reward 56.0, memory_length 2000, epsilon 0.706656914687449 total_time 725.0 step_num 125\n",
      "episode 497, reward 192.0, memory_length 2000, epsilon 0.7061624279377217 total_time 723.0 step_num 132\n",
      "episode 498, reward -136.0, memory_length 2000, epsilon 0.7056682872075981 total_time 722.0 step_num 129\n",
      "episode 499, reward -109.0, memory_length 2000, epsilon 0.7051744922549495 total_time 722.0 step_num 132\n",
      "episode 500, reward 150.0, memory_length 2000, epsilon 0.7046810428378163 total_time 726.0 step_num 121\n",
      "episode 501, reward 94.0, memory_length 2000, epsilon 0.7041879387144081 total_time 721.0 step_num 128\n",
      "episode 502, reward -443.0, memory_length 2000, epsilon 0.7036951796431039 total_time 724.0 step_num 127\n",
      "episode 503, reward 30.0, memory_length 2000, epsilon 0.7032027653824519 total_time 723.0 step_num 140\n",
      "episode 504, reward -49.0, memory_length 2000, epsilon 0.702710695691169 total_time 728.0 step_num 116\n",
      "episode 505, reward -59.0, memory_length 2000, epsilon 0.702218970328141 total_time 721.0 step_num 121\n",
      "episode 506, reward -91.0, memory_length 2000, epsilon 0.7017275890524226 total_time 731.0 step_num 152\n",
      "episode 507, reward 202.0, memory_length 2000, epsilon 0.7012365516232367 total_time 721.0 step_num 130\n",
      "episode 508, reward 121.0, memory_length 2000, epsilon 0.7007458577999753 total_time 721.0 step_num 121\n",
      "episode 509, reward -19.0, memory_length 2000, epsilon 0.7002555073421982 total_time 722.0 step_num 103\n",
      "episode 510, reward 143.0, memory_length 2000, epsilon 0.6997655000096337 total_time 722.0 step_num 119\n",
      "episode 511, reward 147.0, memory_length 2000, epsilon 0.6992758355621782 total_time 723.0 step_num 122\n",
      "episode 512, reward 89.0, memory_length 2000, epsilon 0.6987865137598961 total_time 722.0 step_num 126\n",
      "episode 513, reward 233.0, memory_length 2000, epsilon 0.6982975343630197 total_time 722.0 step_num 123\n",
      "episode 514, reward 226.0, memory_length 2000, epsilon 0.6978088971319493 total_time 727.0 step_num 108\n",
      "episode 515, reward -237.0, memory_length 2000, epsilon 0.6973206018272523 total_time 726.0 step_num 123\n",
      "episode 516, reward -456.0, memory_length 2000, epsilon 0.6968326482096641 total_time 723.0 step_num 102\n",
      "episode 517, reward 66.0, memory_length 2000, epsilon 0.6963450360400875 total_time 723.0 step_num 125\n",
      "episode 518, reward -84.0, memory_length 2000, epsilon 0.6958577650795925 total_time 726.0 step_num 144\n",
      "episode 519, reward -190.0, memory_length 2000, epsilon 0.6953708350894163 total_time 722.0 step_num 142\n",
      "episode 520, reward 148.0, memory_length 2000, epsilon 0.6948842458309632 total_time 721.0 step_num 122\n",
      "episode 521, reward -44.0, memory_length 2000, epsilon 0.6943979970658045 total_time 736.0 step_num 119\n",
      "episode 522, reward 33.0, memory_length 2000, epsilon 0.6939120885556783 total_time 726.0 step_num 134\n",
      "episode 523, reward 161.0, memory_length 2000, epsilon 0.6934265200624893 total_time 722.0 step_num 143\n",
      "episode 524, reward -37.0, memory_length 2000, epsilon 0.6929412913483091 total_time 722.0 step_num 136\n",
      "episode 525, reward 63.0, memory_length 2000, epsilon 0.6924564021753754 total_time 729.0 step_num 129\n",
      "episode 526, reward -46.0, memory_length 2000, epsilon 0.6919718523060926 total_time 722.0 step_num 124\n",
      "episode 527, reward 434.0, memory_length 2000, epsilon 0.6914876415030313 total_time 725.0 step_num 123\n",
      "episode 528, reward 127.0, memory_length 2000, epsilon 0.6910037695289283 total_time 727.0 step_num 132\n",
      "episode 529, reward 341.0, memory_length 2000, epsilon 0.6905202361466861 total_time 722.0 step_num 140\n",
      "episode 530, reward 74.0, memory_length 2000, epsilon 0.6900370411193735 total_time 725.0 step_num 134\n",
      "episode 531, reward -197.0, memory_length 2000, epsilon 0.6895541842102249 total_time 727.0 step_num 129\n",
      "episode 532, reward 113.0, memory_length 2000, epsilon 0.6890716651826402 total_time 728.0 step_num 126\n",
      "episode 533, reward 52.0, memory_length 2000, epsilon 0.6885894838001853 total_time 724.0 step_num 136\n",
      "episode 534, reward 8.0, memory_length 2000, epsilon 0.6881076398265912 total_time 722.0 step_num 136\n",
      "episode 535, reward 60.0, memory_length 2000, epsilon 0.6876261330257543 total_time 726.0 step_num 131\n",
      "episode 536, reward 130.0, memory_length 2000, epsilon 0.6871449631617365 total_time 721.0 step_num 120\n",
      "episode 537, reward 56.0, memory_length 2000, epsilon 0.6866641299987642 total_time 725.0 step_num 109\n",
      "episode 538, reward -154.0, memory_length 2000, epsilon 0.6861836333012296 total_time 722.0 step_num 129\n",
      "episode 539, reward -289.0, memory_length 2000, epsilon 0.685703472833689 total_time 722.0 step_num 138\n",
      "episode 540, reward 371.0, memory_length 2000, epsilon 0.6852236483608637 total_time 725.0 step_num 138\n",
      "episode 541, reward 206.0, memory_length 2000, epsilon 0.6847441596476399 total_time 722.0 step_num 129\n",
      "episode 542, reward 145.0, memory_length 2000, epsilon 0.684265006459068 total_time 736.0 step_num 127\n",
      "episode 543, reward -50.0, memory_length 2000, epsilon 0.6837861885603628 total_time 721.0 step_num 123\n",
      "episode 544, reward 237.0, memory_length 2000, epsilon 0.6833077057169038 total_time 723.0 step_num 141\n",
      "episode 545, reward -101.0, memory_length 2000, epsilon 0.6828295576942343 total_time 724.0 step_num 131\n",
      "episode 546, reward 113.0, memory_length 2000, epsilon 0.6823517442580618 total_time 728.0 step_num 123\n",
      "episode 547, reward -320.0, memory_length 2000, epsilon 0.6818742651742574 total_time 721.0 step_num 123\n",
      "episode 548, reward -28.0, memory_length 2000, epsilon 0.6813971202088568 total_time 722.0 step_num 125\n",
      "episode 549, reward -23.0, memory_length 2000, epsilon 0.6809203091280587 total_time 721.0 step_num 130\n",
      "episode 550, reward -53.0, memory_length 2000, epsilon 0.6804438316982256 total_time 727.0 step_num 133\n",
      "episode 551, reward 162.0, memory_length 2000, epsilon 0.6799676876858838 total_time 729.0 step_num 124\n",
      "episode 552, reward -141.0, memory_length 2000, epsilon 0.6794918768577224 total_time 723.0 step_num 127\n",
      "episode 553, reward 41.0, memory_length 2000, epsilon 0.6790163989805943 total_time 728.0 step_num 132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 554, reward -51.0, memory_length 2000, epsilon 0.6785412538215153 total_time 723.0 step_num 117\n",
      "episode 555, reward -277.0, memory_length 2000, epsilon 0.6780664411476643 total_time 725.0 step_num 113\n",
      "episode 556, reward 272.0, memory_length 2000, epsilon 0.6775919607263831 total_time 725.0 step_num 136\n",
      "episode 557, reward 279.0, memory_length 2000, epsilon 0.6771178123251761 total_time 729.0 step_num 134\n",
      "episode 558, reward 139.0, memory_length 2000, epsilon 0.6766439957117106 total_time 721.0 step_num 111\n",
      "episode 559, reward 125.0, memory_length 2000, epsilon 0.6761705106538167 total_time 722.0 step_num 131\n",
      "episode 560, reward 172.0, memory_length 2000, epsilon 0.6756973569194864 total_time 727.0 step_num 122\n",
      "episode 561, reward 255.0, memory_length 2000, epsilon 0.6752245342768747 total_time 723.0 step_num 113\n",
      "episode 562, reward -12.0, memory_length 2000, epsilon 0.6747520424942982 total_time 726.0 step_num 140\n",
      "episode 563, reward -124.0, memory_length 2000, epsilon 0.674279881340236 total_time 725.0 step_num 138\n",
      "episode 564, reward -347.0, memory_length 2000, epsilon 0.6738080505833292 total_time 721.0 step_num 140\n",
      "episode 565, reward -229.0, memory_length 2000, epsilon 0.6733365499923807 total_time 728.0 step_num 116\n",
      "episode 566, reward 75.0, memory_length 2000, epsilon 0.672865379336355 total_time 723.0 step_num 128\n",
      "episode 567, reward -48.0, memory_length 2000, epsilon 0.6723945383843788 total_time 726.0 step_num 126\n",
      "episode 568, reward 96.0, memory_length 2000, epsilon 0.6719240269057398 total_time 726.0 step_num 119\n",
      "episode 569, reward 58.0, memory_length 2000, epsilon 0.6714538446698874 total_time 721.0 step_num 124\n",
      "episode 570, reward -103.0, memory_length 2000, epsilon 0.6709839914464324 total_time 728.0 step_num 134\n",
      "episode 571, reward -100.0, memory_length 2000, epsilon 0.6705144670051465 total_time 731.0 step_num 126\n",
      "episode 572, reward -203.0, memory_length 2000, epsilon 0.6700452711159631 total_time 721.0 step_num 131\n",
      "episode 573, reward 67.0, memory_length 2000, epsilon 0.6695764035489757 total_time 721.0 step_num 128\n",
      "episode 574, reward -113.0, memory_length 2000, epsilon 0.6691078640744396 total_time 721.0 step_num 126\n",
      "episode 575, reward 53.0, memory_length 2000, epsilon 0.6686396524627702 total_time 722.0 step_num 116\n",
      "episode 576, reward 187.0, memory_length 2000, epsilon 0.6681717684845438 total_time 724.0 step_num 130\n",
      "episode 577, reward -23.0, memory_length 2000, epsilon 0.6677042119104976 total_time 721.0 step_num 132\n",
      "episode 578, reward 652.0, memory_length 2000, epsilon 0.6672369825115283 total_time 730.0 step_num 127\n",
      "episode 579, reward 321.0, memory_length 2000, epsilon 0.6667700800586939 total_time 726.0 step_num 131\n",
      "episode 580, reward 57.0, memory_length 2000, epsilon 0.6663035043232122 total_time 723.0 step_num 127\n",
      "episode 581, reward 112.0, memory_length 2000, epsilon 0.6658372550764607 total_time 721.0 step_num 123\n",
      "episode 582, reward 150.0, memory_length 2000, epsilon 0.6653713320899777 total_time 726.0 step_num 137\n",
      "episode 583, reward 13.0, memory_length 2000, epsilon 0.6649057351354607 total_time 721.0 step_num 135\n",
      "episode 584, reward 35.0, memory_length 2000, epsilon 0.6644404639847671 total_time 722.0 step_num 122\n",
      "episode 585, reward 2.0, memory_length 2000, epsilon 0.6639755184099142 total_time 725.0 step_num 119\n",
      "episode 586, reward -210.0, memory_length 2000, epsilon 0.6635108981830787 total_time 726.0 step_num 140\n",
      "episode 587, reward 56.0, memory_length 2000, epsilon 0.6630466030765966 total_time 725.0 step_num 132\n",
      "episode 588, reward 64.0, memory_length 2000, epsilon 0.6625826328629632 total_time 727.0 step_num 131\n",
      "episode 589, reward -150.0, memory_length 2000, epsilon 0.6621189873148332 total_time 723.0 step_num 126\n",
      "episode 590, reward 43.0, memory_length 2000, epsilon 0.66165566620502 total_time 724.0 step_num 128\n",
      "episode 591, reward 7.0, memory_length 2000, epsilon 0.6611926693064968 total_time 733.0 step_num 123\n",
      "episode 592, reward -3.0, memory_length 2000, epsilon 0.6607299963923947 total_time 726.0 step_num 125\n",
      "episode 593, reward -158.0, memory_length 2000, epsilon 0.660267647236004 total_time 721.0 step_num 128\n",
      "episode 594, reward 12.0, memory_length 2000, epsilon 0.6598056216107737 total_time 732.0 step_num 123\n",
      "episode 595, reward 286.0, memory_length 2000, epsilon 0.6593439192903112 total_time 724.0 step_num 133\n",
      "episode 596, reward -23.0, memory_length 2000, epsilon 0.6588825400483822 total_time 721.0 step_num 133\n",
      "episode 597, reward 75.0, memory_length 2000, epsilon 0.6584214836589112 total_time 732.0 step_num 118\n",
      "episode 598, reward -169.0, memory_length 2000, epsilon 0.6579607498959803 total_time 725.0 step_num 125\n",
      "episode 599, reward -74.0, memory_length 2000, epsilon 0.6575003385338298 total_time 724.0 step_num 143\n",
      "episode 600, reward 94.0, memory_length 2000, epsilon 0.6570402493468587 total_time 721.0 step_num 126\n",
      "episode 601, reward 202.0, memory_length 2000, epsilon 0.6565804821096227 total_time 721.0 step_num 131\n",
      "episode 602, reward -25.0, memory_length 2000, epsilon 0.6561210365968362 total_time 725.0 step_num 135\n",
      "episode 603, reward -22.0, memory_length 2000, epsilon 0.6556619125833707 total_time 728.0 step_num 145\n",
      "episode 604, reward 12.0, memory_length 2000, epsilon 0.6552031098442554 total_time 723.0 step_num 131\n",
      "episode 605, reward -23.0, memory_length 2000, epsilon 0.6547446281546772 total_time 730.0 step_num 130\n",
      "episode 606, reward 323.0, memory_length 2000, epsilon 0.6542864672899797 total_time 722.0 step_num 128\n",
      "episode 607, reward 382.0, memory_length 2000, epsilon 0.6538286270256644 total_time 730.0 step_num 122\n",
      "episode 608, reward 246.0, memory_length 2000, epsilon 0.6533711071373893 total_time 723.0 step_num 137\n",
      "episode 609, reward 136.0, memory_length 2000, epsilon 0.6529139074009699 total_time 727.0 step_num 121\n",
      "episode 610, reward -97.0, memory_length 2000, epsilon 0.6524570275923782 total_time 725.0 step_num 119\n",
      "episode 611, reward 55.0, memory_length 2000, epsilon 0.6520004674877431 total_time 727.0 step_num 135\n",
      "episode 612, reward 20.0, memory_length 2000, epsilon 0.65154422686335 total_time 725.0 step_num 134\n",
      "episode 613, reward -195.0, memory_length 2000, epsilon 0.6510883054956411 total_time 723.0 step_num 126\n",
      "episode 614, reward -139.0, memory_length 2000, epsilon 0.6506327031612149 total_time 728.0 step_num 133\n",
      "episode 615, reward 80.0, memory_length 2000, epsilon 0.6501774196368265 total_time 722.0 step_num 141\n",
      "episode 616, reward 85.0, memory_length 2000, epsilon 0.6497224546993865 total_time 721.0 step_num 132\n",
      "episode 617, reward 454.0, memory_length 2000, epsilon 0.6492678081259623 total_time 721.0 step_num 136\n",
      "episode 618, reward 256.0, memory_length 2000, epsilon 0.6488134796937772 total_time 721.0 step_num 132\n",
      "episode 619, reward 356.0, memory_length 2000, epsilon 0.64835946918021 total_time 728.0 step_num 120\n",
      "episode 620, reward -102.0, memory_length 2000, epsilon 0.6479057763627958 total_time 726.0 step_num 123\n",
      "episode 621, reward -114.0, memory_length 2000, epsilon 0.647452401019225 total_time 723.0 step_num 131\n",
      "episode 622, reward -46.0, memory_length 2000, epsilon 0.6469993429273435 total_time 722.0 step_num 136\n",
      "episode 623, reward 80.0, memory_length 2000, epsilon 0.646546601865153 total_time 722.0 step_num 135\n",
      "episode 624, reward 76.0, memory_length 2000, epsilon 0.6460941776108104 total_time 721.0 step_num 121\n",
      "episode 625, reward 127.0, memory_length 2000, epsilon 0.6456420699426278 total_time 727.0 step_num 111\n",
      "episode 626, reward -28.0, memory_length 2000, epsilon 0.6451902786390723 total_time 722.0 step_num 138\n",
      "episode 627, reward -55.0, memory_length 2000, epsilon 0.6447388034787663 total_time 722.0 step_num 120\n",
      "episode 628, reward 160.0, memory_length 2000, epsilon 0.6442876442404869 total_time 733.0 step_num 124\n",
      "episode 629, reward -29.0, memory_length 2000, epsilon 0.6438368007031661 total_time 724.0 step_num 131\n",
      "episode 630, reward 222.0, memory_length 2000, epsilon 0.6433862726458905 total_time 726.0 step_num 134\n",
      "episode 631, reward 121.0, memory_length 2000, epsilon 0.6429360598479014 total_time 721.0 step_num 120\n",
      "episode 632, reward 170.0, memory_length 2000, epsilon 0.6424861620885944 total_time 722.0 step_num 131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 633, reward 29.0, memory_length 2000, epsilon 0.6420365791475197 total_time 725.0 step_num 142\n",
      "episode 634, reward -112.0, memory_length 2000, epsilon 0.6415873108043817 total_time 728.0 step_num 126\n",
      "episode 635, reward 279.0, memory_length 2000, epsilon 0.6411383568390387 total_time 729.0 step_num 123\n",
      "episode 636, reward 526.0, memory_length 2000, epsilon 0.6406897170315036 total_time 721.0 step_num 125\n",
      "episode 637, reward 129.0, memory_length 2000, epsilon 0.6402413911619425 total_time 732.0 step_num 125\n",
      "episode 638, reward 187.0, memory_length 2000, epsilon 0.6397933790106759 total_time 733.0 step_num 132\n",
      "episode 639, reward 188.0, memory_length 2000, epsilon 0.6393456803581778 total_time 722.0 step_num 128\n",
      "episode 640, reward 251.0, memory_length 2000, epsilon 0.638898294985076 total_time 722.0 step_num 139\n",
      "episode 641, reward 102.0, memory_length 2000, epsilon 0.6384512226721513 total_time 723.0 step_num 118\n",
      "episode 642, reward -100.0, memory_length 2000, epsilon 0.6380044632003387 total_time 722.0 step_num 139\n",
      "episode 643, reward 283.0, memory_length 2000, epsilon 0.6375580163507257 total_time 721.0 step_num 125\n",
      "episode 644, reward 20.0, memory_length 2000, epsilon 0.6371118819045535 total_time 725.0 step_num 120\n",
      "episode 645, reward -244.0, memory_length 2000, epsilon 0.6366660596432161 total_time 722.0 step_num 137\n",
      "episode 646, reward -17.0, memory_length 2000, epsilon 0.6362205493482609 total_time 727.0 step_num 118\n",
      "episode 647, reward 346.0, memory_length 2000, epsilon 0.6357753508013875 total_time 721.0 step_num 141\n",
      "episode 648, reward -50.0, memory_length 2000, epsilon 0.6353304637844486 total_time 721.0 step_num 121\n",
      "episode 649, reward 16.0, memory_length 2000, epsilon 0.6348858880794498 total_time 724.0 step_num 126\n",
      "episode 650, reward 29.0, memory_length 2000, epsilon 0.6344416234685488 total_time 725.0 step_num 133\n",
      "episode 651, reward 192.0, memory_length 2000, epsilon 0.6339976697340559 total_time 723.0 step_num 134\n",
      "episode 652, reward 180.0, memory_length 2000, epsilon 0.633554026658434 total_time 729.0 step_num 130\n",
      "episode 653, reward 185.0, memory_length 2000, epsilon 0.6331106940242978 total_time 728.0 step_num 128\n",
      "episode 654, reward -149.0, memory_length 2000, epsilon 0.6326676716144144 total_time 721.0 step_num 130\n",
      "episode 655, reward 143.0, memory_length 2000, epsilon 0.6322249592117026 total_time 722.0 step_num 122\n",
      "episode 656, reward 213.0, memory_length 2000, epsilon 0.6317825565992335 total_time 726.0 step_num 121\n",
      "episode 657, reward 188.0, memory_length 2000, epsilon 0.6313404635602299 total_time 722.0 step_num 110\n",
      "episode 658, reward 73.0, memory_length 2000, epsilon 0.6308986798780659 total_time 727.0 step_num 127\n",
      "episode 659, reward 52.0, memory_length 2000, epsilon 0.6304572053362678 total_time 724.0 step_num 122\n",
      "episode 660, reward 21.0, memory_length 2000, epsilon 0.6300160397185128 total_time 732.0 step_num 134\n",
      "episode 661, reward 54.0, memory_length 2000, epsilon 0.6295751828086301 total_time 729.0 step_num 148\n",
      "episode 662, reward 287.0, memory_length 2000, epsilon 0.6291346343905994 total_time 722.0 step_num 131\n",
      "episode 663, reward 208.0, memory_length 2000, epsilon 0.6286943942485522 total_time 727.0 step_num 131\n",
      "episode 664, reward 491.0, memory_length 2000, epsilon 0.6282544621667707 total_time 728.0 step_num 123\n",
      "episode 665, reward 187.0, memory_length 2000, epsilon 0.6278148379296883 total_time 724.0 step_num 131\n",
      "episode 666, reward 102.0, memory_length 2000, epsilon 0.627375521321889 total_time 723.0 step_num 113\n",
      "episode 667, reward 280.0, memory_length 2000, epsilon 0.6269365121281076 total_time 727.0 step_num 146\n",
      "episode 668, reward 155.0, memory_length 2000, epsilon 0.6264978101332298 total_time 725.0 step_num 126\n",
      "episode 669, reward 29.0, memory_length 2000, epsilon 0.6260594151222916 total_time 725.0 step_num 116\n",
      "episode 670, reward -146.0, memory_length 2000, epsilon 0.6256213268804792 total_time 724.0 step_num 145\n",
      "episode 671, reward 62.0, memory_length 2000, epsilon 0.6251835451931295 total_time 722.0 step_num 132\n",
      "episode 672, reward 94.0, memory_length 2000, epsilon 0.6247460698457294 total_time 721.0 step_num 137\n",
      "episode 673, reward 79.0, memory_length 2000, epsilon 0.6243089006239162 total_time 733.0 step_num 125\n",
      "episode 674, reward 39.0, memory_length 2000, epsilon 0.6238720373134766 total_time 723.0 step_num 124\n",
      "episode 675, reward 74.0, memory_length 2000, epsilon 0.6234354797003481 total_time 725.0 step_num 123\n",
      "episode 676, reward -59.0, memory_length 2000, epsilon 0.6229992275706168 total_time 721.0 step_num 131\n",
      "episode 677, reward -23.0, memory_length 2000, epsilon 0.6225632807105195 total_time 721.0 step_num 141\n",
      "episode 678, reward 340.0, memory_length 2000, epsilon 0.6221276389064423 total_time 724.0 step_num 114\n",
      "episode 679, reward 175.0, memory_length 2000, epsilon 0.6216923019449205 total_time 721.0 step_num 134\n",
      "episode 680, reward 238.0, memory_length 2000, epsilon 0.6212572696126393 total_time 721.0 step_num 133\n",
      "episode 681, reward -199.0, memory_length 2000, epsilon 0.6208225416964324 total_time 731.0 step_num 122\n",
      "episode 682, reward 386.0, memory_length 2000, epsilon 0.6203881179832835 total_time 722.0 step_num 122\n",
      "episode 683, reward -118.0, memory_length 2000, epsilon 0.6199539982603248 total_time 722.0 step_num 132\n",
      "episode 684, reward 149.0, memory_length 2000, epsilon 0.6195201823148376 total_time 728.0 step_num 120\n",
      "episode 685, reward 96.0, memory_length 2000, epsilon 0.6190866699342522 total_time 726.0 step_num 119\n",
      "episode 686, reward -212.0, memory_length 2000, epsilon 0.6186534609061475 total_time 721.0 step_num 118\n",
      "episode 687, reward 77.0, memory_length 2000, epsilon 0.6182205550182509 total_time 728.0 step_num 114\n",
      "episode 688, reward -291.0, memory_length 2000, epsilon 0.6177879520584387 total_time 726.0 step_num 119\n",
      "episode 689, reward 112.0, memory_length 2000, epsilon 0.6173556518147354 total_time 730.0 step_num 129\n",
      "episode 690, reward 62.0, memory_length 2000, epsilon 0.6169236540753137 total_time 722.0 step_num 117\n",
      "episode 691, reward 218.0, memory_length 2000, epsilon 0.6164919586284949 total_time 725.0 step_num 117\n",
      "episode 692, reward 202.0, memory_length 2000, epsilon 0.6160605652627483 total_time 730.0 step_num 118\n",
      "episode 693, reward 112.0, memory_length 2000, epsilon 0.6156294737666909 total_time 721.0 step_num 116\n",
      "episode 694, reward -93.0, memory_length 2000, epsilon 0.6151986839290879 total_time 726.0 step_num 113\n",
      "episode 695, reward 264.0, memory_length 2000, epsilon 0.6147681955388524 total_time 723.0 step_num 109\n",
      "episode 696, reward 80.0, memory_length 2000, epsilon 0.6143380083850449 total_time 722.0 step_num 120\n",
      "episode 697, reward 146.0, memory_length 2000, epsilon 0.6139081222568741 total_time 725.0 step_num 123\n",
      "episode 698, reward -244.0, memory_length 2000, epsilon 0.6134785369436953 total_time 722.0 step_num 119\n",
      "episode 699, reward 97.0, memory_length 2000, epsilon 0.6130492522350118 total_time 724.0 step_num 121\n",
      "episode 700, reward 121.0, memory_length 2000, epsilon 0.6126202679204743 total_time 721.0 step_num 120\n",
      "episode 701, reward 256.0, memory_length 2000, epsilon 0.6121915837898803 total_time 721.0 step_num 130\n",
      "episode 702, reward 166.0, memory_length 2000, epsilon 0.6117631996331745 total_time 721.0 step_num 139\n",
      "episode 703, reward 58.0, memory_length 2000, epsilon 0.6113351152404488 total_time 721.0 step_num 129\n",
      "episode 704, reward 183.0, memory_length 2000, epsilon 0.6109073304019419 total_time 723.0 step_num 139\n",
      "episode 705, reward 105.0, memory_length 2000, epsilon 0.610479844908039 total_time 726.0 step_num 135\n",
      "episode 706, reward -212.0, memory_length 2000, epsilon 0.6100526585492725 total_time 721.0 step_num 106\n",
      "episode 707, reward -122.0, memory_length 2000, epsilon 0.6096257711163208 total_time 730.0 step_num 129\n",
      "episode 708, reward -57.0, memory_length 2000, epsilon 0.609199182400009 total_time 726.0 step_num 135\n",
      "episode 709, reward -14.0, memory_length 2000, epsilon 0.6087728921913089 total_time 721.0 step_num 127\n",
      "episode 710, reward -132.0, memory_length 2000, epsilon 0.6083469002813382 total_time 723.0 step_num 111\n",
      "episode 711, reward 212.0, memory_length 2000, epsilon 0.6079212064613607 total_time 728.0 step_num 129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 712, reward 8.0, memory_length 2000, epsilon 0.6074958105227866 total_time 722.0 step_num 126\n",
      "episode 713, reward 17.0, memory_length 2000, epsilon 0.6070707122571718 total_time 722.0 step_num 127\n",
      "episode 714, reward -203.0, memory_length 2000, epsilon 0.6066459114562182 total_time 721.0 step_num 135\n",
      "episode 715, reward 150.0, memory_length 2000, epsilon 0.6062214079117734 total_time 726.0 step_num 128\n",
      "episode 716, reward 208.0, memory_length 2000, epsilon 0.6057972014158304 total_time 727.0 step_num 132\n",
      "episode 717, reward -220.0, memory_length 2000, epsilon 0.6053732917605282 total_time 728.0 step_num 134\n",
      "episode 718, reward -28.0, memory_length 2000, epsilon 0.6049496787381513 total_time 722.0 step_num 129\n",
      "episode 719, reward -32.0, memory_length 2000, epsilon 0.604526362141129 total_time 721.0 step_num 126\n",
      "episode 720, reward -10.0, memory_length 2000, epsilon 0.6041033417620362 total_time 722.0 step_num 110\n",
      "episode 721, reward -90.0, memory_length 2000, epsilon 0.6036806173935929 total_time 729.0 step_num 114\n",
      "episode 722, reward -194.0, memory_length 2000, epsilon 0.6032581888286643 total_time 730.0 step_num 117\n",
      "episode 723, reward 4.0, memory_length 2000, epsilon 0.6028360558602603 total_time 721.0 step_num 114\n",
      "episode 724, reward -112.0, memory_length 2000, epsilon 0.6024142182815357 total_time 728.0 step_num 126\n",
      "episode 725, reward 75.0, memory_length 2000, epsilon 0.6019926758857902 total_time 723.0 step_num 140\n",
      "episode 726, reward 194.0, memory_length 2000, epsilon 0.6015714284664678 total_time 728.0 step_num 127\n",
      "episode 727, reward 157.0, memory_length 2000, epsilon 0.6011504758171574 total_time 721.0 step_num 117\n",
      "episode 728, reward -150.0, memory_length 2000, epsilon 0.6007298177315923 total_time 723.0 step_num 133\n",
      "episode 729, reward 48.0, memory_length 2000, epsilon 0.6003094540036498 total_time 723.0 step_num 119\n",
      "episode 730, reward 40.0, memory_length 2000, epsilon 0.5998893844273517 total_time 721.0 step_num 128\n",
      "episode 731, reward 328.0, memory_length 2000, epsilon 0.5994696087968641 total_time 721.0 step_num 134\n",
      "episode 732, reward 229.0, memory_length 2000, epsilon 0.5990501269064967 total_time 721.0 step_num 135\n",
      "episode 733, reward 40.0, memory_length 2000, epsilon 0.5986309385507036 total_time 721.0 step_num 140\n",
      "episode 734, reward -73.0, memory_length 2000, epsilon 0.5982120435240822 total_time 722.0 step_num 134\n",
      "episode 735, reward -100.0, memory_length 2000, epsilon 0.5977934416213744 total_time 722.0 step_num 120\n",
      "episode 736, reward -174.0, memory_length 2000, epsilon 0.5973751326374647 total_time 726.0 step_num 127\n",
      "episode 737, reward -113.0, memory_length 2000, epsilon 0.5969571163673819 total_time 721.0 step_num 126\n",
      "episode 738, reward -21.0, memory_length 2000, epsilon 0.5965393926062983 total_time 726.0 step_num 121\n",
      "episode 739, reward 27.0, memory_length 2000, epsilon 0.5961219611495288 total_time 729.0 step_num 120\n",
      "episode 740, reward 341.0, memory_length 2000, epsilon 0.5957048217925323 total_time 722.0 step_num 132\n",
      "episode 741, reward 317.0, memory_length 2000, epsilon 0.5952879743309103 total_time 725.0 step_num 126\n",
      "episode 742, reward 166.0, memory_length 2000, epsilon 0.5948714185604077 total_time 721.0 step_num 130\n",
      "episode 743, reward -92.0, memory_length 2000, epsilon 0.5944551542769121 total_time 724.0 step_num 126\n",
      "episode 744, reward -178.0, memory_length 2000, epsilon 0.5940391812764539 total_time 725.0 step_num 109\n",
      "episode 745, reward 118.0, memory_length 2000, epsilon 0.5936234993552065 total_time 727.0 step_num 128\n",
      "episode 746, reward 390.0, memory_length 2000, epsilon 0.5932081083094858 total_time 723.0 step_num 124\n",
      "episode 747, reward 214.0, memory_length 2000, epsilon 0.5927930079357497 total_time 724.0 step_num 120\n",
      "episode 748, reward -82.0, memory_length 2000, epsilon 0.5923781980305998 total_time 722.0 step_num 131\n",
      "episode 749, reward 62.0, memory_length 2000, epsilon 0.5919636783907785 total_time 731.0 step_num 140\n",
      "episode 750, reward 274.0, memory_length 2000, epsilon 0.5915494488131715 total_time 721.0 step_num 144\n",
      "episode 751, reward -56.0, memory_length 2000, epsilon 0.5911355090948063 total_time 724.0 step_num 126\n",
      "episode 752, reward -32.0, memory_length 2000, epsilon 0.5907218590328522 total_time 721.0 step_num 128\n",
      "episode 753, reward 124.0, memory_length 2000, epsilon 0.5903084984246211 total_time 724.0 step_num 134\n",
      "episode 754, reward 445.0, memory_length 2000, epsilon 0.5898954270675658 total_time 721.0 step_num 136\n",
      "episode 755, reward 368.0, memory_length 2000, epsilon 0.5894826447592818 total_time 731.0 step_num 128\n",
      "episode 756, reward 62.0, memory_length 2000, epsilon 0.5890701512975053 total_time 722.0 step_num 141\n",
      "episode 757, reward 409.0, memory_length 2000, epsilon 0.5886579464801148 total_time 721.0 step_num 122\n",
      "episode 758, reward -64.0, memory_length 2000, epsilon 0.5882460301051299 total_time 722.0 step_num 140\n",
      "episode 759, reward -86.0, memory_length 2000, epsilon 0.5878344019707115 total_time 721.0 step_num 138\n",
      "episode 760, reward 382.0, memory_length 2000, epsilon 0.5874230618751618 total_time 739.0 step_num 132\n",
      "episode 761, reward -176.0, memory_length 2000, epsilon 0.5870120096169242 total_time 721.0 step_num 130\n",
      "episode 762, reward 256.0, memory_length 2000, epsilon 0.5866012449945831 total_time 721.0 step_num 124\n",
      "episode 763, reward 202.0, memory_length 2000, epsilon 0.5861907678068637 total_time 721.0 step_num 133\n",
      "episode 764, reward -31.0, memory_length 2000, epsilon 0.5857805778526324 total_time 737.0 step_num 132\n",
      "episode 765, reward 217.0, memory_length 2000, epsilon 0.5853706749308958 total_time 727.0 step_num 122\n",
      "episode 766, reward 31.0, memory_length 2000, epsilon 0.5849610588408016 total_time 730.0 step_num 105\n",
      "episode 767, reward 97.0, memory_length 2000, epsilon 0.5845517293816381 total_time 724.0 step_num 141\n",
      "episode 768, reward 45.0, memory_length 2000, epsilon 0.5841426863528336 total_time 729.0 step_num 116\n",
      "episode 769, reward 116.0, memory_length 2000, epsilon 0.5837339295539572 total_time 722.0 step_num 106\n",
      "episode 770, reward 171.0, memory_length 2000, epsilon 0.5833254587847179 total_time 729.0 step_num 128\n",
      "episode 771, reward 30.0, memory_length 2000, epsilon 0.5829172738449651 total_time 723.0 step_num 128\n",
      "episode 772, reward 245.0, memory_length 2000, epsilon 0.582509374534688 total_time 725.0 step_num 132\n",
      "episode 773, reward 185.0, memory_length 2000, epsilon 0.5821017606540162 total_time 728.0 step_num 133\n",
      "episode 774, reward 134.0, memory_length 2000, epsilon 0.5816944320032188 total_time 722.0 step_num 124\n",
      "episode 775, reward -59.0, memory_length 2000, epsilon 0.5812873883827048 total_time 721.0 step_num 135\n",
      "episode 776, reward -105.0, memory_length 2000, epsilon 0.5808806295930226 total_time 723.0 step_num 117\n",
      "episode 777, reward -43.0, memory_length 2000, epsilon 0.5804741554348605 total_time 725.0 step_num 134\n",
      "episode 778, reward -284.0, memory_length 2000, epsilon 0.5800679657090462 total_time 721.0 step_num 129\n",
      "episode 779, reward 339.0, memory_length 2000, epsilon 0.5796620602165466 total_time 726.0 step_num 115\n",
      "episode 780, reward 157.0, memory_length 2000, epsilon 0.5792564387584682 total_time 721.0 step_num 123\n",
      "episode 781, reward -187.0, memory_length 2000, epsilon 0.5788511011360565 total_time 725.0 step_num 113\n",
      "episode 782, reward 76.0, memory_length 2000, epsilon 0.5784460471506958 total_time 721.0 step_num 122\n",
      "episode 783, reward 4.0, memory_length 2000, epsilon 0.5780412766039098 total_time 721.0 step_num 132\n",
      "episode 784, reward 130.0, memory_length 2000, epsilon 0.577636789297361 total_time 721.0 step_num 131\n",
      "episode 785, reward 39.0, memory_length 2000, epsilon 0.5772325850328504 total_time 723.0 step_num 124\n",
      "episode 786, reward 248.0, memory_length 2000, epsilon 0.576828663612318 total_time 728.0 step_num 136\n",
      "episode 787, reward -26.0, memory_length 2000, epsilon 0.5764250248378424 total_time 727.0 step_num 128\n",
      "episode 788, reward 90.0, memory_length 2000, epsilon 0.5760216685116405 total_time 729.0 step_num 123\n",
      "episode 789, reward -138.0, memory_length 2000, epsilon 0.5756185944360677 total_time 726.0 step_num 122\n",
      "episode 790, reward 338.0, memory_length 2000, epsilon 0.5752158024136176 total_time 728.0 step_num 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 791, reward 375.0, memory_length 2000, epsilon 0.5748132922469222 total_time 726.0 step_num 127\n",
      "episode 792, reward -42.0, memory_length 2000, epsilon 0.5744110637387515 total_time 723.0 step_num 118\n",
      "episode 793, reward 499.0, memory_length 2000, epsilon 0.5740091166920136 total_time 721.0 step_num 124\n",
      "episode 794, reward -66.0, memory_length 2000, epsilon 0.5736074509097544 total_time 726.0 step_num 110\n",
      "episode 795, reward 262.0, memory_length 2000, epsilon 0.5732060661951575 total_time 727.0 step_num 115\n",
      "episode 796, reward 168.0, memory_length 2000, epsilon 0.5728049623515445 total_time 726.0 step_num 124\n",
      "episode 797, reward -1.0, memory_length 2000, epsilon 0.5724041391823748 total_time 731.0 step_num 127\n",
      "episode 798, reward 235.0, memory_length 2000, epsilon 0.5720035964912444 total_time 727.0 step_num 118\n",
      "episode 799, reward -260.0, memory_length 2000, epsilon 0.5716033340818878 total_time 727.0 step_num 125\n",
      "episode 800, reward -16.0, memory_length 2000, epsilon 0.5712033517581764 total_time 725.0 step_num 136\n",
      "episode 801, reward 62.0, memory_length 2000, epsilon 0.5708036493241189 total_time 722.0 step_num 131\n",
      "episode 802, reward 239.0, memory_length 2000, epsilon 0.5704042265838608 total_time 728.0 step_num 124\n",
      "episode 803, reward 22.0, memory_length 2000, epsilon 0.5700050833416851 total_time 721.0 step_num 133\n",
      "episode 804, reward 247.0, memory_length 2000, epsilon 0.5696062194020118 total_time 721.0 step_num 121\n",
      "episode 805, reward 98.0, memory_length 2000, epsilon 0.5692076345693974 total_time 722.0 step_num 115\n",
      "episode 806, reward 318.0, memory_length 2000, epsilon 0.5688093286485352 total_time 732.0 step_num 134\n",
      "episode 807, reward -69.0, memory_length 2000, epsilon 0.5684113014442556 total_time 723.0 step_num 115\n",
      "episode 808, reward 265.0, memory_length 2000, epsilon 0.568013552761525 total_time 721.0 step_num 123\n",
      "episode 809, reward 192.0, memory_length 2000, epsilon 0.5676160824054466 total_time 723.0 step_num 144\n",
      "episode 810, reward 391.0, memory_length 2000, epsilon 0.5672188901812599 total_time 721.0 step_num 113\n",
      "episode 811, reward 283.0, memory_length 2000, epsilon 0.5668219758943408 total_time 721.0 step_num 133\n",
      "episode 812, reward 125.0, memory_length 2000, epsilon 0.5664253393502011 total_time 722.0 step_num 123\n",
      "episode 813, reward -110.0, memory_length 2000, epsilon 0.5660289803544891 total_time 724.0 step_num 122\n",
      "episode 814, reward -122.0, memory_length 2000, epsilon 0.5656328987129889 total_time 721.0 step_num 142\n",
      "episode 815, reward 42.0, memory_length 2000, epsilon 0.5652370942316203 total_time 726.0 step_num 125\n",
      "episode 816, reward -116.0, memory_length 2000, epsilon 0.5648415667164391 total_time 727.0 step_num 129\n",
      "episode 817, reward -86.0, memory_length 2000, epsilon 0.564446315973637 total_time 730.0 step_num 110\n",
      "episode 818, reward 414.0, memory_length 2000, epsilon 0.5640513418095411 total_time 729.0 step_num 127\n",
      "episode 819, reward 30.0, memory_length 2000, epsilon 0.5636566440306138 total_time 723.0 step_num 137\n",
      "episode 820, reward 112.0, memory_length 2000, epsilon 0.5632622224434535 total_time 721.0 step_num 125\n",
      "episode 821, reward -56.0, memory_length 2000, epsilon 0.5628680768547933 total_time 724.0 step_num 126\n",
      "episode 822, reward 12.0, memory_length 2000, epsilon 0.5624742070715022 total_time 723.0 step_num 136\n",
      "episode 823, reward 3.0, memory_length 2000, epsilon 0.5620806129005838 total_time 723.0 step_num 107\n",
      "episode 824, reward 241.0, memory_length 2000, epsilon 0.5616872941491768 total_time 724.0 step_num 109\n",
      "episode 825, reward 7.0, memory_length 2000, epsilon 0.5612942506245553 total_time 724.0 step_num 138\n",
      "episode 826, reward 84.0, memory_length 2000, epsilon 0.5609014821341277 total_time 723.0 step_num 132\n",
      "episode 827, reward 232.0, memory_length 2000, epsilon 0.5605089884854377 total_time 724.0 step_num 134\n",
      "episode 828, reward -222.0, memory_length 2000, epsilon 0.5601167694861633 total_time 723.0 step_num 139\n",
      "episode 829, reward 235.0, memory_length 2000, epsilon 0.5597248249441171 total_time 727.0 step_num 126\n",
      "episode 830, reward 278.0, memory_length 2000, epsilon 0.5593331546672463 total_time 722.0 step_num 124\n",
      "episode 831, reward 149.0, memory_length 2000, epsilon 0.5589417584636325 total_time 728.0 step_num 132\n",
      "episode 832, reward 275.0, memory_length 2000, epsilon 0.5585506361414916 total_time 728.0 step_num 134\n",
      "episode 833, reward 134.0, memory_length 2000, epsilon 0.5581597875091735 total_time 722.0 step_num 134\n",
      "episode 834, reward 54.0, memory_length 2000, epsilon 0.5577692123751624 total_time 729.0 step_num 145\n",
      "episode 835, reward 256.0, memory_length 2000, epsilon 0.5573789105480766 total_time 730.0 step_num 125\n",
      "episode 836, reward 353.0, memory_length 2000, epsilon 0.5569888818366682 total_time 725.0 step_num 138\n",
      "episode 837, reward 47.0, memory_length 2000, epsilon 0.556599126049823 total_time 725.0 step_num 118\n",
      "episode 838, reward 256.0, memory_length 2000, epsilon 0.5562096429965605 total_time 721.0 step_num 128\n",
      "episode 839, reward 544.0, memory_length 2000, epsilon 0.5558204324860344 total_time 730.0 step_num 122\n",
      "episode 840, reward 10.0, memory_length 2000, epsilon 0.5554314943275312 total_time 727.0 step_num 133\n",
      "episode 841, reward -86.0, memory_length 2000, epsilon 0.5550428283304715 total_time 721.0 step_num 129\n",
      "episode 842, reward 247.0, memory_length 2000, epsilon 0.5546544343044087 total_time 721.0 step_num 119\n",
      "episode 843, reward 254.0, memory_length 2000, epsilon 0.5542663120590299 total_time 725.0 step_num 120\n",
      "episode 844, reward -185.0, memory_length 2000, epsilon 0.553878461404155 total_time 721.0 step_num 133\n",
      "episode 845, reward 103.0, memory_length 2000, epsilon 0.5534908821497373 total_time 721.0 step_num 126\n",
      "episode 846, reward 112.0, memory_length 2000, epsilon 0.553103574105863 total_time 721.0 step_num 126\n",
      "episode 847, reward 147.0, memory_length 2000, epsilon 0.5527165370827509 total_time 723.0 step_num 112\n",
      "episode 848, reward 193.0, memory_length 2000, epsilon 0.5523297708907531 total_time 721.0 step_num 116\n",
      "episode 849, reward 255.0, memory_length 2000, epsilon 0.5519432753403541 total_time 723.0 step_num 121\n",
      "episode 850, reward 431.0, memory_length 2000, epsilon 0.5515570502421712 total_time 722.0 step_num 129\n",
      "episode 851, reward 139.0, memory_length 2000, epsilon 0.5511710954069537 total_time 721.0 step_num 115\n",
      "episode 852, reward 313.0, memory_length 2000, epsilon 0.5507854106455842 total_time 724.0 step_num 123\n",
      "episode 853, reward 238.0, memory_length 2000, epsilon 0.5503999957690768 total_time 721.0 step_num 131\n",
      "episode 854, reward 62.0, memory_length 2000, epsilon 0.5500148505885784 total_time 722.0 step_num 122\n",
      "episode 855, reward -4.0, memory_length 2000, epsilon 0.5496299749153677 total_time 728.0 step_num 140\n",
      "episode 856, reward -52.0, memory_length 2000, epsilon 0.5492453685608558 total_time 734.0 step_num 127\n",
      "episode 857, reward 444.0, memory_length 2000, epsilon 0.5488610313365855 total_time 723.0 step_num 130\n",
      "episode 858, reward 196.0, memory_length 2000, epsilon 0.5484769630542315 total_time 724.0 step_num 118\n",
      "episode 859, reward 251.0, memory_length 2000, epsilon 0.5480931635256003 total_time 722.0 step_num 125\n",
      "episode 860, reward -86.0, memory_length 2000, epsilon 0.5477096325626304 total_time 721.0 step_num 133\n",
      "episode 861, reward 14.0, memory_length 2000, epsilon 0.5473263699773913 total_time 728.0 step_num 117\n",
      "episode 862, reward 229.0, memory_length 2000, epsilon 0.5469433755820843 total_time 721.0 step_num 130\n",
      "episode 863, reward 290.0, memory_length 2000, epsilon 0.5465606491890425 total_time 725.0 step_num 149\n",
      "episode 864, reward -29.0, memory_length 2000, epsilon 0.5461781906107295 total_time 724.0 step_num 131\n",
      "episode 865, reward 247.0, memory_length 2000, epsilon 0.545795999659741 total_time 721.0 step_num 117\n",
      "episode 866, reward 272.0, memory_length 2000, epsilon 0.5454140761488033 total_time 725.0 step_num 123\n",
      "episode 867, reward 94.0, memory_length 2000, epsilon 0.5450324198907737 total_time 721.0 step_num 138\n",
      "episode 868, reward 347.0, memory_length 2000, epsilon 0.5446510306986407 total_time 728.0 step_num 123\n",
      "episode 869, reward 139.0, memory_length 2000, epsilon 0.5442699083855239 total_time 730.0 step_num 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 870, reward -43.0, memory_length 2000, epsilon 0.5438890527646728 total_time 725.0 step_num 119\n",
      "episode 871, reward 178.0, memory_length 2000, epsilon 0.5435084636494686 total_time 724.0 step_num 125\n",
      "episode 872, reward 239.0, memory_length 2000, epsilon 0.5431281408534225 total_time 728.0 step_num 134\n",
      "episode 873, reward 175.0, memory_length 2000, epsilon 0.5427480841901762 total_time 721.0 step_num 122\n",
      "episode 874, reward 337.0, memory_length 2000, epsilon 0.542368293473502 total_time 730.0 step_num 118\n",
      "episode 875, reward 340.0, memory_length 2000, epsilon 0.5419887685173026 total_time 724.0 step_num 142\n",
      "episode 876, reward -5.0, memory_length 2000, epsilon 0.5416095091356105 total_time 721.0 step_num 120\n",
      "episode 877, reward 359.0, memory_length 2000, epsilon 0.5412305151425887 total_time 722.0 step_num 119\n",
      "episode 878, reward 89.0, memory_length 2000, epsilon 0.5408517863525302 total_time 722.0 step_num 133\n",
      "episode 879, reward 8.0, memory_length 2000, epsilon 0.5404733225798578 total_time 722.0 step_num 117\n",
      "episode 880, reward 160.0, memory_length 2000, epsilon 0.5400951236391243 total_time 724.0 step_num 126\n",
      "episode 881, reward 166.0, memory_length 2000, epsilon 0.539717189345012 total_time 721.0 step_num 118\n",
      "episode 882, reward 179.0, memory_length 2000, epsilon 0.5393395195123335 total_time 722.0 step_num 126\n",
      "episode 883, reward 337.0, memory_length 2000, epsilon 0.5389621139560303 total_time 721.0 step_num 128\n",
      "episode 884, reward 40.0, memory_length 2000, epsilon 0.5385849724911738 total_time 721.0 step_num 124\n",
      "episode 885, reward 346.0, memory_length 2000, epsilon 0.5382080949329645 total_time 730.0 step_num 128\n",
      "episode 886, reward 170.0, memory_length 2000, epsilon 0.5378314810967325 total_time 722.0 step_num 116\n",
      "episode 887, reward 353.0, memory_length 2000, epsilon 0.5374551307979369 total_time 725.0 step_num 124\n",
      "episode 888, reward 39.0, memory_length 2000, epsilon 0.5370790438521662 total_time 723.0 step_num 120\n",
      "episode 889, reward -54.0, memory_length 2000, epsilon 0.5367032200751378 total_time 729.0 step_num 124\n",
      "episode 890, reward 50.0, memory_length 2000, epsilon 0.536327659282698 total_time 728.0 step_num 138\n",
      "episode 891, reward -68.0, memory_length 2000, epsilon 0.5359523612908219 total_time 721.0 step_num 132\n",
      "episode 892, reward 400.0, memory_length 2000, epsilon 0.5355773259156137 total_time 730.0 step_num 126\n",
      "episode 893, reward 247.0, memory_length 2000, epsilon 0.5352025529733058 total_time 721.0 step_num 114\n",
      "episode 894, reward 289.0, memory_length 2000, epsilon 0.5348280422802596 total_time 727.0 step_num 112\n",
      "episode 895, reward -20.0, memory_length 2000, epsilon 0.5344537936529647 total_time 724.0 step_num 114\n",
      "episode 896, reward 128.0, memory_length 2000, epsilon 0.5340798069080396 total_time 725.0 step_num 121\n",
      "episode 897, reward -133.0, memory_length 2000, epsilon 0.5337060818622303 total_time 725.0 step_num 109\n",
      "episode 898, reward 42.0, memory_length 2000, epsilon 0.533332618332412 total_time 726.0 step_num 132\n",
      "episode 899, reward 85.0, memory_length 2000, epsilon 0.5329594161355873 total_time 721.0 step_num 117\n",
      "episode 900, reward 293.0, memory_length 2000, epsilon 0.5325864750888871 total_time 728.0 step_num 120\n",
      "episode 901, reward 14.0, memory_length 2000, epsilon 0.5322137950095704 total_time 728.0 step_num 112\n",
      "episode 902, reward 124.0, memory_length 2000, epsilon 0.5318413757150239 total_time 733.0 step_num 107\n",
      "episode 903, reward 279.0, memory_length 2000, epsilon 0.5314692170227623 total_time 729.0 step_num 114\n",
      "episode 904, reward -104.0, memory_length 2000, epsilon 0.5310973187504274 total_time 721.0 step_num 107\n",
      "episode 905, reward -50.0, memory_length 2000, epsilon 0.5307256807157895 total_time 721.0 step_num 124\n",
      "episode 906, reward 98.0, memory_length 2000, epsilon 0.5303543027367457 total_time 722.0 step_num 122\n",
      "episode 907, reward 9.0, memory_length 2000, epsilon 0.5299831846313209 total_time 729.0 step_num 120\n",
      "episode 908, reward 157.0, memory_length 2000, epsilon 0.5296123262176672 total_time 721.0 step_num 123\n",
      "episode 909, reward 206.0, memory_length 2000, epsilon 0.5292417273140637 total_time 722.0 step_num 125\n",
      "episode 910, reward 167.0, memory_length 2000, epsilon 0.5288713877389174 total_time 728.0 step_num 118\n",
      "episode 911, reward 4.0, memory_length 2000, epsilon 0.5285013073107616 total_time 730.0 step_num 114\n",
      "episode 912, reward 220.0, memory_length 2000, epsilon 0.5281314858482571 total_time 721.0 step_num 120\n",
      "episode 913, reward 292.0, memory_length 2000, epsilon 0.5277619231701911 total_time 721.0 step_num 137\n",
      "episode 914, reward 31.0, memory_length 2000, epsilon 0.5273926190954781 total_time 730.0 step_num 112\n",
      "episode 915, reward 202.0, memory_length 2000, epsilon 0.5270235734431589 total_time 730.0 step_num 125\n",
      "episode 916, reward 49.0, memory_length 2000, epsilon 0.5266547860324012 total_time 730.0 step_num 128\n",
      "episode 917, reward 120.0, memory_length 2000, epsilon 0.5262862566824993 total_time 723.0 step_num 130\n",
      "episode 918, reward 152.0, memory_length 2000, epsilon 0.5259179852128737 total_time 731.0 step_num 130\n",
      "episode 919, reward 220.0, memory_length 2000, epsilon 0.5255499714430714 total_time 721.0 step_num 118\n",
      "episode 920, reward 345.0, memory_length 2000, epsilon 0.5251822151927655 total_time 732.0 step_num 137\n",
      "episode 921, reward -73.0, memory_length 2000, epsilon 0.5248147162817557 total_time 722.0 step_num 122\n",
      "episode 922, reward 247.0, memory_length 2000, epsilon 0.5244474745299672 total_time 721.0 step_num 131\n",
      "episode 923, reward 246.0, memory_length 2000, epsilon 0.5240804897574518 total_time 723.0 step_num 113\n",
      "episode 924, reward 81.0, memory_length 2000, epsilon 0.5237137617843869 total_time 729.0 step_num 130\n",
      "episode 925, reward -266.0, memory_length 2000, epsilon 0.5233472904310758 total_time 730.0 step_num 120\n",
      "episode 926, reward 2.0, memory_length 2000, epsilon 0.5229810755179474 total_time 725.0 step_num 128\n",
      "episode 927, reward 79.0, memory_length 2000, epsilon 0.5226151168655564 total_time 724.0 step_num 139\n",
      "episode 928, reward 58.0, memory_length 2000, epsilon 0.5222494142945833 total_time 721.0 step_num 130\n",
      "episode 929, reward 153.0, memory_length 2000, epsilon 0.5218839676258336 total_time 729.0 step_num 125\n",
      "episode 930, reward 173.0, memory_length 2000, epsilon 0.5215187766802384 total_time 725.0 step_num 118\n",
      "episode 931, reward -34.0, memory_length 2000, epsilon 0.5211538412788542 total_time 725.0 step_num 123\n",
      "episode 932, reward 121.0, memory_length 2000, epsilon 0.5207891612428627 total_time 721.0 step_num 118\n",
      "episode 933, reward 175.0, memory_length 2000, epsilon 0.5204247363935707 total_time 721.0 step_num 125\n",
      "episode 934, reward -64.0, memory_length 2000, epsilon 0.5200605665524098 total_time 731.0 step_num 120\n",
      "episode 935, reward 75.0, memory_length 2000, epsilon 0.519696651540937 total_time 723.0 step_num 128\n",
      "episode 936, reward 25.0, memory_length 2000, epsilon 0.5193329911808339 total_time 724.0 step_num 123\n",
      "episode 937, reward -86.0, memory_length 2000, epsilon 0.5189695852939067 total_time 721.0 step_num 116\n",
      "episode 938, reward 254.0, memory_length 2000, epsilon 0.5186064337020869 total_time 725.0 step_num 122\n",
      "episode 939, reward -79.0, memory_length 2000, epsilon 0.5182435362274298 total_time 725.0 step_num 114\n",
      "episode 940, reward 432.0, memory_length 2000, epsilon 0.5178808926921159 total_time 729.0 step_num 127\n",
      "episode 941, reward 334.0, memory_length 2000, epsilon 0.5175185029184498 total_time 727.0 step_num 136\n",
      "episode 942, reward -41.0, memory_length 2000, epsilon 0.5171563667288606 total_time 730.0 step_num 119\n",
      "episode 943, reward 103.0, memory_length 2000, epsilon 0.5167944839459012 total_time 721.0 step_num 135\n",
      "episode 944, reward 76.0, memory_length 2000, epsilon 0.5164328543922494 total_time 721.0 step_num 132\n",
      "episode 945, reward -68.0, memory_length 2000, epsilon 0.5160714778907065 total_time 721.0 step_num 124\n",
      "episode 946, reward 152.0, memory_length 2000, epsilon 0.5157103542641982 total_time 722.0 step_num 122\n",
      "episode 947, reward 107.0, memory_length 2000, epsilon 0.5153494833357738 total_time 722.0 step_num 135\n",
      "episode 948, reward 161.0, memory_length 2000, epsilon 0.5149888649286065 total_time 722.0 step_num 113\n",
      "episode 949, reward -94.0, memory_length 2000, epsilon 0.5146284988659934 total_time 728.0 step_num 140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 950, reward 157.0, memory_length 2000, epsilon 0.5142683849713549 total_time 721.0 step_num 125\n",
      "episode 951, reward 103.0, memory_length 2000, epsilon 0.5139085230682354 total_time 721.0 step_num 127\n",
      "episode 952, reward 185.0, memory_length 2000, epsilon 0.5135489129803025 total_time 728.0 step_num 129\n",
      "episode 953, reward 220.0, memory_length 2000, epsilon 0.5131895545313472 total_time 721.0 step_num 120\n",
      "episode 954, reward 350.0, memory_length 2000, epsilon 0.5128304475452841 total_time 722.0 step_num 120\n",
      "episode 955, reward 155.0, memory_length 2000, epsilon 0.5124715918461503 total_time 725.0 step_num 118\n",
      "episode 956, reward 217.0, memory_length 2000, epsilon 0.5121129872581067 total_time 736.0 step_num 104\n",
      "episode 957, reward 202.0, memory_length 2000, epsilon 0.5117546336054374 total_time 721.0 step_num 120\n",
      "episode 958, reward 164.0, memory_length 2000, epsilon 0.5113965307125485 total_time 725.0 step_num 117\n",
      "episode 959, reward 140.0, memory_length 2000, epsilon 0.51103867840397 total_time 728.0 step_num 112\n",
      "episode 960, reward 224.0, memory_length 2000, epsilon 0.5106810765043542 total_time 722.0 step_num 119\n",
      "episode 961, reward 84.0, memory_length 2000, epsilon 0.5103237248384761 total_time 723.0 step_num 113\n",
      "episode 962, reward 309.0, memory_length 2000, epsilon 0.5099666232312333 total_time 723.0 step_num 139\n",
      "episode 963, reward -176.0, memory_length 2000, epsilon 0.5096097715076462 total_time 730.0 step_num 118\n",
      "episode 964, reward -123.0, memory_length 2000, epsilon 0.5092531694928573 total_time 723.0 step_num 117\n",
      "episode 965, reward 89.0, memory_length 2000, epsilon 0.5088968170121316 total_time 722.0 step_num 107\n",
      "episode 966, reward 382.0, memory_length 2000, epsilon 0.5085407138908563 total_time 721.0 step_num 129\n",
      "episode 967, reward 337.0, memory_length 2000, epsilon 0.5081848599545412 total_time 721.0 step_num 117\n",
      "episode 968, reward 253.0, memory_length 2000, epsilon 0.5078292550288176 total_time 727.0 step_num 138\n",
      "episode 969, reward 265.0, memory_length 2000, epsilon 0.5074738989394391 total_time 721.0 step_num 126\n",
      "episode 970, reward 166.0, memory_length 2000, epsilon 0.5071187915122811 total_time 730.0 step_num 117\n",
      "episode 971, reward 121.0, memory_length 2000, epsilon 0.5067639325733413 total_time 721.0 step_num 135\n",
      "episode 972, reward 55.0, memory_length 2000, epsilon 0.5064093219487384 total_time 736.0 step_num 125\n",
      "episode 973, reward 8.0, memory_length 2000, epsilon 0.5060549594647136 total_time 722.0 step_num 128\n",
      "episode 974, reward 165.0, memory_length 2000, epsilon 0.5057008449476289 total_time 723.0 step_num 109\n",
      "episode 975, reward 329.0, memory_length 2000, epsilon 0.5053469782239685 total_time 728.0 step_num 128\n",
      "episode 976, reward -166.0, memory_length 2000, epsilon 0.5049933591203374 total_time 728.0 step_num 128\n",
      "episode 977, reward -149.0, memory_length 2000, epsilon 0.5046399874634624 total_time 721.0 step_num 136\n",
      "episode 978, reward -4.0, memory_length 2000, epsilon 0.5042868630801913 total_time 728.0 step_num 120\n",
      "episode 979, reward 310.0, memory_length 2000, epsilon 0.5039339857974933 total_time 721.0 step_num 131\n",
      "episode 980, reward 474.0, memory_length 2000, epsilon 0.5035813554424584 total_time 726.0 step_num 130\n",
      "episode 981, reward 200.0, memory_length 2000, epsilon 0.5032289718422978 total_time 725.0 step_num 123\n",
      "episode 982, reward -24.0, memory_length 2000, epsilon 0.5028768348243433 total_time 723.0 step_num 131\n",
      "episode 983, reward 229.0, memory_length 2000, epsilon 0.502524944216048 total_time 721.0 step_num 124\n",
      "episode 984, reward 301.0, memory_length 2000, epsilon 0.5021732998449855 total_time 721.0 step_num 127\n",
      "episode 985, reward -146.0, memory_length 2000, epsilon 0.50182190153885 total_time 724.0 step_num 126\n",
      "episode 986, reward 170.0, memory_length 2000, epsilon 0.5014707491254562 total_time 722.0 step_num 133\n",
      "episode 987, reward -66.0, memory_length 2000, epsilon 0.5011198424327394 total_time 726.0 step_num 115\n",
      "episode 988, reward 185.0, memory_length 2000, epsilon 0.5007691812887556 total_time 728.0 step_num 142\n",
      "episode 989, reward 284.0, memory_length 2000, epsilon 0.5004187655216806 total_time 728.0 step_num 127\n",
      "episode 990, reward 261.0, memory_length 2000, epsilon 0.5000685949598108 total_time 729.0 step_num 120\n",
      "episode 991, reward 176.0, memory_length 2000, epsilon 0.4997186694315624 total_time 728.0 step_num 116\n",
      "episode 992, reward -32.0, memory_length 2000, epsilon 0.49936898876547203 total_time 721.0 step_num 131\n",
      "episode 993, reward 22.0, memory_length 2000, epsilon 0.4990195527901962 total_time 721.0 step_num 129\n",
      "episode 994, reward 52.0, memory_length 2000, epsilon 0.4986703613345112 total_time 724.0 step_num 127\n",
      "episode 995, reward 197.0, memory_length 2000, epsilon 0.4983214142273132 total_time 722.0 step_num 130\n",
      "episode 996, reward -6.0, memory_length 2000, epsilon 0.49797271129761816 total_time 723.0 step_num 129\n",
      "episode 997, reward 103.0, memory_length 2000, epsilon 0.4976242523745617 total_time 721.0 step_num 129\n",
      "episode 998, reward -79.0, memory_length 2000, epsilon 0.4972760372873987 total_time 725.0 step_num 123\n",
      "episode 999, reward 292.0, memory_length 2000, epsilon 0.4969280658655041 total_time 730.0 step_num 122\n",
      "episode 1000, reward 130.0, memory_length 2000, epsilon 0.49658033793837164 total_time 721.0 step_num 106\n",
      "episode 1001, reward -32.0, memory_length 2000, epsilon 0.4962328533356147 total_time 739.0 step_num 131\n",
      "episode 1002, reward 265.0, memory_length 2000, epsilon 0.4958856118869658 total_time 721.0 step_num 117\n",
      "episode 1003, reward -51.0, memory_length 2000, epsilon 0.4955386134222767 total_time 723.0 step_num 118\n",
      "episode 1004, reward 103.0, memory_length 2000, epsilon 0.4951918577715181 total_time 721.0 step_num 122\n",
      "episode 1005, reward 154.0, memory_length 2000, epsilon 0.4948453447647796 total_time 736.0 step_num 125\n",
      "episode 1006, reward 328.0, memory_length 2000, epsilon 0.49449907423226996 total_time 721.0 step_num 120\n",
      "episode 1007, reward 15.0, memory_length 2000, epsilon 0.49415304600431675 total_time 726.0 step_num 120\n",
      "episode 1008, reward 15.0, memory_length 2000, epsilon 0.4938072599113658 total_time 726.0 step_num 130\n",
      "episode 1009, reward -68.0, memory_length 2000, epsilon 0.4934617157839821 total_time 721.0 step_num 120\n",
      "episode 1010, reward 235.0, memory_length 2000, epsilon 0.4931164134528491 total_time 727.0 step_num 132\n",
      "episode 1011, reward 301.0, memory_length 2000, epsilon 0.49277135274876854 total_time 721.0 step_num 110\n",
      "episode 1012, reward -374.0, memory_length 2000, epsilon 0.49242653350266063 total_time 721.0 step_num 110\n",
      "episode 1013, reward 323.0, memory_length 2000, epsilon 0.49208195554556405 total_time 722.0 step_num 118\n",
      "episode 1014, reward -14.0, memory_length 2000, epsilon 0.4917376187086355 total_time 721.0 step_num 124\n",
      "episode 1015, reward 274.0, memory_length 2000, epsilon 0.49139352282314996 total_time 730.0 step_num 125\n",
      "episode 1016, reward 13.0, memory_length 2000, epsilon 0.4910496677205004 total_time 721.0 step_num 140\n",
      "episode 1017, reward 102.0, memory_length 2000, epsilon 0.4907060532321979 total_time 723.0 step_num 119\n",
      "episode 1018, reward 157.0, memory_length 2000, epsilon 0.4903626791898713 total_time 721.0 step_num 122\n",
      "episode 1019, reward -100.0, memory_length 2000, epsilon 0.49001954542526727 total_time 722.0 step_num 118\n",
      "episode 1020, reward -82.0, memory_length 2000, epsilon 0.4896766517702504 total_time 722.0 step_num 123\n",
      "episode 1021, reward 128.0, memory_length 2000, epsilon 0.48933399805680255 total_time 725.0 step_num 134\n",
      "episode 1022, reward 313.0, memory_length 2000, epsilon 0.4889915841170236 total_time 724.0 step_num 134\n",
      "episode 1023, reward 132.0, memory_length 2000, epsilon 0.4886494097831307 total_time 735.0 step_num 130\n",
      "episode 1024, reward 19.0, memory_length 2000, epsilon 0.4883074748874583 total_time 727.0 step_num 123\n",
      "episode 1025, reward 490.0, memory_length 2000, epsilon 0.4879657792624584 total_time 730.0 step_num 113\n",
      "episode 1026, reward 249.0, memory_length 2000, epsilon 0.48762432274070017 total_time 726.0 step_num 105\n",
      "episode 1027, reward 13.0, memory_length 2000, epsilon 0.4872831051548697 total_time 721.0 step_num 125\n",
      "episode 1028, reward -177.0, memory_length 2000, epsilon 0.4869421263377706 total_time 732.0 step_num 121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1029, reward -60.0, memory_length 2000, epsilon 0.4866013861223232 total_time 723.0 step_num 113\n",
      "episode 1030, reward 13.0, memory_length 2000, epsilon 0.4862608843415646 total_time 730.0 step_num 128\n",
      "episode 1031, reward -9.0, memory_length 2000, epsilon 0.4859206208286491 total_time 729.0 step_num 105\n",
      "episode 1032, reward 252.0, memory_length 2000, epsilon 0.4855805954168475 total_time 729.0 step_num 124\n",
      "episode 1033, reward -19.0, memory_length 2000, epsilon 0.4852408079395475 total_time 731.0 step_num 127\n",
      "episode 1034, reward 319.0, memory_length 2000, epsilon 0.484901258230253 total_time 721.0 step_num 111\n",
      "episode 1035, reward 188.0, memory_length 2000, epsilon 0.48456194612258474 total_time 722.0 step_num 123\n",
      "episode 1036, reward 157.0, memory_length 2000, epsilon 0.4842228714502798 total_time 721.0 step_num 129\n",
      "episode 1037, reward 93.0, memory_length 2000, epsilon 0.48388403404719155 total_time 723.0 step_num 129\n",
      "episode 1038, reward 64.0, memory_length 2000, epsilon 0.48354543374728964 total_time 727.0 step_num 127\n",
      "episode 1039, reward 13.0, memory_length 2000, epsilon 0.48320707038466 total_time 721.0 step_num 124\n",
      "episode 1040, reward 101.0, memory_length 2000, epsilon 0.4828689437935045 total_time 725.0 step_num 121\n",
      "episode 1041, reward -100.0, memory_length 2000, epsilon 0.48253105380814104 total_time 722.0 step_num 137\n",
      "episode 1042, reward 314.0, memory_length 2000, epsilon 0.4821934002630037 total_time 722.0 step_num 118\n",
      "episode 1043, reward 44.0, memory_length 2000, epsilon 0.48185598299264204 total_time 722.0 step_num 121\n",
      "episode 1044, reward -15.0, memory_length 2000, epsilon 0.4815188018317218 total_time 723.0 step_num 119\n",
      "episode 1045, reward 163.0, memory_length 2000, epsilon 0.481181856615024 total_time 727.0 step_num 122\n",
      "episode 1046, reward 276.0, memory_length 2000, epsilon 0.4808451471774456 total_time 726.0 step_num 127\n",
      "episode 1047, reward 64.0, memory_length 2000, epsilon 0.48050867335399894 total_time 727.0 step_num 108\n",
      "episode 1048, reward 8.0, memory_length 2000, epsilon 0.4801724349798118 total_time 722.0 step_num 112\n",
      "episode 1049, reward -144.0, memory_length 2000, epsilon 0.47983643189012753 total_time 729.0 step_num 118\n",
      "episode 1050, reward -451.0, memory_length 2000, epsilon 0.4795006639203044 total_time 722.0 step_num 119\n",
      "episode 1051, reward 2.0, memory_length 2000, epsilon 0.47916513090581614 total_time 725.0 step_num 119\n",
      "episode 1052, reward 130.0, memory_length 2000, epsilon 0.4788298326822517 total_time 721.0 step_num 120\n",
      "episode 1053, reward 409.0, memory_length 2000, epsilon 0.4784947690853148 total_time 721.0 step_num 124\n",
      "episode 1054, reward 250.0, memory_length 2000, epsilon 0.47815993995082434 total_time 724.0 step_num 121\n",
      "episode 1055, reward 228.0, memory_length 2000, epsilon 0.477825345114714 total_time 723.0 step_num 120\n",
      "episode 1056, reward -2.0, memory_length 2000, epsilon 0.47749098441303234 total_time 724.0 step_num 113\n",
      "episode 1057, reward 301.0, memory_length 2000, epsilon 0.4771568576819426 total_time 730.0 step_num 130\n",
      "episode 1058, reward 292.0, memory_length 2000, epsilon 0.4768229647577227 total_time 721.0 step_num 123\n",
      "episode 1059, reward -19.0, memory_length 2000, epsilon 0.47648930547676505 total_time 722.0 step_num 121\n",
      "episode 1060, reward 255.0, memory_length 2000, epsilon 0.47615587967557665 total_time 723.0 step_num 134\n",
      "episode 1061, reward 71.0, memory_length 2000, epsilon 0.47582268719077875 total_time 722.0 step_num 113\n",
      "episode 1062, reward 373.0, memory_length 2000, epsilon 0.47548972785910715 total_time 721.0 step_num 122\n",
      "episode 1063, reward 31.0, memory_length 2000, epsilon 0.4751570015174117 total_time 721.0 step_num 119\n",
      "episode 1064, reward 274.0, memory_length 2000, epsilon 0.47482450800265646 total_time 721.0 step_num 128\n",
      "episode 1065, reward 161.0, memory_length 2000, epsilon 0.47449224715191973 total_time 722.0 step_num 127\n",
      "episode 1066, reward 121.0, memory_length 2000, epsilon 0.4741602188023935 total_time 721.0 step_num 118\n",
      "episode 1067, reward 283.0, memory_length 2000, epsilon 0.47382842279138404 total_time 721.0 step_num 129\n",
      "episode 1068, reward 463.0, memory_length 2000, epsilon 0.47349685895631116 total_time 721.0 step_num 123\n",
      "episode 1069, reward -29.0, memory_length 2000, epsilon 0.4731655271347087 total_time 724.0 step_num 119\n",
      "episode 1070, reward -162.0, memory_length 2000, epsilon 0.472834427164224 total_time 738.0 step_num 120\n",
      "episode 1071, reward 85.0, memory_length 2000, epsilon 0.4725035588826181 total_time 721.0 step_num 120\n",
      "episode 1072, reward 193.0, memory_length 2000, epsilon 0.47217292212776546 total_time 721.0 step_num 121\n",
      "episode 1073, reward 397.0, memory_length 2000, epsilon 0.4718425167376541 total_time 727.0 step_num 123\n",
      "episode 1074, reward 139.0, memory_length 2000, epsilon 0.4715123425503854 total_time 721.0 step_num 116\n",
      "episode 1075, reward -15.0, memory_length 2000, epsilon 0.471182399404174 total_time 723.0 step_num 120\n",
      "episode 1076, reward -15.0, memory_length 2000, epsilon 0.47085268713734774 total_time 723.0 step_num 98\n",
      "episode 1077, reward 230.0, memory_length 2000, epsilon 0.4705232055883475 total_time 728.0 step_num 136\n",
      "episode 1078, reward -28.0, memory_length 2000, epsilon 0.4701939545957275 total_time 722.0 step_num 110\n",
      "episode 1079, reward 119.0, memory_length 2000, epsilon 0.4698649339981547 total_time 725.0 step_num 107\n",
      "episode 1080, reward 301.0, memory_length 2000, epsilon 0.4695361436344088 total_time 721.0 step_num 124\n",
      "episode 1081, reward 283.0, memory_length 2000, epsilon 0.46920758334338286 total_time 721.0 step_num 122\n",
      "episode 1082, reward -129.0, memory_length 2000, epsilon 0.46887925296408206 total_time 726.0 step_num 125\n",
      "episode 1083, reward 40.0, memory_length 2000, epsilon 0.4685511523356246 total_time 721.0 step_num 122\n",
      "episode 1084, reward 229.0, memory_length 2000, epsilon 0.46822328129724117 total_time 721.0 step_num 123\n",
      "episode 1085, reward 116.0, memory_length 2000, epsilon 0.46789563968827497 total_time 722.0 step_num 121\n",
      "episode 1086, reward 166.0, memory_length 2000, epsilon 0.46756822734818154 total_time 721.0 step_num 121\n",
      "episode 1087, reward 137.0, memory_length 2000, epsilon 0.46724104411652884 total_time 725.0 step_num 120\n",
      "episode 1088, reward 242.0, memory_length 2000, epsilon 0.4669140898329972 total_time 722.0 step_num 131\n",
      "episode 1089, reward -32.0, memory_length 2000, epsilon 0.4665873643373788 total_time 721.0 step_num 116\n",
      "episode 1090, reward -146.0, memory_length 2000, epsilon 0.4662608674695783 total_time 724.0 step_num 130\n",
      "episode 1091, reward 364.0, memory_length 2000, epsilon 0.4659345990696122 total_time 721.0 step_num 108\n",
      "episode 1092, reward 85.0, memory_length 2000, epsilon 0.46560855897760905 total_time 730.0 step_num 128\n",
      "episode 1093, reward 95.0, memory_length 2000, epsilon 0.465282747033809 total_time 728.0 step_num 118\n",
      "episode 1094, reward 62.0, memory_length 2000, epsilon 0.46495716307856433 total_time 722.0 step_num 132\n",
      "episode 1095, reward 228.0, memory_length 2000, epsilon 0.46463180695233897 total_time 723.0 step_num 133\n",
      "episode 1096, reward 215.0, memory_length 2000, epsilon 0.46430667849570817 total_time 722.0 step_num 122\n",
      "episode 1097, reward 392.0, memory_length 2000, epsilon 0.4639817775493592 total_time 728.0 step_num 118\n",
      "episode 1098, reward 193.0, memory_length 2000, epsilon 0.46365710395409054 total_time 721.0 step_num 128\n",
      "episode 1099, reward 219.0, memory_length 2000, epsilon 0.463332657550812 total_time 723.0 step_num 121\n",
      "episode 1100, reward 19.0, memory_length 2000, epsilon 0.463008438180545 total_time 736.0 step_num 108\n",
      "episode 1101, reward 286.0, memory_length 2000, epsilon 0.46268444568442196 total_time 724.0 step_num 127\n",
      "episode 1102, reward 113.0, memory_length 2000, epsilon 0.46236067990368657 total_time 728.0 step_num 115\n",
      "episode 1103, reward 496.0, memory_length 2000, epsilon 0.46203714067969354 total_time 727.0 step_num 120\n",
      "episode 1104, reward 310.0, memory_length 2000, epsilon 0.4617138278539087 total_time 721.0 step_num 123\n",
      "episode 1105, reward 247.0, memory_length 2000, epsilon 0.4613907412679088 total_time 721.0 step_num 117\n",
      "episode 1106, reward 39.0, memory_length 2000, epsilon 0.4610678807633813 total_time 723.0 step_num 132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1107, reward 274.0, memory_length 2000, epsilon 0.4607452461821246 total_time 730.0 step_num 135\n",
      "episode 1108, reward -5.0, memory_length 2000, epsilon 0.4604228373660478 total_time 721.0 step_num 119\n",
      "episode 1109, reward 102.0, memory_length 2000, epsilon 0.4601006541571705 total_time 723.0 step_num 129\n",
      "episode 1110, reward 103.0, memory_length 2000, epsilon 0.4597786963976229 total_time 721.0 step_num 127\n",
      "episode 1111, reward 167.0, memory_length 2000, epsilon 0.4594569639296458 total_time 728.0 step_num 121\n",
      "episode 1112, reward 230.0, memory_length 2000, epsilon 0.4591354565955902 total_time 737.0 step_num 122\n",
      "episode 1113, reward -7.0, memory_length 2000, epsilon 0.4588141742379175 total_time 725.0 step_num 110\n",
      "episode 1114, reward 155.0, memory_length 2000, epsilon 0.45849311669919934 total_time 734.0 step_num 119\n",
      "episode 1115, reward 239.0, memory_length 2000, epsilon 0.45817228382211755 total_time 728.0 step_num 121\n",
      "episode 1116, reward -145.0, memory_length 2000, epsilon 0.457851675449464 total_time 731.0 step_num 124\n",
      "episode 1117, reward -75.0, memory_length 2000, epsilon 0.4575312914241405 total_time 726.0 step_num 108\n",
      "episode 1118, reward -167.0, memory_length 2000, epsilon 0.45721113158915916 total_time 721.0 step_num 122\n",
      "episode 1119, reward 397.0, memory_length 2000, epsilon 0.45689119578764126 total_time 727.0 step_num 112\n",
      "episode 1120, reward -50.0, memory_length 2000, epsilon 0.4565714838628185 total_time 730.0 step_num 112\n",
      "episode 1121, reward 308.0, memory_length 2000, epsilon 0.456251995658032 total_time 725.0 step_num 122\n",
      "episode 1122, reward -160.0, memory_length 2000, epsilon 0.45593273101673243 total_time 725.0 step_num 127\n",
      "episode 1123, reward 343.0, memory_length 2000, epsilon 0.45561368978248024 total_time 727.0 step_num 129\n",
      "episode 1124, reward 134.0, memory_length 2000, epsilon 0.4552948717989452 total_time 722.0 step_num 120\n",
      "episode 1125, reward 398.0, memory_length 2000, epsilon 0.4549762769099064 total_time 725.0 step_num 122\n",
      "episode 1126, reward 187.0, memory_length 2000, epsilon 0.4546579049592523 total_time 724.0 step_num 119\n",
      "episode 1127, reward 157.0, memory_length 2000, epsilon 0.4543397557909808 total_time 721.0 step_num 136\n",
      "episode 1128, reward -67.0, memory_length 2000, epsilon 0.45402182924919876 total_time 728.0 step_num 124\n",
      "episode 1129, reward 35.0, memory_length 2000, epsilon 0.45370412517812214 total_time 722.0 step_num 139\n",
      "episode 1130, reward 76.0, memory_length 2000, epsilon 0.4533866434220759 total_time 721.0 step_num 120\n",
      "episode 1131, reward 210.0, memory_length 2000, epsilon 0.453069383825494 total_time 723.0 step_num 132\n",
      "episode 1132, reward 66.0, memory_length 2000, epsilon 0.45275234623291927 total_time 723.0 step_num 115\n",
      "episode 1133, reward 181.0, memory_length 2000, epsilon 0.4524355304890032 total_time 727.0 step_num 127\n",
      "episode 1134, reward 33.0, memory_length 2000, epsilon 0.4521189364385062 total_time 726.0 step_num 121\n",
      "episode 1135, reward 212.0, memory_length 2000, epsilon 0.45180256392629703 total_time 728.0 step_num 107\n",
      "episode 1136, reward 88.0, memory_length 2000, epsilon 0.4514864127973533 total_time 724.0 step_num 118\n",
      "episode 1137, reward 418.0, memory_length 2000, epsilon 0.45117048289676087 total_time 721.0 step_num 121\n",
      "episode 1138, reward 305.0, memory_length 2000, epsilon 0.450854774069714 total_time 722.0 step_num 117\n",
      "episode 1139, reward 138.0, memory_length 2000, epsilon 0.4505392861615155 total_time 723.0 step_num 125\n",
      "episode 1140, reward 228.0, memory_length 2000, epsilon 0.45022401901757625 total_time 723.0 step_num 134\n",
      "episode 1141, reward 283.0, memory_length 2000, epsilon 0.44990897248341527 total_time 730.0 step_num 125\n",
      "episode 1142, reward 208.0, memory_length 2000, epsilon 0.44959414640465983 total_time 727.0 step_num 123\n",
      "episode 1143, reward 30.0, memory_length 2000, epsilon 0.4492795406270451 total_time 723.0 step_num 112\n",
      "episode 1144, reward 49.0, memory_length 2000, epsilon 0.4489651549964144 total_time 721.0 step_num 121\n",
      "episode 1145, reward 80.0, memory_length 2000, epsilon 0.4486509893587185 total_time 722.0 step_num 125\n",
      "episode 1146, reward 341.0, memory_length 2000, epsilon 0.4483370435600164 total_time 722.0 step_num 120\n",
      "episode 1147, reward 70.0, memory_length 2000, epsilon 0.4480233174464746 total_time 724.0 step_num 122\n",
      "episode 1148, reward 167.0, memory_length 2000, epsilon 0.44770981086436734 total_time 728.0 step_num 125\n",
      "episode 1149, reward 309.0, memory_length 2000, epsilon 0.4473965236600763 total_time 723.0 step_num 133\n",
      "episode 1150, reward 156.0, memory_length 2000, epsilon 0.4470834556800909 total_time 723.0 step_num 125\n",
      "episode 1151, reward 236.0, memory_length 2000, epsilon 0.44677060677100766 total_time 725.0 step_num 138\n",
      "episode 1152, reward -95.0, memory_length 2000, epsilon 0.4464579767795307 total_time 721.0 step_num 107\n",
      "episode 1153, reward 47.0, memory_length 2000, epsilon 0.44614556555247126 total_time 725.0 step_num 116\n",
      "episode 1154, reward 274.0, memory_length 2000, epsilon 0.4458333729367479 total_time 721.0 step_num 124\n",
      "episode 1155, reward 188.0, memory_length 2000, epsilon 0.4455213987793862 total_time 722.0 step_num 124\n",
      "episode 1156, reward 285.0, memory_length 2000, epsilon 0.4452096429275188 total_time 726.0 step_num 125\n",
      "episode 1157, reward 278.0, memory_length 2000, epsilon 0.4448981052283854 total_time 722.0 step_num 119\n",
      "episode 1158, reward 320.0, memory_length 2000, epsilon 0.4445867855293324 total_time 728.0 step_num 122\n",
      "episode 1159, reward 569.0, memory_length 2000, epsilon 0.4442756836778132 total_time 725.0 step_num 125\n",
      "episode 1160, reward 328.0, memory_length 2000, epsilon 0.44396479952138795 total_time 721.0 step_num 129\n",
      "episode 1161, reward 404.0, memory_length 2000, epsilon 0.4436541329077233 total_time 722.0 step_num 122\n",
      "episode 1162, reward 251.0, memory_length 2000, epsilon 0.4433436836845927 total_time 722.0 step_num 123\n",
      "episode 1163, reward 232.0, memory_length 2000, epsilon 0.4430334516998759 total_time 733.0 step_num 114\n",
      "episode 1164, reward 368.0, memory_length 2000, epsilon 0.44272343680155934 total_time 722.0 step_num 117\n",
      "episode 1165, reward -39.0, memory_length 2000, epsilon 0.44241363883773566 total_time 726.0 step_num 117\n",
      "episode 1166, reward 339.0, memory_length 2000, epsilon 0.4421040576566039 total_time 726.0 step_num 115\n",
      "episode 1167, reward -77.0, memory_length 2000, epsilon 0.44179469310646924 total_time 721.0 step_num 112\n",
      "episode 1168, reward 335.0, memory_length 2000, epsilon 0.44148554503574294 total_time 725.0 step_num 126\n",
      "episode 1169, reward 85.0, memory_length 2000, epsilon 0.44117661329294267 total_time 721.0 step_num 113\n",
      "episode 1170, reward 102.0, memory_length 2000, epsilon 0.4408678977266917 total_time 723.0 step_num 121\n",
      "episode 1171, reward 164.0, memory_length 2000, epsilon 0.4405593981857194 total_time 725.0 step_num 120\n",
      "episode 1172, reward 73.0, memory_length 2000, epsilon 0.44025111451886106 total_time 727.0 step_num 111\n",
      "episode 1173, reward 348.0, memory_length 2000, epsilon 0.4399430465750577 total_time 735.0 step_num 110\n",
      "episode 1174, reward 121.0, memory_length 2000, epsilon 0.4396351942033558 total_time 721.0 step_num 130\n",
      "episode 1175, reward 292.0, memory_length 2000, epsilon 0.43932755725290795 total_time 721.0 step_num 116\n",
      "episode 1176, reward 130.0, memory_length 2000, epsilon 0.4390201355729719 total_time 721.0 step_num 124\n",
      "episode 1177, reward 297.0, memory_length 2000, epsilon 0.43871292901291115 total_time 729.0 step_num 118\n",
      "episode 1178, reward -15.0, memory_length 2000, epsilon 0.43840593742219436 total_time 723.0 step_num 118\n",
      "episode 1179, reward 377.0, memory_length 2000, epsilon 0.43809916065039567 total_time 722.0 step_num 120\n",
      "episode 1180, reward 404.0, memory_length 2000, epsilon 0.4377925985471945 total_time 722.0 step_num 129\n",
      "episode 1181, reward 419.0, memory_length 2000, epsilon 0.4374862509623753 total_time 728.0 step_num 119\n",
      "episode 1182, reward 67.0, memory_length 2000, epsilon 0.4371801177458279 total_time 721.0 step_num 120\n",
      "episode 1183, reward 533.0, memory_length 2000, epsilon 0.4368741987475469 total_time 734.0 step_num 116\n",
      "episode 1184, reward 180.0, memory_length 2000, epsilon 0.436568493817632 total_time 729.0 step_num 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1185, reward 140.0, memory_length 2000, epsilon 0.4362630028062879 total_time 728.0 step_num 109\n",
      "episode 1186, reward 219.0, memory_length 2000, epsilon 0.43595772556382384 total_time 723.0 step_num 116\n",
      "episode 1187, reward 147.0, memory_length 2000, epsilon 0.435652661940654 total_time 723.0 step_num 113\n",
      "episode 1188, reward 38.0, memory_length 2000, epsilon 0.43534781178729726 total_time 725.0 step_num 128\n",
      "episode 1189, reward 248.0, memory_length 2000, epsilon 0.435043174954377 total_time 728.0 step_num 125\n",
      "episode 1190, reward 26.0, memory_length 2000, epsilon 0.43473875129262124 total_time 722.0 step_num 121\n",
      "episode 1191, reward -28.0, memory_length 2000, epsilon 0.43443454065286224 total_time 722.0 step_num 115\n",
      "episode 1192, reward 273.0, memory_length 2000, epsilon 0.43413054288603686 total_time 723.0 step_num 121\n",
      "episode 1193, reward -5.0, memory_length 2000, epsilon 0.4338267578431862 total_time 721.0 step_num 121\n",
      "episode 1194, reward 346.0, memory_length 2000, epsilon 0.43352318537545553 total_time 721.0 step_num 114\n",
      "episode 1195, reward 220.0, memory_length 2000, epsilon 0.43321982533409437 total_time 721.0 step_num 118\n",
      "episode 1196, reward 319.0, memory_length 2000, epsilon 0.4329166775704564 total_time 721.0 step_num 147\n",
      "episode 1197, reward 175.0, memory_length 2000, epsilon 0.43261374193599894 total_time 721.0 step_num 115\n",
      "episode 1198, reward 241.0, memory_length 2000, epsilon 0.4323110182822838 total_time 724.0 step_num 123\n",
      "episode 1199, reward 16.0, memory_length 2000, epsilon 0.43200850646097616 total_time 724.0 step_num 117\n",
      "episode 1200, reward 265.0, memory_length 2000, epsilon 0.43170620632384543 total_time 721.0 step_num 114\n",
      "episode 1201, reward 76.0, memory_length 2000, epsilon 0.4314041177227644 total_time 721.0 step_num 104\n",
      "episode 1202, reward 309.0, memory_length 2000, epsilon 0.43110224050970963 total_time 723.0 step_num 110\n",
      "episode 1203, reward 102.0, memory_length 2000, epsilon 0.43080057453676146 total_time 723.0 step_num 111\n",
      "episode 1204, reward 318.0, memory_length 2000, epsilon 0.4304991196561034 total_time 723.0 step_num 133\n",
      "episode 1205, reward 199.0, memory_length 2000, epsilon 0.43019787572002244 total_time 727.0 step_num 120\n",
      "episode 1206, reward 166.0, memory_length 2000, epsilon 0.4298968425809094 total_time 730.0 step_num 117\n",
      "episode 1207, reward 250.0, memory_length 2000, epsilon 0.4295960200912577 total_time 724.0 step_num 111\n",
      "episode 1208, reward 238.0, memory_length 2000, epsilon 0.42929540810366446 total_time 721.0 step_num 123\n",
      "episode 1209, reward -158.0, memory_length 2000, epsilon 0.4289950064708298 total_time 730.0 step_num 114\n",
      "episode 1210, reward 193.0, memory_length 2000, epsilon 0.4286948150455569 total_time 739.0 step_num 129\n",
      "episode 1211, reward 14.0, memory_length 2000, epsilon 0.4283948336807519 total_time 728.0 step_num 115\n",
      "episode 1212, reward 254.0, memory_length 2000, epsilon 0.428095062229424 total_time 725.0 step_num 127\n",
      "episode 1213, reward 263.0, memory_length 2000, epsilon 0.4277955005446852 total_time 734.0 step_num 133\n",
      "episode 1214, reward 84.0, memory_length 2000, epsilon 0.42749614847975015 total_time 723.0 step_num 111\n",
      "episode 1215, reward 274.0, memory_length 2000, epsilon 0.42719700588793647 total_time 730.0 step_num 130\n",
      "episode 1216, reward 11.0, memory_length 2000, epsilon 0.4268980726226642 total_time 725.0 step_num 120\n",
      "episode 1217, reward 59.0, memory_length 2000, epsilon 0.426599348537456 total_time 728.0 step_num 132\n",
      "episode 1218, reward 34.0, memory_length 2000, epsilon 0.4263008334859372 total_time 724.0 step_num 131\n",
      "episode 1219, reward 252.0, memory_length 2000, epsilon 0.42600252732183536 total_time 738.0 step_num 127\n",
      "episode 1220, reward 76.0, memory_length 2000, epsilon 0.42570442989898033 total_time 721.0 step_num 133\n",
      "episode 1221, reward 362.0, memory_length 2000, epsilon 0.42540654107130454 total_time 725.0 step_num 118\n",
      "episode 1222, reward 103.0, memory_length 2000, epsilon 0.42510886069284237 total_time 721.0 step_num 119\n",
      "episode 1223, reward 448.0, memory_length 2000, epsilon 0.42481138861773043 total_time 724.0 step_num 127\n",
      "episode 1224, reward 163.0, memory_length 2000, epsilon 0.4245141247002075 total_time 727.0 step_num 123\n",
      "episode 1225, reward 167.0, memory_length 2000, epsilon 0.424217068794614 total_time 728.0 step_num 122\n",
      "episode 1226, reward 294.0, memory_length 2000, epsilon 0.4239202207553929 total_time 726.0 step_num 110\n",
      "episode 1227, reward 85.0, memory_length 2000, epsilon 0.42362358043708825 total_time 730.0 step_num 120\n",
      "episode 1228, reward 132.0, memory_length 2000, epsilon 0.4233271476943466 total_time 726.0 step_num 113\n",
      "episode 1229, reward 184.0, memory_length 2000, epsilon 0.4230309223819158 total_time 721.0 step_num 124\n",
      "episode 1230, reward 256.0, memory_length 2000, epsilon 0.4227349043546454 total_time 721.0 step_num 135\n",
      "episode 1231, reward 94.0, memory_length 2000, epsilon 0.4224390934674866 total_time 721.0 step_num 126\n",
      "episode 1232, reward 456.0, memory_length 2000, epsilon 0.4221434895754921 total_time 726.0 step_num 113\n",
      "episode 1233, reward 124.0, memory_length 2000, epsilon 0.42184809253381583 total_time 724.0 step_num 128\n",
      "episode 1234, reward -181.0, memory_length 2000, epsilon 0.4215529021977134 total_time 722.0 step_num 109\n",
      "episode 1235, reward 22.0, memory_length 2000, epsilon 0.4212579184225415 total_time 721.0 step_num 122\n",
      "episode 1236, reward 343.0, memory_length 2000, epsilon 0.42096314106375804 total_time 727.0 step_num 121\n",
      "episode 1237, reward 32.0, memory_length 2000, epsilon 0.4206685699769221 total_time 728.0 step_num 119\n",
      "episode 1238, reward 184.0, memory_length 2000, epsilon 0.4203742050176939 total_time 721.0 step_num 120\n",
      "episode 1239, reward -125.0, memory_length 2000, epsilon 0.4200800460418346 total_time 727.0 step_num 118\n",
      "episode 1240, reward 14.0, memory_length 2000, epsilon 0.4197860929052062 total_time 728.0 step_num 127\n",
      "episode 1241, reward 451.0, memory_length 2000, epsilon 0.41949234546377173 total_time 727.0 step_num 122\n",
      "episode 1242, reward 211.0, memory_length 2000, epsilon 0.41919880357359496 total_time 730.0 step_num 129\n",
      "episode 1243, reward 355.0, memory_length 2000, epsilon 0.4189054670908403 total_time 721.0 step_num 125\n",
      "episode 1244, reward 193.0, memory_length 2000, epsilon 0.4186123358717729 total_time 730.0 step_num 131\n",
      "episode 1245, reward 427.0, memory_length 2000, epsilon 0.4183194097727585 total_time 721.0 step_num 114\n",
      "episode 1246, reward 217.0, memory_length 2000, epsilon 0.41802668865026316 total_time 727.0 step_num 107\n",
      "episode 1247, reward 285.0, memory_length 2000, epsilon 0.4177341723608537 total_time 726.0 step_num 129\n",
      "episode 1248, reward 227.0, memory_length 2000, epsilon 0.417441860761197 total_time 725.0 step_num 111\n",
      "episode 1249, reward 40.0, memory_length 2000, epsilon 0.4171497537080605 total_time 721.0 step_num 121\n",
      "episode 1250, reward -50.0, memory_length 2000, epsilon 0.41685785105831163 total_time 721.0 step_num 119\n",
      "episode 1251, reward 269.0, memory_length 2000, epsilon 0.4165661526689181 total_time 722.0 step_num 123\n",
      "episode 1252, reward 429.0, memory_length 2000, epsilon 0.41627465839694777 total_time 726.0 step_num 131\n",
      "episode 1253, reward 67.0, memory_length 2000, epsilon 0.4159833680995683 total_time 721.0 step_num 108\n",
      "episode 1254, reward 308.0, memory_length 2000, epsilon 0.41569228163404753 total_time 725.0 step_num 129\n",
      "episode 1255, reward -149.0, memory_length 2000, epsilon 0.4154013988577532 total_time 721.0 step_num 123\n",
      "episode 1256, reward 139.0, memory_length 2000, epsilon 0.4151107196281525 total_time 730.0 step_num 115\n",
      "episode 1257, reward -284.0, memory_length 2000, epsilon 0.4148202438028128 total_time 721.0 step_num 120\n",
      "episode 1258, reward 326.0, memory_length 2000, epsilon 0.41452997123940083 total_time 725.0 step_num 114\n",
      "episode 1259, reward 305.0, memory_length 2000, epsilon 0.41423990179568304 total_time 722.0 step_num 109\n",
      "episode 1260, reward 2.0, memory_length 2000, epsilon 0.4139500353295254 total_time 725.0 step_num 116\n",
      "episode 1261, reward 264.0, memory_length 2000, epsilon 0.41366037169889336 total_time 723.0 step_num 118\n",
      "episode 1262, reward 33.0, memory_length 2000, epsilon 0.4133709107618518 total_time 726.0 step_num 106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1263, reward 250.0, memory_length 2000, epsilon 0.4130816523765647 total_time 724.0 step_num 110\n",
      "episode 1264, reward -68.0, memory_length 2000, epsilon 0.4127925964012956 total_time 730.0 step_num 106\n",
      "episode 1265, reward 422.0, memory_length 2000, epsilon 0.412503742694407 total_time 722.0 step_num 118\n",
      "episode 1266, reward -95.0, memory_length 2000, epsilon 0.4122150911143605 total_time 721.0 step_num 126\n",
      "episode 1267, reward -95.0, memory_length 2000, epsilon 0.4119266415197169 total_time 730.0 step_num 114\n",
      "episode 1268, reward -5.0, memory_length 2000, epsilon 0.41163839376913597 total_time 721.0 step_num 110\n",
      "episode 1269, reward 269.0, memory_length 2000, epsilon 0.41135034772137613 total_time 722.0 step_num 126\n",
      "episode 1270, reward 166.0, memory_length 2000, epsilon 0.411062503235295 total_time 730.0 step_num 104\n",
      "episode 1271, reward 149.0, memory_length 2000, epsilon 0.41077486016984854 total_time 728.0 step_num 128\n",
      "episode 1272, reward 140.0, memory_length 2000, epsilon 0.4104874183840919 total_time 728.0 step_num 120\n",
      "episode 1273, reward -7.0, memory_length 2000, epsilon 0.4102001777371785 total_time 725.0 step_num 119\n",
      "episode 1274, reward 267.0, memory_length 2000, epsilon 0.4099131380883603 total_time 726.0 step_num 115\n",
      "episode 1275, reward 246.0, memory_length 2000, epsilon 0.409626299296988 total_time 732.0 step_num 115\n",
      "episode 1276, reward 228.0, memory_length 2000, epsilon 0.4093396612225106 total_time 723.0 step_num 113\n",
      "episode 1277, reward 309.0, memory_length 2000, epsilon 0.40905322372447533 total_time 732.0 step_num 118\n",
      "episode 1278, reward -4.0, memory_length 2000, epsilon 0.4087669866625279 total_time 728.0 step_num 120\n",
      "episode 1279, reward 92.0, memory_length 2000, epsilon 0.4084809498964121 total_time 725.0 step_num 110\n",
      "episode 1280, reward 143.0, memory_length 2000, epsilon 0.4081951132859699 total_time 722.0 step_num 129\n",
      "episode 1281, reward 283.0, memory_length 2000, epsilon 0.40790947669114147 total_time 721.0 step_num 112\n",
      "episode 1282, reward 233.0, memory_length 2000, epsilon 0.40762403997196467 total_time 731.0 step_num 121\n",
      "episode 1283, reward 34.0, memory_length 2000, epsilon 0.40733880298857567 total_time 724.0 step_num 124\n",
      "episode 1284, reward 52.0, memory_length 2000, epsilon 0.40705376560120826 total_time 724.0 step_num 118\n",
      "episode 1285, reward 292.0, memory_length 2000, epsilon 0.4067689276701942 total_time 721.0 step_num 125\n",
      "episode 1286, reward 202.0, memory_length 2000, epsilon 0.40648428905596273 total_time 721.0 step_num 131\n",
      "episode 1287, reward 159.0, memory_length 2000, epsilon 0.4061998496190411 total_time 726.0 step_num 131\n",
      "episode 1288, reward -208.0, memory_length 2000, epsilon 0.4059156092200539 total_time 722.0 step_num 127\n",
      "episode 1289, reward 13.0, memory_length 2000, epsilon 0.40563156771972336 total_time 721.0 step_num 128\n",
      "episode 1290, reward 354.0, memory_length 2000, epsilon 0.40534772497886906 total_time 723.0 step_num 128\n",
      "episode 1291, reward 79.0, memory_length 2000, epsilon 0.40506408085840817 total_time 724.0 step_num 118\n",
      "episode 1292, reward 265.0, memory_length 2000, epsilon 0.404780635219355 total_time 721.0 step_num 113\n",
      "episode 1293, reward 398.0, memory_length 2000, epsilon 0.40449738792282114 total_time 725.0 step_num 134\n",
      "episode 1294, reward 184.0, memory_length 2000, epsilon 0.4042143388300155 total_time 721.0 step_num 114\n",
      "episode 1295, reward 536.0, memory_length 2000, epsilon 0.40393148780224397 total_time 728.0 step_num 129\n",
      "episode 1296, reward 241.0, memory_length 2000, epsilon 0.4036488347009095 total_time 724.0 step_num 129\n",
      "episode 1297, reward 229.0, memory_length 2000, epsilon 0.4033663793875122 total_time 721.0 step_num 133\n",
      "episode 1298, reward 367.0, memory_length 2000, epsilon 0.4030841217236488 total_time 724.0 step_num 126\n",
      "episode 1299, reward 326.0, memory_length 2000, epsilon 0.4028020615710131 total_time 725.0 step_num 122\n",
      "episode 1300, reward 283.0, memory_length 2000, epsilon 0.40252019879139567 total_time 730.0 step_num 127\n",
      "episode 1301, reward 22.0, memory_length 2000, epsilon 0.4022385332466837 total_time 721.0 step_num 123\n",
      "episode 1302, reward 233.0, memory_length 2000, epsilon 0.40195706479886106 total_time 722.0 step_num 107\n",
      "episode 1303, reward 257.0, memory_length 2000, epsilon 0.40167579331000813 total_time 728.0 step_num 126\n",
      "episode 1304, reward -33.0, memory_length 2000, epsilon 0.4013947186423021 total_time 723.0 step_num 119\n",
      "episode 1305, reward 148.0, memory_length 2000, epsilon 0.4011138406580162 total_time 730.0 step_num 114\n",
      "episode 1306, reward 282.0, memory_length 2000, epsilon 0.4008331592195202 total_time 723.0 step_num 120\n",
      "episode 1307, reward 214.0, memory_length 2000, epsilon 0.40055267418928026 total_time 724.0 step_num 138\n",
      "episode 1308, reward 242.0, memory_length 2000, epsilon 0.4002723854298587 total_time 722.0 step_num 124\n",
      "episode 1309, reward 86.0, memory_length 2000, epsilon 0.39999229280391396 total_time 728.0 step_num 124\n",
      "episode 1310, reward 544.0, memory_length 2000, epsilon 0.39971239617420073 total_time 721.0 step_num 133\n",
      "episode 1311, reward 148.0, memory_length 2000, epsilon 0.3994326954035696 total_time 721.0 step_num 117\n",
      "episode 1312, reward 256.0, memory_length 2000, epsilon 0.39915319035496727 total_time 721.0 step_num 121\n",
      "episode 1313, reward 31.0, memory_length 2000, epsilon 0.39887388089143616 total_time 721.0 step_num 115\n",
      "episode 1314, reward 332.0, memory_length 2000, epsilon 0.3985947668761147 total_time 731.0 step_num 113\n",
      "episode 1315, reward 206.0, memory_length 2000, epsilon 0.3983158481722369 total_time 731.0 step_num 124\n",
      "episode 1316, reward 148.0, memory_length 2000, epsilon 0.39803712464313273 total_time 721.0 step_num 125\n",
      "episode 1317, reward 185.0, memory_length 2000, epsilon 0.39775859615222764 total_time 728.0 step_num 128\n",
      "episode 1318, reward 106.0, memory_length 2000, epsilon 0.3974802625630426 total_time 724.0 step_num 124\n",
      "episode 1319, reward 53.0, memory_length 2000, epsilon 0.3972021237391941 total_time 722.0 step_num 110\n",
      "episode 1320, reward -191.0, memory_length 2000, epsilon 0.39692417954439424 total_time 724.0 step_num 119\n",
      "episode 1321, reward 359.0, memory_length 2000, epsilon 0.3966464298424503 total_time 722.0 step_num 128\n",
      "episode 1322, reward 17.0, memory_length 2000, epsilon 0.39636887449726493 total_time 722.0 step_num 130\n",
      "episode 1323, reward -39.0, memory_length 2000, epsilon 0.39609151337283593 total_time 726.0 step_num 121\n",
      "episode 1324, reward 70.0, memory_length 2000, epsilon 0.39581434633325646 total_time 724.0 step_num 106\n",
      "episode 1325, reward 147.0, memory_length 2000, epsilon 0.39553737324271465 total_time 723.0 step_num 131\n",
      "episode 1326, reward 205.0, memory_length 2000, epsilon 0.39526059396549357 total_time 733.0 step_num 126\n",
      "episode 1327, reward 279.0, memory_length 2000, epsilon 0.39498400836597153 total_time 729.0 step_num 120\n",
      "episode 1328, reward 229.0, memory_length 2000, epsilon 0.3947076163086214 total_time 730.0 step_num 118\n",
      "episode 1329, reward 409.0, memory_length 2000, epsilon 0.39443141765801115 total_time 721.0 step_num 138\n",
      "episode 1330, reward 129.0, memory_length 2000, epsilon 0.3941554122788035 total_time 723.0 step_num 122\n",
      "episode 1331, reward 94.0, memory_length 2000, epsilon 0.39387960003575573 total_time 721.0 step_num 119\n",
      "episode 1332, reward 291.0, memory_length 2000, epsilon 0.3936039807937199 total_time 723.0 step_num 121\n",
      "episode 1333, reward 170.0, memory_length 2000, epsilon 0.3933285544176424 total_time 722.0 step_num 127\n",
      "episode 1334, reward 256.0, memory_length 2000, epsilon 0.39305332077256466 total_time 721.0 step_num 125\n",
      "episode 1335, reward 431.0, memory_length 2000, epsilon 0.3927782797236218 total_time 722.0 step_num 122\n",
      "episode 1336, reward 96.0, memory_length 2000, epsilon 0.3925034311360439 total_time 726.0 step_num 119\n",
      "episode 1337, reward 326.0, memory_length 2000, epsilon 0.3922287748751551 total_time 725.0 step_num 128\n",
      "episode 1338, reward 215.0, memory_length 2000, epsilon 0.39195431080637383 total_time 722.0 step_num 125\n",
      "episode 1339, reward 445.0, memory_length 2000, epsilon 0.39168003879521274 total_time 721.0 step_num 120\n",
      "episode 1340, reward 130.0, memory_length 2000, epsilon 0.3914059587072785 total_time 721.0 step_num 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1341, reward 75.0, memory_length 2000, epsilon 0.3911320704082718 total_time 723.0 step_num 119\n",
      "episode 1342, reward 503.0, memory_length 2000, epsilon 0.39085837376398747 total_time 722.0 step_num 128\n",
      "episode 1343, reward 173.0, memory_length 2000, epsilon 0.3905848686403141 total_time 725.0 step_num 111\n",
      "episode 1344, reward 177.0, memory_length 2000, epsilon 0.39031155490323416 total_time 726.0 step_num 117\n",
      "episode 1345, reward 355.0, memory_length 2000, epsilon 0.3900384324188239 total_time 721.0 step_num 107\n",
      "episode 1346, reward 301.0, memory_length 2000, epsilon 0.38976550105325336 total_time 721.0 step_num 118\n",
      "episode 1347, reward 389.0, memory_length 2000, epsilon 0.38949276067278615 total_time 725.0 step_num 128\n",
      "episode 1348, reward 134.0, memory_length 2000, epsilon 0.38922021114377947 total_time 722.0 step_num 123\n",
      "episode 1349, reward 197.0, memory_length 2000, epsilon 0.38894785233268403 total_time 722.0 step_num 134\n",
      "episode 1350, reward 103.0, memory_length 2000, epsilon 0.38867568410604403 total_time 721.0 step_num 120\n",
      "episode 1351, reward 76.0, memory_length 2000, epsilon 0.388403706330497 total_time 721.0 step_num 139\n",
      "episode 1352, reward 236.0, memory_length 2000, epsilon 0.3881319188727738 total_time 725.0 step_num 120\n",
      "episode 1353, reward 221.0, memory_length 2000, epsilon 0.3878603215996987 total_time 728.0 step_num 123\n",
      "episode 1354, reward -131.0, memory_length 2000, epsilon 0.38758891437818893 total_time 730.0 step_num 112\n",
      "episode 1355, reward 229.0, memory_length 2000, epsilon 0.3873176970752549 total_time 721.0 step_num 116\n",
      "episode 1356, reward -105.0, memory_length 2000, epsilon 0.38704666955800016 total_time 723.0 step_num 119\n",
      "episode 1357, reward 130.0, memory_length 2000, epsilon 0.38677583169362134 total_time 721.0 step_num 128\n",
      "episode 1358, reward -20.0, memory_length 2000, epsilon 0.38650518334940775 total_time 733.0 step_num 113\n",
      "episode 1359, reward 67.0, memory_length 2000, epsilon 0.38623472439274176 total_time 721.0 step_num 119\n",
      "episode 1360, reward 1.0, memory_length 2000, epsilon 0.38596445469109847 total_time 727.0 step_num 118\n",
      "episode 1361, reward 157.0, memory_length 2000, epsilon 0.3856943741120456 total_time 721.0 step_num 123\n",
      "episode 1362, reward 16.0, memory_length 2000, epsilon 0.38542448252324385 total_time 724.0 step_num 121\n",
      "episode 1363, reward -10.0, memory_length 2000, epsilon 0.3851547797924462 total_time 722.0 step_num 124\n",
      "episode 1364, reward -154.0, memory_length 2000, epsilon 0.3848852657874984 total_time 722.0 step_num 121\n",
      "episode 1365, reward 391.0, memory_length 2000, epsilon 0.3846159403763385 total_time 721.0 step_num 114\n",
      "episode 1366, reward 155.0, memory_length 2000, epsilon 0.3843468034269971 total_time 725.0 step_num 116\n",
      "episode 1367, reward 211.0, memory_length 2000, epsilon 0.3840778548075971 total_time 721.0 step_num 115\n",
      "episode 1368, reward 148.0, memory_length 2000, epsilon 0.3838090943863535 total_time 730.0 step_num 115\n",
      "episode 1369, reward -14.0, memory_length 2000, epsilon 0.38354052203157396 total_time 721.0 step_num 122\n",
      "episode 1370, reward 409.0, memory_length 2000, epsilon 0.3832721376116579 total_time 721.0 step_num 129\n",
      "episode 1371, reward 274.0, memory_length 2000, epsilon 0.3830039409950969 total_time 721.0 step_num 124\n",
      "episode 1372, reward 211.0, memory_length 2000, epsilon 0.38273593205047457 total_time 721.0 step_num 128\n",
      "episode 1373, reward 364.0, memory_length 2000, epsilon 0.38246811064646674 total_time 721.0 step_num 121\n",
      "episode 1374, reward -136.0, memory_length 2000, epsilon 0.3822004766518407 total_time 722.0 step_num 125\n",
      "episode 1375, reward -57.0, memory_length 2000, epsilon 0.38193302993545586 total_time 726.0 step_num 114\n",
      "episode 1376, reward 260.0, memory_length 2000, epsilon 0.38166577036626337 total_time 722.0 step_num 126\n",
      "episode 1377, reward 205.0, memory_length 2000, epsilon 0.38139869781330604 total_time 724.0 step_num 122\n",
      "episode 1378, reward 136.0, memory_length 2000, epsilon 0.3811318121457182 total_time 727.0 step_num 123\n",
      "episode 1379, reward -209.0, memory_length 2000, epsilon 0.380865113232726 total_time 724.0 step_num 112\n",
      "episode 1380, reward 152.0, memory_length 2000, epsilon 0.3805986009436468 total_time 722.0 step_num 112\n",
      "episode 1381, reward 419.0, memory_length 2000, epsilon 0.3803322751478897 total_time 728.0 step_num 121\n",
      "episode 1382, reward 175.0, memory_length 2000, epsilon 0.38006613571495507 total_time 721.0 step_num 119\n",
      "episode 1383, reward 525.0, memory_length 2000, epsilon 0.37980018251443454 total_time 723.0 step_num 125\n",
      "episode 1384, reward 383.0, memory_length 2000, epsilon 0.379534415416011 total_time 728.0 step_num 123\n",
      "episode 1385, reward 320.0, memory_length 2000, epsilon 0.3792688342894587 total_time 728.0 step_num 129\n",
      "episode 1386, reward 355.0, memory_length 2000, epsilon 0.3790034390046428 total_time 721.0 step_num 119\n",
      "episode 1387, reward 371.0, memory_length 2000, epsilon 0.37873822943151947 total_time 725.0 step_num 117\n",
      "episode 1388, reward 228.0, memory_length 2000, epsilon 0.3784732054401362 total_time 723.0 step_num 109\n",
      "episode 1389, reward 193.0, memory_length 2000, epsilon 0.3782083669006312 total_time 721.0 step_num 120\n",
      "episode 1390, reward 331.0, memory_length 2000, epsilon 0.3779437136832335 total_time 724.0 step_num 119\n",
      "episode 1391, reward 98.0, memory_length 2000, epsilon 0.3776792456582631 total_time 722.0 step_num 108\n",
      "episode 1392, reward 264.0, memory_length 2000, epsilon 0.3774149626961306 total_time 723.0 step_num 116\n",
      "episode 1393, reward 140.0, memory_length 2000, epsilon 0.3771508646673374 total_time 728.0 step_num 123\n",
      "episode 1394, reward 265.0, memory_length 2000, epsilon 0.3768869514424754 total_time 721.0 step_num 120\n",
      "episode 1395, reward 69.0, memory_length 2000, epsilon 0.37662322289222716 total_time 726.0 step_num 135\n",
      "episode 1396, reward 142.0, memory_length 2000, epsilon 0.3763596788873657 total_time 733.0 step_num 115\n",
      "episode 1397, reward 140.0, memory_length 2000, epsilon 0.3760963192987544 total_time 728.0 step_num 130\n",
      "episode 1398, reward 300.0, memory_length 2000, epsilon 0.3758331439973471 total_time 723.0 step_num 119\n",
      "episode 1399, reward 220.0, memory_length 2000, epsilon 0.3755701528541879 total_time 721.0 step_num 126\n",
      "episode 1400, reward 437.0, memory_length 2000, epsilon 0.3753073457404111 total_time 737.0 step_num 134\n",
      "episode 1401, reward 175.0, memory_length 2000, epsilon 0.37504472252724114 total_time 721.0 step_num 114\n",
      "episode 1402, reward 280.0, memory_length 2000, epsilon 0.3747822830859928 total_time 727.0 step_num 111\n",
      "episode 1403, reward 462.0, memory_length 2000, epsilon 0.37452002728807066 total_time 723.0 step_num 114\n",
      "episode 1404, reward 194.0, memory_length 2000, epsilon 0.37425795500496933 total_time 728.0 step_num 114\n",
      "episode 1405, reward 121.0, memory_length 2000, epsilon 0.3739960661082735 total_time 721.0 step_num 121\n",
      "episode 1406, reward -1.0, memory_length 2000, epsilon 0.3737343604696576 total_time 722.0 step_num 110\n",
      "episode 1407, reward -32.0, memory_length 2000, epsilon 0.3734728379608857 total_time 721.0 step_num 120\n",
      "episode 1408, reward 136.0, memory_length 2000, epsilon 0.3732114984538119 total_time 736.0 step_num 118\n",
      "episode 1409, reward 281.0, memory_length 2000, epsilon 0.3729503418203799 total_time 725.0 step_num 97\n",
      "episode 1410, reward 53.0, memory_length 2000, epsilon 0.37268936793262275 total_time 722.0 step_num 121\n",
      "episode 1411, reward 380.0, memory_length 2000, epsilon 0.3724285766626634 total_time 725.0 step_num 100\n",
      "episode 1412, reward 125.0, memory_length 2000, epsilon 0.372167967882714 total_time 722.0 step_num 118\n",
      "episode 1413, reward 212.0, memory_length 2000, epsilon 0.3719075414650764 total_time 728.0 step_num 112\n",
      "episode 1414, reward 200.0, memory_length 2000, epsilon 0.37164729728214146 total_time 725.0 step_num 123\n",
      "episode 1415, reward -71.0, memory_length 2000, epsilon 0.37138723520638967 total_time 727.0 step_num 92\n",
      "episode 1416, reward 107.0, memory_length 2000, epsilon 0.37112735511039063 total_time 722.0 step_num 125\n",
      "episode 1417, reward 328.0, memory_length 2000, epsilon 0.3708676568668029 total_time 730.0 step_num 112\n",
      "episode 1418, reward 544.0, memory_length 2000, epsilon 0.37060814034837447 total_time 721.0 step_num 112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1419, reward 323.0, memory_length 2000, epsilon 0.37034880542794235 total_time 722.0 step_num 114\n",
      "episode 1420, reward 238.0, memory_length 2000, epsilon 0.37008965197843224 total_time 721.0 step_num 111\n",
      "episode 1421, reward 230.0, memory_length 2000, epsilon 0.3698306798728589 total_time 728.0 step_num 115\n",
      "episode 1422, reward 203.0, memory_length 2000, epsilon 0.3695718889843262 total_time 728.0 step_num 104\n",
      "episode 1423, reward 13.0, memory_length 2000, epsilon 0.3693132791860265 total_time 721.0 step_num 105\n",
      "episode 1424, reward 146.0, memory_length 2000, epsilon 0.36905485035124097 total_time 725.0 step_num 122\n",
      "episode 1425, reward 485.0, memory_length 2000, epsilon 0.3687966023533395 total_time 722.0 step_num 125\n",
      "episode 1426, reward 50.0, memory_length 2000, epsilon 0.36853853506578055 total_time 728.0 step_num 114\n",
      "episode 1427, reward 307.0, memory_length 2000, epsilon 0.36828064836211116 total_time 727.0 step_num 119\n",
      "episode 1428, reward 299.0, memory_length 2000, epsilon 0.3680229421159668 total_time 725.0 step_num 118\n",
      "episode 1429, reward 205.0, memory_length 2000, epsilon 0.3677654162010715 total_time 733.0 step_num 130\n",
      "episode 1430, reward 343.0, memory_length 2000, epsilon 0.3675080704912375 total_time 727.0 step_num 125\n",
      "episode 1431, reward -46.0, memory_length 2000, epsilon 0.3672509048603653 total_time 722.0 step_num 116\n",
      "episode 1432, reward 202.0, memory_length 2000, epsilon 0.36699391918244395 total_time 721.0 step_num 138\n",
      "episode 1433, reward 305.0, memory_length 2000, epsilon 0.36673711333155035 total_time 722.0 step_num 134\n",
      "episode 1434, reward 413.0, memory_length 2000, epsilon 0.3664804871818495 total_time 722.0 step_num 119\n",
      "episode 1435, reward 418.0, memory_length 2000, epsilon 0.3662240406075948 total_time 721.0 step_num 123\n",
      "episode 1436, reward 232.0, memory_length 2000, epsilon 0.3659677734831272 total_time 724.0 step_num 120\n",
      "episode 1437, reward 302.0, memory_length 2000, epsilon 0.36571168568287604 total_time 728.0 step_num 129\n",
      "episode 1438, reward 440.0, memory_length 2000, epsilon 0.36545577708135824 total_time 722.0 step_num 118\n",
      "episode 1439, reward 490.0, memory_length 2000, epsilon 0.36520004755317836 total_time 721.0 step_num 116\n",
      "episode 1440, reward -156.0, memory_length 2000, epsilon 0.3649444969730292 total_time 726.0 step_num 107\n",
      "episode 1441, reward 124.0, memory_length 2000, epsilon 0.36468912521569086 total_time 724.0 step_num 123\n",
      "episode 1442, reward 439.0, memory_length 2000, epsilon 0.3644339321560311 total_time 724.0 step_num 112\n",
      "episode 1443, reward 130.0, memory_length 2000, epsilon 0.36417891766900545 total_time 730.0 step_num 114\n",
      "episode 1444, reward 20.0, memory_length 2000, epsilon 0.3639240816296568 total_time 725.0 step_num 123\n",
      "episode 1445, reward 119.0, memory_length 2000, epsilon 0.36366942391311524 total_time 725.0 step_num 113\n",
      "episode 1446, reward 278.0, memory_length 2000, epsilon 0.3634149443945988 total_time 722.0 step_num 113\n",
      "episode 1447, reward 212.0, memory_length 2000, epsilon 0.3631606429494124 total_time 728.0 step_num 117\n",
      "episode 1448, reward 182.0, memory_length 2000, epsilon 0.3629065194529482 total_time 725.0 step_num 123\n",
      "episode 1449, reward 325.0, memory_length 2000, epsilon 0.36265257378068594 total_time 727.0 step_num 127\n",
      "episode 1450, reward 31.0, memory_length 2000, epsilon 0.36239880580819206 total_time 721.0 step_num 113\n",
      "episode 1451, reward 130.0, memory_length 2000, epsilon 0.3621452154111202 total_time 730.0 step_num 106\n",
      "episode 1452, reward 102.0, memory_length 2000, epsilon 0.3618918024652112 total_time 723.0 step_num 116\n",
      "episode 1453, reward 209.0, memory_length 2000, epsilon 0.36163856684629264 total_time 725.0 step_num 131\n",
      "episode 1454, reward 184.0, memory_length 2000, epsilon 0.361385508430279 total_time 721.0 step_num 116\n",
      "episode 1455, reward 130.0, memory_length 2000, epsilon 0.36113262709317184 total_time 721.0 step_num 122\n",
      "episode 1456, reward 170.0, memory_length 2000, epsilon 0.3608799227110591 total_time 722.0 step_num 121\n",
      "episode 1457, reward -39.0, memory_length 2000, epsilon 0.3606273951601157 total_time 726.0 step_num 122\n",
      "episode 1458, reward -14.0, memory_length 2000, epsilon 0.3603750443166032 total_time 730.0 step_num 110\n",
      "episode 1459, reward 152.0, memory_length 2000, epsilon 0.36012287005686955 total_time 722.0 step_num 124\n",
      "episode 1460, reward 228.0, memory_length 2000, epsilon 0.35987087225734954 total_time 723.0 step_num 124\n",
      "episode 1461, reward 182.0, memory_length 2000, epsilon 0.35961905079456413 total_time 734.0 step_num 118\n",
      "episode 1462, reward 328.0, memory_length 2000, epsilon 0.35936740554512064 total_time 721.0 step_num 118\n",
      "episode 1463, reward -104.0, memory_length 2000, epsilon 0.3591159363857132 total_time 721.0 step_num 119\n",
      "episode 1464, reward 471.0, memory_length 2000, epsilon 0.3588646431931218 total_time 723.0 step_num 106\n",
      "episode 1465, reward 265.0, memory_length 2000, epsilon 0.35861352584421263 total_time 721.0 step_num 124\n",
      "episode 1466, reward 290.0, memory_length 2000, epsilon 0.3583625842159384 total_time 725.0 step_num 116\n",
      "episode 1467, reward 374.0, memory_length 2000, epsilon 0.35811181818533755 total_time 728.0 step_num 126\n",
      "episode 1468, reward 17.0, memory_length 2000, epsilon 0.35786122762953476 total_time 722.0 step_num 102\n",
      "episode 1469, reward 22.0, memory_length 2000, epsilon 0.3576108124257407 total_time 721.0 step_num 113\n",
      "episode 1470, reward -5.0, memory_length 2000, epsilon 0.35736057245125197 total_time 721.0 step_num 123\n",
      "episode 1471, reward 105.0, memory_length 2000, epsilon 0.3571105075834507 total_time 726.0 step_num 124\n",
      "episode 1472, reward 283.0, memory_length 2000, epsilon 0.3568606176998055 total_time 721.0 step_num 111\n",
      "episode 1473, reward 92.0, memory_length 2000, epsilon 0.35661090267787 total_time 725.0 step_num 133\n",
      "episode 1474, reward 170.0, memory_length 2000, epsilon 0.35636136239528393 total_time 722.0 step_num 112\n",
      "episode 1475, reward 268.0, memory_length 2000, epsilon 0.3561119967297726 total_time 724.0 step_num 114\n",
      "episode 1476, reward 67.0, memory_length 2000, epsilon 0.3558628055591468 total_time 721.0 step_num 124\n",
      "episode 1477, reward -142.0, memory_length 2000, epsilon 0.3556137887613028 total_time 725.0 step_num 111\n",
      "episode 1478, reward 391.0, memory_length 2000, epsilon 0.35536494621422243 total_time 730.0 step_num 123\n",
      "episode 1479, reward -75.0, memory_length 2000, epsilon 0.3551162777959729 total_time 726.0 step_num 112\n",
      "episode 1480, reward 332.0, memory_length 2000, epsilon 0.3548677833847064 total_time 722.0 step_num 110\n",
      "episode 1481, reward 202.0, memory_length 2000, epsilon 0.3546194628586611 total_time 721.0 step_num 123\n",
      "episode 1482, reward 143.0, memory_length 2000, epsilon 0.35437131609615946 total_time 722.0 step_num 127\n",
      "episode 1483, reward 91.0, memory_length 2000, epsilon 0.35412334297560993 total_time 736.0 step_num 108\n",
      "episode 1484, reward 670.0, memory_length 2000, epsilon 0.35387554337550553 total_time 721.0 step_num 118\n",
      "episode 1485, reward 212.0, memory_length 2000, epsilon 0.35362791717442443 total_time 728.0 step_num 113\n",
      "episode 1486, reward 436.0, memory_length 2000, epsilon 0.35338046425102987 total_time 730.0 step_num 110\n",
      "episode 1487, reward -210.0, memory_length 2000, epsilon 0.3531331844840699 total_time 726.0 step_num 114\n",
      "episode 1488, reward 174.0, memory_length 2000, epsilon 0.35288607775237724 total_time 732.0 step_num 119\n",
      "episode 1489, reward 395.0, memory_length 2000, epsilon 0.3526391439348699 total_time 722.0 step_num 113\n",
      "episode 1490, reward 210.0, memory_length 2000, epsilon 0.3523923829105501 total_time 723.0 step_num 119\n",
      "episode 1491, reward 484.0, memory_length 2000, epsilon 0.35214579455850487 total_time 724.0 step_num 125\n",
      "episode 1492, reward -275.0, memory_length 2000, epsilon 0.35189937875790617 total_time 721.0 step_num 127\n",
      "episode 1493, reward 172.0, memory_length 2000, epsilon 0.3516531353880101 total_time 727.0 step_num 132\n",
      "episode 1494, reward 140.0, memory_length 2000, epsilon 0.35140706432815727 total_time 728.0 step_num 129\n",
      "episode 1495, reward 239.0, memory_length 2000, epsilon 0.35116116545777304 total_time 728.0 step_num 111\n",
      "episode 1496, reward 188.0, memory_length 2000, epsilon 0.350915438656367 total_time 722.0 step_num 117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1497, reward 417.0, memory_length 2000, epsilon 0.3506698838035328 total_time 723.0 step_num 118\n",
      "episode 1498, reward -48.0, memory_length 2000, epsilon 0.35042450077894877 total_time 735.0 step_num 132\n",
      "episode 1499, reward 361.0, memory_length 2000, epsilon 0.35017928946237714 total_time 727.0 step_num 122\n",
      "episode 1500, reward 264.0, memory_length 2000, epsilon 0.3499342497336642 total_time 723.0 step_num 125\n",
      "episode 1501, reward 571.0, memory_length 2000, epsilon 0.3496893814727408 total_time 721.0 step_num 121\n",
      "episode 1502, reward 257.0, memory_length 2000, epsilon 0.3494446845596213 total_time 728.0 step_num 134\n",
      "episode 1503, reward 291.0, memory_length 2000, epsilon 0.3492001588744042 total_time 723.0 step_num 122\n",
      "episode 1504, reward 323.0, memory_length 2000, epsilon 0.3489558042972719 total_time 722.0 step_num 106\n",
      "episode 1505, reward -65.0, memory_length 2000, epsilon 0.34871162070849077 total_time 724.0 step_num 109\n",
      "episode 1506, reward 152.0, memory_length 2000, epsilon 0.34846760798841064 total_time 722.0 step_num 98\n",
      "episode 1507, reward 215.0, memory_length 2000, epsilon 0.34822376601746546 total_time 722.0 step_num 94\n",
      "episode 1508, reward -26.0, memory_length 2000, epsilon 0.3479800946761726 total_time 727.0 step_num 89\n",
      "episode 1509, reward 186.0, memory_length 2000, epsilon 0.3477365938451331 total_time 726.0 step_num 123\n",
      "episode 1510, reward 409.0, memory_length 2000, epsilon 0.3474932634050315 total_time 721.0 step_num 120\n",
      "episode 1511, reward -5.0, memory_length 2000, epsilon 0.34725010323663597 total_time 721.0 step_num 107\n",
      "episode 1512, reward 51.0, memory_length 2000, epsilon 0.34700711322079797 total_time 726.0 step_num 115\n",
      "episode 1513, reward 138.0, memory_length 2000, epsilon 0.34676429323845237 total_time 723.0 step_num 110\n",
      "episode 1514, reward 269.0, memory_length 2000, epsilon 0.3465216431706174 total_time 722.0 step_num 119\n",
      "episode 1515, reward 103.0, memory_length 2000, epsilon 0.34627916289839455 total_time 721.0 step_num 117\n",
      "episode 1516, reward 187.0, memory_length 2000, epsilon 0.34603685230296843 total_time 724.0 step_num 117\n",
      "episode 1517, reward 143.0, memory_length 2000, epsilon 0.34579471126560685 total_time 722.0 step_num 115\n",
      "episode 1518, reward 467.0, memory_length 2000, epsilon 0.3455527396676607 total_time 722.0 step_num 126\n",
      "episode 1519, reward -40.0, memory_length 2000, epsilon 0.34531093739056395 total_time 728.0 step_num 116\n",
      "episode 1520, reward 80.0, memory_length 2000, epsilon 0.3450693043158333 total_time 722.0 step_num 132\n",
      "episode 1521, reward 305.0, memory_length 2000, epsilon 0.34482784032506886 total_time 722.0 step_num 128\n",
      "episode 1522, reward 58.0, memory_length 2000, epsilon 0.344586545299953 total_time 721.0 step_num 117\n",
      "episode 1523, reward -24.0, memory_length 2000, epsilon 0.34434541912225114 total_time 723.0 step_num 127\n",
      "episode 1524, reward 163.0, memory_length 2000, epsilon 0.34410446167381165 total_time 736.0 step_num 118\n",
      "episode 1525, reward 373.0, memory_length 2000, epsilon 0.3438636728365652 total_time 721.0 step_num 109\n",
      "episode 1526, reward 28.0, memory_length 2000, epsilon 0.34362305249252534 total_time 727.0 step_num 122\n",
      "episode 1527, reward 195.0, memory_length 2000, epsilon 0.3433826005237881 total_time 726.0 step_num 120\n",
      "episode 1528, reward -7.0, memory_length 2000, epsilon 0.34314231681253204 total_time 725.0 step_num 105\n",
      "episode 1529, reward -8.0, memory_length 2000, epsilon 0.34290220124101795 total_time 736.0 step_num 121\n",
      "episode 1530, reward 278.0, memory_length 2000, epsilon 0.3426622536915894 total_time 722.0 step_num 126\n",
      "episode 1531, reward 160.0, memory_length 2000, epsilon 0.342422474046672 total_time 724.0 step_num 121\n",
      "episode 1532, reward 400.0, memory_length 2000, epsilon 0.34218286218877375 total_time 721.0 step_num 121\n",
      "episode 1533, reward 192.0, memory_length 2000, epsilon 0.34194341800048483 total_time 723.0 step_num 115\n",
      "episode 1534, reward 421.0, memory_length 2000, epsilon 0.3417041413644775 total_time 724.0 step_num 114\n",
      "episode 1535, reward 203.0, memory_length 2000, epsilon 0.3414650321635064 total_time 737.0 step_num 107\n",
      "episode 1536, reward 52.0, memory_length 2000, epsilon 0.3412260902804078 total_time 724.0 step_num 141\n",
      "episode 1537, reward 133.0, memory_length 2000, epsilon 0.34098731559810025 total_time 724.0 step_num 131\n",
      "episode 1538, reward 229.0, memory_length 2000, epsilon 0.34074870799958423 total_time 721.0 step_num 124\n",
      "episode 1539, reward 283.0, memory_length 2000, epsilon 0.340510267367942 total_time 721.0 step_num 118\n",
      "episode 1540, reward 90.0, memory_length 2000, epsilon 0.3402719935863374 total_time 729.0 step_num 121\n",
      "episode 1541, reward 222.0, memory_length 2000, epsilon 0.34003388653801664 total_time 726.0 step_num 113\n",
      "episode 1542, reward 139.0, memory_length 2000, epsilon 0.3397959461063071 total_time 721.0 step_num 116\n",
      "episode 1543, reward 439.0, memory_length 2000, epsilon 0.33955817217461776 total_time 724.0 step_num 124\n",
      "episode 1544, reward 48.0, memory_length 2000, epsilon 0.3393205646264397 total_time 723.0 step_num 123\n",
      "episode 1545, reward 71.0, memory_length 2000, epsilon 0.3390831233453451 total_time 722.0 step_num 126\n",
      "episode 1546, reward 51.0, memory_length 2000, epsilon 0.3388458482149877 total_time 726.0 step_num 141\n",
      "episode 1547, reward 130.0, memory_length 2000, epsilon 0.3386087391191028 total_time 721.0 step_num 122\n",
      "episode 1548, reward 17.0, memory_length 2000, epsilon 0.3383717959415068 total_time 722.0 step_num 112\n",
      "episode 1549, reward -307.0, memory_length 2000, epsilon 0.3381350185660975 total_time 722.0 step_num 129\n",
      "episode 1550, reward -47.0, memory_length 2000, epsilon 0.33789840687685413 total_time 724.0 step_num 123\n",
      "episode 1551, reward 319.0, memory_length 2000, epsilon 0.3376619607578369 total_time 721.0 step_num 115\n",
      "episode 1552, reward 317.0, memory_length 2000, epsilon 0.33742568009318713 total_time 725.0 step_num 123\n",
      "episode 1553, reward 211.0, memory_length 2000, epsilon 0.3371895647671274 total_time 721.0 step_num 126\n",
      "episode 1554, reward 409.0, memory_length 2000, epsilon 0.3369536146639612 total_time 721.0 step_num 108\n",
      "episode 1555, reward 364.0, memory_length 2000, epsilon 0.3367178296680728 total_time 721.0 step_num 117\n",
      "episode 1556, reward 6.0, memory_length 2000, epsilon 0.3364822096639277 total_time 726.0 step_num 124\n",
      "episode 1557, reward 332.0, memory_length 2000, epsilon 0.33624675453607217 total_time 722.0 step_num 119\n",
      "episode 1558, reward 344.0, memory_length 2000, epsilon 0.336011464169133 total_time 725.0 step_num 113\n",
      "episode 1559, reward 376.0, memory_length 2000, epsilon 0.3357763384478181 total_time 724.0 step_num 139\n",
      "episode 1560, reward 197.0, memory_length 2000, epsilon 0.33554137725691563 total_time 722.0 step_num 119\n",
      "episode 1561, reward 354.0, memory_length 2000, epsilon 0.3353065804812948 total_time 723.0 step_num 118\n",
      "episode 1562, reward 196.0, memory_length 2000, epsilon 0.3350719480059052 total_time 724.0 step_num 126\n",
      "episode 1563, reward 273.0, memory_length 2000, epsilon 0.33483747971577665 total_time 723.0 step_num 117\n",
      "episode 1564, reward 281.0, memory_length 2000, epsilon 0.33460317549602 total_time 725.0 step_num 118\n",
      "episode 1565, reward 30.0, memory_length 2000, epsilon 0.334369035231826 total_time 723.0 step_num 129\n",
      "episode 1566, reward 312.0, memory_length 2000, epsilon 0.33413505880846583 total_time 726.0 step_num 123\n",
      "episode 1567, reward 301.0, memory_length 2000, epsilon 0.33390124611129135 total_time 721.0 step_num 129\n",
      "episode 1568, reward 311.0, memory_length 2000, epsilon 0.33366759702573406 total_time 728.0 step_num 115\n",
      "episode 1569, reward -123.0, memory_length 2000, epsilon 0.33343411143730595 total_time 723.0 step_num 121\n",
      "episode 1570, reward 183.0, memory_length 2000, epsilon 0.3332007892315991 total_time 723.0 step_num 107\n",
      "episode 1571, reward 175.0, memory_length 2000, epsilon 0.3329676302942858 total_time 721.0 step_num 117\n",
      "episode 1572, reward 202.0, memory_length 2000, epsilon 0.33273463451111784 total_time 721.0 step_num 115\n",
      "episode 1573, reward 162.0, memory_length 2000, epsilon 0.33250180176792754 total_time 729.0 step_num 111\n",
      "episode 1574, reward -28.0, memory_length 2000, epsilon 0.33226913195062674 total_time 722.0 step_num 111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1575, reward 220.0, memory_length 2000, epsilon 0.3320366249452072 total_time 730.0 step_num 119\n",
      "episode 1576, reward -103.0, memory_length 2000, epsilon 0.3318042806377406 total_time 728.0 step_num 117\n",
      "episode 1577, reward 243.0, memory_length 2000, epsilon 0.3315720989143781 total_time 729.0 step_num 108\n",
      "episode 1578, reward 219.0, memory_length 2000, epsilon 0.33134007966135065 total_time 723.0 step_num 106\n",
      "episode 1579, reward 80.0, memory_length 2000, epsilon 0.331108222764969 total_time 722.0 step_num 124\n",
      "episode 1580, reward 67.0, memory_length 2000, epsilon 0.330876528111623 total_time 721.0 step_num 111\n",
      "episode 1581, reward 418.0, memory_length 2000, epsilon 0.33064499558778243 total_time 721.0 step_num 109\n",
      "episode 1582, reward 186.0, memory_length 2000, epsilon 0.33041362507999644 total_time 726.0 step_num 121\n",
      "episode 1583, reward 203.0, memory_length 2000, epsilon 0.3301824164748932 total_time 728.0 step_num 115\n",
      "episode 1584, reward 203.0, memory_length 2000, epsilon 0.3299513696591807 total_time 728.0 step_num 123\n",
      "episode 1585, reward 238.0, memory_length 2000, epsilon 0.3297204845196459 total_time 721.0 step_num 113\n",
      "episode 1586, reward 252.0, memory_length 2000, epsilon 0.32948976094315513 total_time 729.0 step_num 128\n",
      "episode 1587, reward 566.0, memory_length 2000, epsilon 0.32925919881665383 total_time 722.0 step_num 116\n",
      "episode 1588, reward 273.0, memory_length 2000, epsilon 0.32902879802716656 total_time 723.0 step_num 118\n",
      "episode 1589, reward 39.0, memory_length 2000, epsilon 0.32879855846179684 total_time 723.0 step_num 128\n",
      "episode 1590, reward -28.0, memory_length 2000, epsilon 0.32856848000772737 total_time 722.0 step_num 118\n",
      "episode 1591, reward 497.0, memory_length 2000, epsilon 0.3283385625522197 total_time 725.0 step_num 105\n",
      "episode 1592, reward 580.0, memory_length 2000, epsilon 0.3281088059826142 total_time 721.0 step_num 127\n",
      "episode 1593, reward 119.0, memory_length 2000, epsilon 0.32787921018633026 total_time 725.0 step_num 122\n",
      "episode 1594, reward 352.0, memory_length 2000, epsilon 0.32764977505086584 total_time 727.0 step_num 113\n",
      "episode 1595, reward 564.0, memory_length 2000, epsilon 0.3274205004637977 total_time 726.0 step_num 127\n",
      "episode 1596, reward 94.0, memory_length 2000, epsilon 0.32719138631278144 total_time 721.0 step_num 108\n",
      "episode 1597, reward 93.0, memory_length 2000, epsilon 0.326962432485551 total_time 723.0 step_num 130\n",
      "episode 1598, reward 155.0, memory_length 2000, epsilon 0.32673363886991896 total_time 734.0 step_num 123\n",
      "episode 1599, reward 56.0, memory_length 2000, epsilon 0.3265050053537765 total_time 725.0 step_num 132\n",
      "episode 1600, reward 170.0, memory_length 2000, epsilon 0.3262765318250933 total_time 722.0 step_num 115\n",
      "episode 1601, reward 229.0, memory_length 2000, epsilon 0.32604821817191715 total_time 721.0 step_num 129\n",
      "episode 1602, reward -104.0, memory_length 2000, epsilon 0.32582006428237437 total_time 730.0 step_num 121\n",
      "episode 1603, reward 65.0, memory_length 2000, epsilon 0.32559207004466967 total_time 725.0 step_num 130\n",
      "episode 1604, reward 29.0, memory_length 2000, epsilon 0.32536423534708586 total_time 725.0 step_num 122\n",
      "episode 1605, reward 382.0, memory_length 2000, epsilon 0.3251365600779838 total_time 721.0 step_num 115\n",
      "episode 1606, reward 400.0, memory_length 2000, epsilon 0.3249090441258027 total_time 721.0 step_num 114\n",
      "episode 1607, reward 182.0, memory_length 2000, epsilon 0.3246816873790597 total_time 725.0 step_num 114\n",
      "episode 1608, reward 359.0, memory_length 2000, epsilon 0.3244544897263501 total_time 722.0 step_num 117\n",
      "episode 1609, reward 130.0, memory_length 2000, epsilon 0.32422745105634687 total_time 730.0 step_num 118\n",
      "episode 1610, reward -10.0, memory_length 2000, epsilon 0.32400057125780124 total_time 722.0 step_num 115\n",
      "episode 1611, reward -218.0, memory_length 2000, epsilon 0.3237738502195419 total_time 724.0 step_num 113\n",
      "episode 1612, reward 299.0, memory_length 2000, epsilon 0.32354728783047565 total_time 725.0 step_num 114\n",
      "episode 1613, reward 38.0, memory_length 2000, epsilon 0.323320883979587 total_time 725.0 step_num 111\n",
      "episode 1614, reward 232.0, memory_length 2000, epsilon 0.32309463855593795 total_time 724.0 step_num 119\n",
      "episode 1615, reward 336.0, memory_length 2000, epsilon 0.32286855144866816 total_time 723.0 step_num 118\n",
      "episode 1616, reward 248.0, memory_length 2000, epsilon 0.32264262254699516 total_time 728.0 step_num 115\n",
      "episode 1617, reward 40.0, memory_length 2000, epsilon 0.3224168517402136 total_time 721.0 step_num 104\n",
      "episode 1618, reward 303.0, memory_length 2000, epsilon 0.32219123891769585 total_time 726.0 step_num 129\n",
      "episode 1619, reward 44.0, memory_length 2000, epsilon 0.32196578396889164 total_time 722.0 step_num 128\n",
      "episode 1620, reward 192.0, memory_length 2000, epsilon 0.321740486783328 total_time 723.0 step_num 133\n",
      "episode 1621, reward 110.0, memory_length 2000, epsilon 0.32151534725060926 total_time 725.0 step_num 119\n",
      "episode 1622, reward 260.0, memory_length 2000, epsilon 0.3212903652604172 total_time 722.0 step_num 109\n",
      "episode 1623, reward 382.0, memory_length 2000, epsilon 0.32106554070251053 total_time 721.0 step_num 121\n",
      "episode 1624, reward -31.0, memory_length 2000, epsilon 0.3208408734667252 total_time 728.0 step_num 106\n",
      "episode 1625, reward 299.0, memory_length 2000, epsilon 0.3206163634429743 total_time 725.0 step_num 122\n",
      "episode 1626, reward 146.0, memory_length 2000, epsilon 0.32039201052124794 total_time 725.0 step_num 112\n",
      "episode 1627, reward 76.0, memory_length 2000, epsilon 0.32016781459161303 total_time 721.0 step_num 125\n",
      "episode 1628, reward 508.0, memory_length 2000, epsilon 0.31994377554421377 total_time 721.0 step_num 125\n",
      "episode 1629, reward 389.0, memory_length 2000, epsilon 0.3197198932692709 total_time 725.0 step_num 117\n",
      "episode 1630, reward 178.0, memory_length 2000, epsilon 0.31949616765708216 total_time 724.0 step_num 124\n",
      "episode 1631, reward 291.0, memory_length 2000, epsilon 0.31927259859802193 total_time 723.0 step_num 124\n",
      "episode 1632, reward 294.0, memory_length 2000, epsilon 0.3190491859825414 total_time 726.0 step_num 127\n",
      "episode 1633, reward -192.0, memory_length 2000, epsilon 0.3188259297011684 total_time 726.0 step_num 110\n",
      "episode 1634, reward 212.0, memory_length 2000, epsilon 0.31860282964450737 total_time 728.0 step_num 112\n",
      "episode 1635, reward -55.0, memory_length 2000, epsilon 0.31837988570323916 total_time 722.0 step_num 121\n",
      "episode 1636, reward 68.0, memory_length 2000, epsilon 0.3181570977681214 total_time 728.0 step_num 117\n",
      "episode 1637, reward 37.0, memory_length 2000, epsilon 0.3179344657299879 total_time 727.0 step_num 110\n",
      "episode 1638, reward 250.0, memory_length 2000, epsilon 0.3177119894797489 total_time 724.0 step_num 117\n",
      "episode 1639, reward 562.0, memory_length 2000, epsilon 0.31748966890839114 total_time 721.0 step_num 127\n",
      "episode 1640, reward -68.0, memory_length 2000, epsilon 0.3172675039069775 total_time 730.0 step_num 130\n",
      "episode 1641, reward 119.0, memory_length 2000, epsilon 0.31704549436664714 total_time 725.0 step_num 129\n",
      "episode 1642, reward 364.0, memory_length 2000, epsilon 0.31682364017861536 total_time 730.0 step_num 121\n",
      "episode 1643, reward 344.0, memory_length 2000, epsilon 0.3166019412341736 total_time 725.0 step_num 114\n",
      "episode 1644, reward 353.0, memory_length 2000, epsilon 0.31638039742468926 total_time 725.0 step_num 120\n",
      "episode 1645, reward 413.0, memory_length 2000, epsilon 0.3161590086416062 total_time 722.0 step_num 115\n",
      "episode 1646, reward 377.0, memory_length 2000, epsilon 0.3159377747764436 total_time 722.0 step_num 132\n",
      "episode 1647, reward 445.0, memory_length 2000, epsilon 0.3157166957207969 total_time 721.0 step_num 119\n",
      "episode 1648, reward 364.0, memory_length 2000, epsilon 0.3154957713663375 total_time 721.0 step_num 133\n",
      "episode 1649, reward -12.0, memory_length 2000, epsilon 0.3152750016048124 total_time 726.0 step_num 137\n",
      "episode 1650, reward 425.0, memory_length 2000, epsilon 0.3150543863280443 total_time 725.0 step_num 130\n",
      "episode 1651, reward 265.0, memory_length 2000, epsilon 0.3148339254279319 total_time 721.0 step_num 119\n",
      "episode 1652, reward -2.0, memory_length 2000, epsilon 0.31461361879644917 total_time 724.0 step_num 117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1653, reward -20.0, memory_length 2000, epsilon 0.314393466325646 total_time 724.0 step_num 114\n",
      "episode 1654, reward 200.0, memory_length 2000, epsilon 0.31417346790764766 total_time 725.0 step_num 128\n",
      "episode 1655, reward 121.0, memory_length 2000, epsilon 0.3139536234346548 total_time 721.0 step_num 120\n",
      "episode 1656, reward 380.0, memory_length 2000, epsilon 0.31373393279894374 total_time 725.0 step_num 116\n",
      "episode 1657, reward 272.0, memory_length 2000, epsilon 0.3135143958928661 total_time 725.0 step_num 114\n",
      "episode 1658, reward 725.0, memory_length 2000, epsilon 0.31329501260884857 total_time 728.0 step_num 115\n",
      "episode 1659, reward 286.0, memory_length 2000, epsilon 0.3130757828393936 total_time 733.0 step_num 116\n",
      "episode 1660, reward -266.0, memory_length 2000, epsilon 0.3128567064770785 total_time 721.0 step_num 116\n",
      "episode 1661, reward 148.0, memory_length 2000, epsilon 0.3126377834145557 total_time 721.0 step_num 115\n",
      "episode 1662, reward 42.0, memory_length 2000, epsilon 0.31241901354455315 total_time 726.0 step_num 119\n",
      "episode 1663, reward 427.0, memory_length 2000, epsilon 0.3122003967598735 total_time 721.0 step_num 120\n",
      "episode 1664, reward 41.0, memory_length 2000, epsilon 0.3119819329533944 total_time 728.0 step_num 123\n",
      "episode 1665, reward 145.0, memory_length 2000, epsilon 0.31176362201806873 total_time 736.0 step_num 112\n",
      "episode 1666, reward 223.0, memory_length 2000, epsilon 0.3115454638469242 total_time 724.0 step_num 115\n",
      "episode 1667, reward -32.0, memory_length 2000, epsilon 0.311327458333063 total_time 730.0 step_num 105\n",
      "episode 1668, reward 377.0, memory_length 2000, epsilon 0.31110960536966276 total_time 722.0 step_num 117\n",
      "episode 1669, reward 104.0, memory_length 2000, epsilon 0.31089190484997536 total_time 728.0 step_num 126\n",
      "episode 1670, reward 21.0, memory_length 2000, epsilon 0.31067435666732746 total_time 723.0 step_num 113\n",
      "episode 1671, reward 334.0, memory_length 2000, epsilon 0.31045696071512063 total_time 727.0 step_num 126\n",
      "episode 1672, reward -20.0, memory_length 2000, epsilon 0.3102397168868308 total_time 724.0 step_num 124\n",
      "episode 1673, reward 49.0, memory_length 2000, epsilon 0.3100226250760083 total_time 721.0 step_num 111\n",
      "episode 1674, reward 462.0, memory_length 2000, epsilon 0.30980568517627843 total_time 723.0 step_num 112\n",
      "episode 1675, reward 347.0, memory_length 2000, epsilon 0.3095888970813404 total_time 728.0 step_num 127\n",
      "episode 1676, reward 254.0, memory_length 2000, epsilon 0.3093722606849682 total_time 725.0 step_num 123\n",
      "episode 1677, reward 58.0, memory_length 2000, epsilon 0.3091557758810099 total_time 721.0 step_num 110\n",
      "episode 1678, reward 377.0, memory_length 2000, epsilon 0.30893944256338796 total_time 722.0 step_num 116\n",
      "episode 1679, reward -89.0, memory_length 2000, epsilon 0.30872326062609906 total_time 727.0 step_num 107\n",
      "episode 1680, reward 192.0, memory_length 2000, epsilon 0.30850722996321406 total_time 723.0 step_num 126\n",
      "episode 1681, reward 347.0, memory_length 2000, epsilon 0.3082913504688779 total_time 737.0 step_num 115\n",
      "episode 1682, reward 192.0, memory_length 2000, epsilon 0.30807562203730965 total_time 723.0 step_num 130\n",
      "episode 1683, reward 225.0, memory_length 2000, epsilon 0.30786004456280236 total_time 729.0 step_num 114\n",
      "episode 1684, reward 383.0, memory_length 2000, epsilon 0.30764461793972303 total_time 728.0 step_num 123\n",
      "episode 1685, reward 166.0, memory_length 2000, epsilon 0.3074293420625127 total_time 721.0 step_num 122\n",
      "episode 1686, reward 224.0, memory_length 2000, epsilon 0.30721421682568617 total_time 722.0 step_num 128\n",
      "episode 1687, reward 107.0, memory_length 2000, epsilon 0.3069992421238319 total_time 722.0 step_num 119\n",
      "episode 1688, reward 269.0, memory_length 2000, epsilon 0.3067844178516125 total_time 722.0 step_num 118\n",
      "episode 1689, reward 361.0, memory_length 2000, epsilon 0.306569743903764 total_time 727.0 step_num 121\n",
      "episode 1690, reward 274.0, memory_length 2000, epsilon 0.3063552201750961 total_time 721.0 step_num 104\n",
      "episode 1691, reward 215.0, memory_length 2000, epsilon 0.3061408465604923 total_time 722.0 step_num 118\n",
      "episode 1692, reward 346.0, memory_length 2000, epsilon 0.30592662295490936 total_time 730.0 step_num 123\n",
      "episode 1693, reward 240.0, memory_length 2000, epsilon 0.30571254925337776 total_time 726.0 step_num 130\n",
      "episode 1694, reward 285.0, memory_length 2000, epsilon 0.3054986253510015 total_time 726.0 step_num 119\n",
      "episode 1695, reward 254.0, memory_length 2000, epsilon 0.30528485114295767 total_time 725.0 step_num 123\n",
      "episode 1696, reward 220.0, memory_length 2000, epsilon 0.30507122652449703 total_time 721.0 step_num 115\n",
      "episode 1697, reward -64.0, memory_length 2000, epsilon 0.30485775139094357 total_time 722.0 step_num 127\n",
      "episode 1698, reward 235.0, memory_length 2000, epsilon 0.3046444256376944 total_time 736.0 step_num 124\n",
      "episode 1699, reward 241.0, memory_length 2000, epsilon 0.3044312491602198 total_time 724.0 step_num 115\n",
      "episode 1700, reward 49.0, memory_length 2000, epsilon 0.30421822185406344 total_time 721.0 step_num 118\n",
      "episode 1701, reward 162.0, memory_length 2000, epsilon 0.3040053436148418 total_time 729.0 step_num 116\n",
      "episode 1702, reward 139.0, memory_length 2000, epsilon 0.30379261433824467 total_time 721.0 step_num 127\n",
      "episode 1703, reward 22.0, memory_length 2000, epsilon 0.30358003392003463 total_time 721.0 step_num 121\n",
      "episode 1704, reward -91.0, memory_length 2000, epsilon 0.30336760225604725 total_time 731.0 step_num 118\n",
      "episode 1705, reward 202.0, memory_length 2000, epsilon 0.30315531924219113 total_time 721.0 step_num 120\n",
      "episode 1706, reward 451.0, memory_length 2000, epsilon 0.3029431847744475 total_time 727.0 step_num 125\n",
      "episode 1707, reward 323.0, memory_length 2000, epsilon 0.3027311987488704 total_time 731.0 step_num 120\n",
      "episode 1708, reward -81.0, memory_length 2000, epsilon 0.3025193610615868 total_time 738.0 step_num 118\n",
      "episode 1709, reward -140.0, memory_length 2000, epsilon 0.3023076716087961 total_time 730.0 step_num 117\n",
      "episode 1710, reward -12.0, memory_length 2000, epsilon 0.3020961302867706 total_time 726.0 step_num 126\n",
      "episode 1711, reward 114.0, memory_length 2000, epsilon 0.30188473699185503 total_time 726.0 step_num 112\n",
      "episode 1712, reward 268.0, memory_length 2000, epsilon 0.3016734916204666 total_time 724.0 step_num 129\n",
      "episode 1713, reward 355.0, memory_length 2000, epsilon 0.30146239406909503 total_time 721.0 step_num 120\n",
      "episode 1714, reward 85.0, memory_length 2000, epsilon 0.30125144423430267 total_time 721.0 step_num 116\n",
      "episode 1715, reward 292.0, memory_length 2000, epsilon 0.30104064201272396 total_time 730.0 step_num 123\n",
      "episode 1716, reward 568.0, memory_length 2000, epsilon 0.3008299873010658 total_time 736.0 step_num 117\n",
      "episode 1717, reward 427.0, memory_length 2000, epsilon 0.3006194799961075 total_time 721.0 step_num 116\n",
      "episode 1718, reward 238.0, memory_length 2000, epsilon 0.30040911999470044 total_time 721.0 step_num 108\n",
      "episode 1719, reward 298.0, memory_length 2000, epsilon 0.3001989071937682 total_time 736.0 step_num 122\n",
      "episode 1720, reward 139.0, memory_length 2000, epsilon 0.2999888414903064 total_time 721.0 step_num 115\n",
      "episode 1721, reward 135.0, memory_length 2000, epsilon 0.2997789227813831 total_time 729.0 step_num 121\n",
      "episode 1722, reward 224.0, memory_length 2000, epsilon 0.2995691509641378 total_time 722.0 step_num 116\n",
      "episode 1723, reward 148.0, memory_length 2000, epsilon 0.2993595259357825 total_time 721.0 step_num 108\n",
      "episode 1724, reward 319.0, memory_length 2000, epsilon 0.29915004759360087 total_time 721.0 step_num 126\n",
      "episode 1725, reward 10.0, memory_length 2000, epsilon 0.29894071583494863 total_time 736.0 step_num 107\n",
      "episode 1726, reward 237.0, memory_length 2000, epsilon 0.2987315305572531 total_time 723.0 step_num 119\n",
      "episode 1727, reward 305.0, memory_length 2000, epsilon 0.2985224916580135 total_time 722.0 step_num 119\n",
      "episode 1728, reward 655.0, memory_length 2000, epsilon 0.2983135990348008 total_time 724.0 step_num 123\n",
      "episode 1729, reward 335.0, memory_length 2000, epsilon 0.2981048525852576 total_time 725.0 step_num 112\n",
      "episode 1730, reward 272.0, memory_length 2000, epsilon 0.2978962522070981 total_time 725.0 step_num 125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1731, reward 473.0, memory_length 2000, epsilon 0.29768779779810817 total_time 728.0 step_num 124\n",
      "episode 1732, reward 390.0, memory_length 2000, epsilon 0.29747948925614515 total_time 723.0 step_num 108\n",
      "episode 1733, reward 319.0, memory_length 2000, epsilon 0.29727132647913773 total_time 730.0 step_num 118\n",
      "episode 1734, reward 202.0, memory_length 2000, epsilon 0.2970633093650863 total_time 721.0 step_num 108\n",
      "episode 1735, reward 229.0, memory_length 2000, epsilon 0.2968554378120624 total_time 730.0 step_num 117\n",
      "episode 1736, reward -59.0, memory_length 2000, epsilon 0.2966477117182089 total_time 730.0 step_num 115\n",
      "episode 1737, reward 224.0, memory_length 2000, epsilon 0.2964401309817402 total_time 722.0 step_num 107\n",
      "episode 1738, reward -82.0, memory_length 2000, epsilon 0.29623269550094156 total_time 722.0 step_num 112\n",
      "episode 1739, reward 49.0, memory_length 2000, epsilon 0.2960254051741696 total_time 721.0 step_num 116\n",
      "episode 1740, reward 234.0, memory_length 2000, epsilon 0.2958182598998521 total_time 729.0 step_num 113\n",
      "episode 1741, reward 104.0, memory_length 2000, epsilon 0.29561125957648793 total_time 728.0 step_num 119\n",
      "episode 1742, reward 45.0, memory_length 2000, epsilon 0.2954044041026468 total_time 729.0 step_num 132\n",
      "episode 1743, reward 562.0, memory_length 2000, epsilon 0.2951976933769696 total_time 721.0 step_num 128\n",
      "episode 1744, reward 71.0, memory_length 2000, epsilon 0.2949911272981681 total_time 722.0 step_num 121\n",
      "episode 1745, reward 170.0, memory_length 2000, epsilon 0.2947847057650248 total_time 722.0 step_num 128\n",
      "episode 1746, reward 139.0, memory_length 2000, epsilon 0.2945784286763934 total_time 721.0 step_num 111\n",
      "episode 1747, reward 207.0, memory_length 2000, epsilon 0.29437229593119774 total_time 729.0 step_num 118\n",
      "episode 1748, reward -34.0, memory_length 2000, epsilon 0.2941663074284331 total_time 725.0 step_num 113\n",
      "episode 1749, reward 427.0, memory_length 2000, epsilon 0.293960463067165 total_time 721.0 step_num 117\n",
      "episode 1750, reward 512.0, memory_length 2000, epsilon 0.29375476274652956 total_time 731.0 step_num 122\n",
      "episode 1751, reward 184.0, memory_length 2000, epsilon 0.2935492063657339 total_time 721.0 step_num 116\n",
      "episode 1752, reward 317.0, memory_length 2000, epsilon 0.2933437938240551 total_time 725.0 step_num 126\n",
      "episode 1753, reward 131.0, memory_length 2000, epsilon 0.29313852502084115 total_time 728.0 step_num 113\n",
      "episode 1754, reward 424.0, memory_length 2000, epsilon 0.2929333998555104 total_time 736.0 step_num 139\n",
      "episode 1755, reward 301.0, memory_length 2000, epsilon 0.2927284182275514 total_time 721.0 step_num 114\n",
      "episode 1756, reward 111.0, memory_length 2000, epsilon 0.2925235800365232 total_time 723.0 step_num 122\n",
      "episode 1757, reward 103.0, memory_length 2000, epsilon 0.2923188851820551 total_time 721.0 step_num 109\n",
      "episode 1758, reward -31.0, memory_length 2000, epsilon 0.2921143335638466 total_time 728.0 step_num 125\n",
      "episode 1759, reward 17.0, memory_length 2000, epsilon 0.2919099250816673 total_time 722.0 step_num 131\n",
      "episode 1760, reward 373.0, memory_length 2000, epsilon 0.29170565963535716 total_time 721.0 step_num 110\n",
      "episode 1761, reward 151.0, memory_length 2000, epsilon 0.2915015371248262 total_time 724.0 step_num 107\n",
      "episode 1762, reward 354.0, memory_length 2000, epsilon 0.2912975574500541 total_time 723.0 step_num 126\n",
      "episode 1763, reward 238.0, memory_length 2000, epsilon 0.291093720511091 total_time 721.0 step_num 128\n",
      "episode 1764, reward 298.0, memory_length 2000, epsilon 0.2908900262080569 total_time 727.0 step_num 137\n",
      "episode 1765, reward 211.0, memory_length 2000, epsilon 0.2906864744411413 total_time 721.0 step_num 131\n",
      "episode 1766, reward 220.0, memory_length 2000, epsilon 0.2904830651106041 total_time 721.0 step_num 112\n",
      "episode 1767, reward 160.0, memory_length 2000, epsilon 0.2902797981167746 total_time 724.0 step_num 112\n",
      "episode 1768, reward 267.0, memory_length 2000, epsilon 0.29007667336005194 total_time 726.0 step_num 110\n",
      "episode 1769, reward 390.0, memory_length 2000, epsilon 0.2898736907409051 total_time 723.0 step_num 121\n",
      "episode 1770, reward -4.0, memory_length 2000, epsilon 0.2896708501598725 total_time 728.0 step_num 100\n",
      "episode 1771, reward 269.0, memory_length 2000, epsilon 0.2894681515175622 total_time 722.0 step_num 114\n",
      "episode 1772, reward 517.0, memory_length 2000, epsilon 0.289265594714652 total_time 721.0 step_num 124\n",
      "episode 1773, reward 157.0, memory_length 2000, epsilon 0.28906317965188894 total_time 721.0 step_num 123\n",
      "episode 1774, reward 77.0, memory_length 2000, epsilon 0.2888609062300898 total_time 728.0 step_num 128\n",
      "episode 1775, reward 156.0, memory_length 2000, epsilon 0.2886587743501405 total_time 723.0 step_num 119\n",
      "episode 1776, reward -205.0, memory_length 2000, epsilon 0.2884567839129963 total_time 725.0 step_num 118\n",
      "episode 1777, reward 137.0, memory_length 2000, epsilon 0.288254934819682 total_time 725.0 step_num 112\n",
      "episode 1778, reward 152.0, memory_length 2000, epsilon 0.2880532269712916 total_time 722.0 step_num 126\n",
      "episode 1779, reward 219.0, memory_length 2000, epsilon 0.2878516602689881 total_time 723.0 step_num 119\n",
      "episode 1780, reward -110.0, memory_length 2000, epsilon 0.28765023461400396 total_time 724.0 step_num 119\n",
      "episode 1781, reward 274.0, memory_length 2000, epsilon 0.2874489499076405 total_time 721.0 step_num 125\n",
      "episode 1782, reward 235.0, memory_length 2000, epsilon 0.28724780605126826 total_time 727.0 step_num 108\n",
      "episode 1783, reward 287.0, memory_length 2000, epsilon 0.28704680294632673 total_time 722.0 step_num 130\n",
      "episode 1784, reward 607.0, memory_length 2000, epsilon 0.2868459404943244 total_time 721.0 step_num 109\n",
      "episode 1785, reward 16.0, memory_length 2000, epsilon 0.28664521859683867 total_time 724.0 step_num 116\n",
      "episode 1786, reward 203.0, memory_length 2000, epsilon 0.2864446371555157 total_time 728.0 step_num 116\n",
      "episode 1787, reward 105.0, memory_length 2000, epsilon 0.2862441960720708 total_time 726.0 step_num 112\n",
      "episode 1788, reward 134.0, memory_length 2000, epsilon 0.28604389524828755 total_time 722.0 step_num 112\n",
      "episode 1789, reward 392.0, memory_length 2000, epsilon 0.2858437345860188 total_time 728.0 step_num 117\n",
      "episode 1790, reward 200.0, memory_length 2000, epsilon 0.2856437139871857 total_time 725.0 step_num 121\n",
      "episode 1791, reward 427.0, memory_length 2000, epsilon 0.2854438333537781 total_time 721.0 step_num 131\n",
      "episode 1792, reward 229.0, memory_length 2000, epsilon 0.2852440925878546 total_time 721.0 step_num 114\n",
      "episode 1793, reward 42.0, memory_length 2000, epsilon 0.28504449159154227 total_time 726.0 step_num 113\n",
      "episode 1794, reward 265.0, memory_length 2000, epsilon 0.2848450302670364 total_time 721.0 step_num 125\n",
      "episode 1795, reward 34.0, memory_length 2000, epsilon 0.28464570851660115 total_time 724.0 step_num 111\n",
      "episode 1796, reward 182.0, memory_length 2000, epsilon 0.2844465262425686 total_time 725.0 step_num 115\n",
      "episode 1797, reward 153.0, memory_length 2000, epsilon 0.2842474833473398 total_time 729.0 step_num 130\n",
      "episode 1798, reward 152.0, memory_length 2000, epsilon 0.28404857973338343 total_time 722.0 step_num 118\n",
      "episode 1799, reward 209.0, memory_length 2000, epsilon 0.28384981530323683 total_time 725.0 step_num 103\n",
      "episode 1800, reward 49.0, memory_length 2000, epsilon 0.2836511899595054 total_time 721.0 step_num 123\n",
      "episode 1801, reward 578.0, memory_length 2000, epsilon 0.28345270360486274 total_time 725.0 step_num 127\n",
      "episode 1802, reward 233.0, memory_length 2000, epsilon 0.28325435614205047 total_time 722.0 step_num 127\n",
      "episode 1803, reward 290.0, memory_length 2000, epsilon 0.2830561474738784 total_time 725.0 step_num 116\n",
      "episode 1804, reward 157.0, memory_length 2000, epsilon 0.28285807750322434 total_time 721.0 step_num 120\n",
      "episode 1805, reward 107.0, memory_length 2000, epsilon 0.2826601461330338 total_time 731.0 step_num 117\n",
      "episode 1806, reward 384.0, memory_length 2000, epsilon 0.28246235326632063 total_time 726.0 step_num 118\n",
      "episode 1807, reward 44.0, memory_length 2000, epsilon 0.2822646988061661 total_time 722.0 step_num 110\n",
      "episode 1808, reward -38.0, memory_length 2000, epsilon 0.2820671826557197 total_time 724.0 step_num 121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1809, reward 231.0, memory_length 2000, epsilon 0.28186980471819845 total_time 726.0 step_num 119\n",
      "episode 1810, reward 382.0, memory_length 2000, epsilon 0.28167256489688713 total_time 730.0 step_num 120\n",
      "episode 1811, reward 490.0, memory_length 2000, epsilon 0.2814754630951382 total_time 721.0 step_num 113\n",
      "episode 1812, reward 353.0, memory_length 2000, epsilon 0.2812784992163719 total_time 725.0 step_num 119\n",
      "episode 1813, reward 219.0, memory_length 2000, epsilon 0.28108167316407584 total_time 723.0 step_num 118\n",
      "episode 1814, reward 287.0, memory_length 2000, epsilon 0.28088498484180513 total_time 722.0 step_num 113\n",
      "episode 1815, reward 129.0, memory_length 2000, epsilon 0.28068843415318273 total_time 723.0 step_num 115\n",
      "episode 1816, reward 492.0, memory_length 2000, epsilon 0.2804920210018987 total_time 726.0 step_num 127\n",
      "episode 1817, reward 314.0, memory_length 2000, epsilon 0.2802957452917105 total_time 722.0 step_num 114\n",
      "episode 1818, reward 211.0, memory_length 2000, epsilon 0.2800996069264431 total_time 721.0 step_num 123\n",
      "episode 1819, reward 220.0, memory_length 2000, epsilon 0.2799036058099888 total_time 721.0 step_num 112\n",
      "episode 1820, reward 479.0, memory_length 2000, epsilon 0.2797077418463068 total_time 725.0 step_num 119\n",
      "episode 1821, reward 113.0, memory_length 2000, epsilon 0.279512014939424 total_time 728.0 step_num 132\n",
      "episode 1822, reward 205.0, memory_length 2000, epsilon 0.27931642499343406 total_time 724.0 step_num 124\n",
      "episode 1823, reward 116.0, memory_length 2000, epsilon 0.279120971912498 total_time 722.0 step_num 125\n",
      "episode 1824, reward 85.0, memory_length 2000, epsilon 0.27892565560084376 total_time 730.0 step_num 116\n",
      "episode 1825, reward 222.0, memory_length 2000, epsilon 0.27873047596276634 total_time 726.0 step_num 105\n",
      "episode 1826, reward 305.0, memory_length 2000, epsilon 0.27853543290262767 total_time 722.0 step_num 130\n",
      "episode 1827, reward 158.0, memory_length 2000, epsilon 0.2783405263248568 total_time 728.0 step_num 101\n",
      "episode 1828, reward 22.0, memory_length 2000, epsilon 0.27814575613394926 total_time 721.0 step_num 110\n",
      "episode 1829, reward 330.0, memory_length 2000, epsilon 0.2779511222344679 total_time 726.0 step_num 114\n",
      "episode 1830, reward 94.0, memory_length 2000, epsilon 0.277756624531042 total_time 721.0 step_num 118\n",
      "episode 1831, reward 247.0, memory_length 2000, epsilon 0.2775622629283676 total_time 721.0 step_num 122\n",
      "episode 1832, reward 44.0, memory_length 2000, epsilon 0.27736803733120763 total_time 722.0 step_num 116\n",
      "episode 1833, reward 165.0, memory_length 2000, epsilon 0.2771739476443915 total_time 723.0 step_num 115\n",
      "episode 1834, reward 214.0, memory_length 2000, epsilon 0.27697999377281524 total_time 724.0 step_num 124\n",
      "episode 1835, reward 135.0, memory_length 2000, epsilon 0.27678617562144153 total_time 729.0 step_num 118\n",
      "episode 1836, reward 355.0, memory_length 2000, epsilon 0.2765924930952994 total_time 721.0 step_num 104\n",
      "episode 1837, reward 179.0, memory_length 2000, epsilon 0.27639894609948434 total_time 722.0 step_num 144\n",
      "episode 1838, reward -32.0, memory_length 2000, epsilon 0.2762055345391584 total_time 730.0 step_num 119\n",
      "episode 1839, reward 53.0, memory_length 2000, epsilon 0.27601225831955006 total_time 722.0 step_num 116\n",
      "episode 1840, reward 262.0, memory_length 2000, epsilon 0.2758191173459537 total_time 736.0 step_num 127\n",
      "episode 1841, reward 386.0, memory_length 2000, epsilon 0.27562611152373034 total_time 722.0 step_num 122\n",
      "episode 1842, reward 313.0, memory_length 2000, epsilon 0.2754332407583072 total_time 724.0 step_num 133\n",
      "episode 1843, reward 268.0, memory_length 2000, epsilon 0.27524050495517755 total_time 724.0 step_num 119\n",
      "episode 1844, reward 294.0, memory_length 2000, epsilon 0.2750479040199008 total_time 726.0 step_num 115\n",
      "episode 1845, reward 352.0, memory_length 2000, epsilon 0.2748554378581025 total_time 727.0 step_num 107\n",
      "episode 1846, reward 194.0, memory_length 2000, epsilon 0.2746631063754743 total_time 728.0 step_num 119\n",
      "episode 1847, reward -32.0, memory_length 2000, epsilon 0.27447090947777375 total_time 721.0 step_num 107\n",
      "episode 1848, reward 508.0, memory_length 2000, epsilon 0.2742788470708242 total_time 721.0 step_num 101\n",
      "episode 1849, reward 375.0, memory_length 2000, epsilon 0.27408691906051535 total_time 726.0 step_num 121\n",
      "episode 1850, reward -75.0, memory_length 2000, epsilon 0.2738951253528023 total_time 726.0 step_num 117\n",
      "episode 1851, reward 176.0, memory_length 2000, epsilon 0.2737034658537061 total_time 728.0 step_num 122\n",
      "episode 1852, reward -42.0, memory_length 2000, epsilon 0.27351194046931365 total_time 723.0 step_num 128\n",
      "episode 1853, reward 292.0, memory_length 2000, epsilon 0.2733205491057776 total_time 730.0 step_num 115\n",
      "episode 1854, reward 146.0, memory_length 2000, epsilon 0.2731292916693159 total_time 725.0 step_num 115\n",
      "episode 1855, reward 122.0, memory_length 2000, epsilon 0.2729381680662127 total_time 728.0 step_num 113\n",
      "episode 1856, reward 211.0, memory_length 2000, epsilon 0.2727471782028173 total_time 721.0 step_num 127\n",
      "episode 1857, reward 206.0, memory_length 2000, epsilon 0.27255632198554464 total_time 722.0 step_num 120\n",
      "episode 1858, reward 187.0, memory_length 2000, epsilon 0.2723655993208753 total_time 724.0 step_num 129\n",
      "episode 1859, reward 634.0, memory_length 2000, epsilon 0.272175010115355 total_time 721.0 step_num 112\n",
      "episode 1860, reward 112.0, memory_length 2000, epsilon 0.27198455427559504 total_time 721.0 step_num 120\n",
      "episode 1861, reward 242.0, memory_length 2000, epsilon 0.27179423170827227 total_time 722.0 step_num 111\n",
      "episode 1862, reward 473.0, memory_length 2000, epsilon 0.2716040423201284 total_time 737.0 step_num 118\n",
      "episode 1863, reward 146.0, memory_length 2000, epsilon 0.2714139860179707 total_time 725.0 step_num 125\n",
      "episode 1864, reward 489.0, memory_length 2000, epsilon 0.27122406270867155 total_time 723.0 step_num 122\n",
      "episode 1865, reward 328.0, memory_length 2000, epsilon 0.2710342722991686 total_time 721.0 step_num 126\n",
      "episode 1866, reward 148.0, memory_length 2000, epsilon 0.2708446146964644 total_time 721.0 step_num 124\n",
      "episode 1867, reward 400.0, memory_length 2000, epsilon 0.2706550898076269 total_time 721.0 step_num 116\n",
      "episode 1868, reward 70.0, memory_length 2000, epsilon 0.27046569753978883 total_time 724.0 step_num 105\n",
      "episode 1869, reward 272.0, memory_length 2000, epsilon 0.270276437800148 total_time 725.0 step_num 108\n",
      "episode 1870, reward 79.0, memory_length 2000, epsilon 0.27008731049596707 total_time 724.0 step_num 123\n",
      "episode 1871, reward 211.0, memory_length 2000, epsilon 0.2698983155345736 total_time 739.0 step_num 107\n",
      "episode 1872, reward 173.0, memory_length 2000, epsilon 0.2697094528233603 total_time 725.0 step_num 128\n",
      "episode 1873, reward -39.0, memory_length 2000, epsilon 0.2695207222697842 total_time 726.0 step_num 122\n",
      "episode 1874, reward 470.0, memory_length 2000, epsilon 0.26933212378136734 total_time 725.0 step_num 110\n",
      "episode 1875, reward 70.0, memory_length 2000, epsilon 0.26914365726569656 total_time 724.0 step_num 114\n",
      "episode 1876, reward 426.0, memory_length 2000, epsilon 0.26895532263042327 total_time 723.0 step_num 132\n",
      "episode 1877, reward -105.0, memory_length 2000, epsilon 0.2687671197832634 total_time 723.0 step_num 117\n",
      "episode 1878, reward 403.0, memory_length 2000, epsilon 0.2685790486319977 total_time 724.0 step_num 118\n",
      "episode 1879, reward 148.0, memory_length 2000, epsilon 0.2683911090844711 total_time 721.0 step_num 110\n",
      "episode 1880, reward 130.0, memory_length 2000, epsilon 0.26820330104859336 total_time 721.0 step_num 122\n",
      "episode 1881, reward -84.0, memory_length 2000, epsilon 0.2680156244323385 total_time 726.0 step_num 119\n",
      "episode 1882, reward 123.0, memory_length 2000, epsilon 0.267828079143745 total_time 726.0 step_num 119\n",
      "episode 1883, reward 173.0, memory_length 2000, epsilon 0.26764066509091555 total_time 734.0 step_num 117\n",
      "episode 1884, reward 191.0, memory_length 2000, epsilon 0.2674533821820175 total_time 725.0 step_num 114\n",
      "episode 1885, reward 154.0, memory_length 2000, epsilon 0.26726623032528196 total_time 727.0 step_num 113\n",
      "episode 1886, reward 404.0, memory_length 2000, epsilon 0.2670792094290046 total_time 722.0 step_num 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1887, reward 290.0, memory_length 2000, epsilon 0.2668923194015453 total_time 725.0 step_num 109\n",
      "episode 1888, reward 272.0, memory_length 2000, epsilon 0.2667055601513278 total_time 725.0 step_num 127\n",
      "episode 1889, reward 337.0, memory_length 2000, epsilon 0.26651893158684004 total_time 721.0 step_num 108\n",
      "episode 1890, reward 219.0, memory_length 2000, epsilon 0.2663324336166342 total_time 723.0 step_num 101\n",
      "episode 1891, reward 139.0, memory_length 2000, epsilon 0.2661460661493261 total_time 739.0 step_num 115\n",
      "episode 1892, reward 114.0, memory_length 2000, epsilon 0.2659598290935958 total_time 726.0 step_num 120\n",
      "episode 1893, reward 290.0, memory_length 2000, epsilon 0.265773722358187 total_time 725.0 step_num 119\n",
      "episode 1894, reward -23.0, memory_length 2000, epsilon 0.2655877458519075 total_time 721.0 step_num 112\n",
      "episode 1895, reward 138.0, memory_length 2000, epsilon 0.2654018994836288 total_time 723.0 step_num 110\n",
      "episode 1896, reward 78.0, memory_length 2000, epsilon 0.2652161831622862 total_time 726.0 step_num 111\n",
      "episode 1897, reward 442.0, memory_length 2000, epsilon 0.2650305967968785 total_time 727.0 step_num 111\n",
      "episode 1898, reward 129.0, memory_length 2000, epsilon 0.26484514029646866 total_time 723.0 step_num 115\n",
      "episode 1899, reward 352.0, memory_length 2000, epsilon 0.26465981357018287 total_time 727.0 step_num 123\n",
      "episode 1900, reward -228.0, memory_length 2000, epsilon 0.264474616527211 total_time 726.0 step_num 116\n",
      "episode 1901, reward 42.0, memory_length 2000, epsilon 0.26428954907680646 total_time 726.0 step_num 106\n",
      "episode 1902, reward 471.0, memory_length 2000, epsilon 0.26410461112828637 total_time 723.0 step_num 108\n",
      "episode 1903, reward 66.0, memory_length 2000, epsilon 0.2639198025910309 total_time 723.0 step_num 114\n",
      "episode 1904, reward 13.0, memory_length 2000, epsilon 0.26373512337448407 total_time 721.0 step_num 105\n",
      "episode 1905, reward 349.0, memory_length 2000, epsilon 0.26355057338815296 total_time 724.0 step_num 116\n",
      "episode 1906, reward 112.0, memory_length 2000, epsilon 0.263366152541608 total_time 721.0 step_num 113\n",
      "episode 1907, reward -95.0, memory_length 2000, epsilon 0.2631818607444832 total_time 721.0 step_num 118\n",
      "episode 1908, reward 283.0, memory_length 2000, epsilon 0.2629976979064753 total_time 721.0 step_num 131\n",
      "episode 1909, reward -295.0, memory_length 2000, epsilon 0.2628136639373447 total_time 725.0 step_num 121\n",
      "episode 1910, reward 388.0, memory_length 2000, epsilon 0.2626297587469147 total_time 727.0 step_num 122\n",
      "episode 1911, reward 304.0, memory_length 2000, epsilon 0.2624459822450717 total_time 724.0 step_num 124\n",
      "episode 1912, reward 111.0, memory_length 2000, epsilon 0.2622623343417652 total_time 723.0 step_num 120\n",
      "episode 1913, reward 118.0, memory_length 2000, epsilon 0.2620788149470079 total_time 727.0 step_num 108\n",
      "episode 1914, reward 80.0, memory_length 2000, epsilon 0.26189542397087506 total_time 722.0 step_num 108\n",
      "episode 1915, reward 160.0, memory_length 2000, epsilon 0.2617121613235053 total_time 724.0 step_num 121\n",
      "episode 1916, reward 215.0, memory_length 2000, epsilon 0.26152902691509977 total_time 731.0 step_num 126\n",
      "episode 1917, reward 530.0, memory_length 2000, epsilon 0.2613460206559226 total_time 722.0 step_num 124\n",
      "episode 1918, reward 284.0, memory_length 2000, epsilon 0.2611631424563009 total_time 728.0 step_num 114\n",
      "episode 1919, reward 223.0, memory_length 2000, epsilon 0.2609803922266242 total_time 724.0 step_num 125\n",
      "episode 1920, reward 328.0, memory_length 2000, epsilon 0.2607977698773448 total_time 730.0 step_num 109\n",
      "episode 1921, reward 112.0, memory_length 2000, epsilon 0.260615275318978 total_time 739.0 step_num 133\n",
      "episode 1922, reward 159.0, memory_length 2000, epsilon 0.26043290846210126 total_time 726.0 step_num 127\n",
      "episode 1923, reward 512.0, memory_length 2000, epsilon 0.26025066921735485 total_time 722.0 step_num 123\n",
      "episode 1924, reward 146.0, memory_length 2000, epsilon 0.26006855749544167 total_time 725.0 step_num 114\n",
      "episode 1925, reward 116.0, memory_length 2000, epsilon 0.25988657320712677 total_time 722.0 step_num 118\n",
      "episode 1926, reward 398.0, memory_length 2000, epsilon 0.259704716263238 total_time 725.0 step_num 112\n",
      "episode 1927, reward 344.0, memory_length 2000, epsilon 0.2595229865746653 total_time 725.0 step_num 122\n",
      "episode 1928, reward 152.0, memory_length 2000, epsilon 0.2593413840523613 total_time 722.0 step_num 113\n",
      "episode 1929, reward 471.0, memory_length 2000, epsilon 0.2591599086073406 total_time 723.0 step_num 119\n",
      "episode 1930, reward 98.0, memory_length 2000, epsilon 0.25897856015068044 total_time 722.0 step_num 117\n",
      "episode 1931, reward 331.0, memory_length 2000, epsilon 0.2587973385935199 total_time 724.0 step_num 135\n",
      "episode 1932, reward 407.0, memory_length 2000, epsilon 0.25861624384706033 total_time 725.0 step_num 116\n",
      "episode 1933, reward 523.0, memory_length 2000, epsilon 0.2584352758225655 total_time 727.0 step_num 124\n",
      "episode 1934, reward 229.0, memory_length 2000, epsilon 0.258254434431361 total_time 721.0 step_num 118\n",
      "episode 1935, reward 247.0, memory_length 2000, epsilon 0.2580737195848345 total_time 721.0 step_num 120\n",
      "episode 1936, reward 291.0, memory_length 2000, epsilon 0.2578931311944358 total_time 723.0 step_num 126\n",
      "episode 1937, reward 98.0, memory_length 2000, epsilon 0.25771266917167657 total_time 722.0 step_num 105\n",
      "episode 1938, reward 435.0, memory_length 2000, epsilon 0.25753233342813026 total_time 723.0 step_num 121\n",
      "episode 1939, reward 309.0, memory_length 2000, epsilon 0.2573521238754326 total_time 723.0 step_num 111\n",
      "episode 1940, reward 490.0, memory_length 2000, epsilon 0.2571720404252807 total_time 721.0 step_num 113\n",
      "episode 1941, reward 211.0, memory_length 2000, epsilon 0.2569920829894338 total_time 730.0 step_num 115\n",
      "episode 1942, reward 317.0, memory_length 2000, epsilon 0.25681225147971276 total_time 725.0 step_num 119\n",
      "episode 1943, reward 157.0, memory_length 2000, epsilon 0.25663254580800005 total_time 730.0 step_num 118\n",
      "episode 1944, reward -14.0, memory_length 2000, epsilon 0.25645296588623995 total_time 721.0 step_num 119\n",
      "episode 1945, reward 183.0, memory_length 2000, epsilon 0.25627351162643824 total_time 723.0 step_num 112\n",
      "episode 1946, reward 485.0, memory_length 2000, epsilon 0.2560941829406623 total_time 722.0 step_num 121\n",
      "episode 1947, reward 229.0, memory_length 2000, epsilon 0.25591497974104116 total_time 721.0 step_num 118\n",
      "episode 1948, reward 220.0, memory_length 2000, epsilon 0.25573590193976525 total_time 721.0 step_num 116\n",
      "episode 1949, reward 291.0, memory_length 2000, epsilon 0.25555694944908636 total_time 723.0 step_num 108\n",
      "episode 1950, reward 348.0, memory_length 2000, epsilon 0.25537812218131783 total_time 726.0 step_num 122\n",
      "episode 1951, reward 76.0, memory_length 2000, epsilon 0.25519942004883434 total_time 721.0 step_num 110\n",
      "episode 1952, reward 535.0, memory_length 2000, epsilon 0.2550208429640716 total_time 721.0 step_num 122\n",
      "episode 1953, reward 420.0, memory_length 2000, epsilon 0.2548423908395272 total_time 726.0 step_num 109\n",
      "episode 1954, reward 427.0, memory_length 2000, epsilon 0.25466406358775934 total_time 730.0 step_num 110\n",
      "episode 1955, reward 105.0, memory_length 2000, epsilon 0.2544858611213877 total_time 726.0 step_num 110\n",
      "episode 1956, reward 133.0, memory_length 2000, epsilon 0.25430778335309323 total_time 733.0 step_num 118\n",
      "episode 1957, reward 170.0, memory_length 2000, epsilon 0.2541298301956176 total_time 722.0 step_num 120\n",
      "episode 1958, reward 184.0, memory_length 2000, epsilon 0.2539520015617638 total_time 721.0 step_num 120\n",
      "episode 1959, reward 445.0, memory_length 2000, epsilon 0.25377429736439594 total_time 721.0 step_num 121\n",
      "episode 1960, reward 140.0, memory_length 2000, epsilon 0.2535967175164388 total_time 728.0 step_num 120\n",
      "episode 1961, reward 194.0, memory_length 2000, epsilon 0.2534192619308783 total_time 728.0 step_num 122\n",
      "episode 1962, reward -275.0, memory_length 2000, epsilon 0.25324193052076127 total_time 721.0 step_num 119\n",
      "episode 1963, reward 381.0, memory_length 2000, epsilon 0.2530647231991953 total_time 723.0 step_num 118\n",
      "episode 1964, reward 557.0, memory_length 2000, epsilon 0.2528876398793487 total_time 722.0 step_num 130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1965, reward 339.0, memory_length 2000, epsilon 0.2527106804744507 total_time 726.0 step_num 120\n",
      "episode 1966, reward 392.0, memory_length 2000, epsilon 0.2525338448977912 total_time 728.0 step_num 120\n",
      "episode 1967, reward 94.0, memory_length 2000, epsilon 0.25235713306272073 total_time 721.0 step_num 112\n",
      "episode 1968, reward 635.0, memory_length 2000, epsilon 0.25218054488265057 total_time 728.0 step_num 119\n",
      "episode 1969, reward 544.0, memory_length 2000, epsilon 0.25200408027105237 total_time 721.0 step_num 112\n",
      "episode 1970, reward 561.0, memory_length 2000, epsilon 0.2518277391414586 total_time 723.0 step_num 119\n",
      "episode 1971, reward 250.0, memory_length 2000, epsilon 0.25165152140746205 total_time 724.0 step_num 124\n",
      "episode 1972, reward 75.0, memory_length 2000, epsilon 0.251475426982716 total_time 723.0 step_num 111\n",
      "episode 1973, reward 241.0, memory_length 2000, epsilon 0.2512994557809342 total_time 724.0 step_num 121\n",
      "episode 1974, reward 283.0, memory_length 2000, epsilon 0.2511236077158908 total_time 721.0 step_num 116\n",
      "episode 1975, reward 299.0, memory_length 2000, epsilon 0.25094788270142016 total_time 725.0 step_num 106\n",
      "episode 1976, reward 233.0, memory_length 2000, epsilon 0.2507722806514171 total_time 722.0 step_num 122\n",
      "episode 1977, reward 337.0, memory_length 2000, epsilon 0.2505968014798366 total_time 730.0 step_num 103\n",
      "episode 1978, reward -37.0, memory_length 2000, epsilon 0.25042144510069375 total_time 722.0 step_num 130\n",
      "episode 1979, reward 400.0, memory_length 2000, epsilon 0.2502462114280641 total_time 721.0 step_num 117\n",
      "episode 1980, reward 224.0, memory_length 2000, epsilon 0.25007110037608304 total_time 722.0 step_num 117\n",
      "episode 1981, reward -33.0, memory_length 2000, epsilon 0.24989611185894609 total_time 723.0 step_num 116\n",
      "episode 1982, reward 75.0, memory_length 2000, epsilon 0.249721245790909 total_time 723.0 step_num 112\n",
      "episode 1983, reward -63.0, memory_length 2000, epsilon 0.2495465020862874 total_time 729.0 step_num 111\n",
      "episode 1984, reward 280.0, memory_length 2000, epsilon 0.2493718806594567 total_time 736.0 step_num 123\n",
      "episode 1985, reward 292.0, memory_length 2000, epsilon 0.2491973814248526 total_time 721.0 step_num 122\n",
      "episode 1986, reward 416.0, memory_length 2000, epsilon 0.24902300429697038 total_time 725.0 step_num 123\n",
      "episode 1987, reward -136.0, memory_length 2000, epsilon 0.24884874919036518 total_time 731.0 step_num 120\n",
      "episode 1988, reward 288.0, memory_length 2000, epsilon 0.24867461601965213 total_time 729.0 step_num 111\n",
      "episode 1989, reward 26.0, memory_length 2000, epsilon 0.24850060469950588 total_time 722.0 step_num 125\n",
      "episode 1990, reward 568.0, memory_length 2000, epsilon 0.24832671514466093 total_time 727.0 step_num 118\n",
      "episode 1991, reward 116.0, memory_length 2000, epsilon 0.24815294726991136 total_time 722.0 step_num 113\n",
      "episode 1992, reward 256.0, memory_length 2000, epsilon 0.24797930099011087 total_time 721.0 step_num 120\n",
      "episode 1993, reward 274.0, memory_length 2000, epsilon 0.24780577622017289 total_time 721.0 step_num 110\n",
      "episode 1994, reward 156.0, memory_length 2000, epsilon 0.2476323728750702 total_time 723.0 step_num 123\n",
      "episode 1995, reward 355.0, memory_length 2000, epsilon 0.24745909086983514 total_time 721.0 step_num 108\n",
      "episode 1996, reward 193.0, memory_length 2000, epsilon 0.2472859301195596 total_time 721.0 step_num 120\n",
      "episode 1997, reward 224.0, memory_length 2000, epsilon 0.24711289053939475 total_time 722.0 step_num 113\n",
      "episode 1998, reward 129.0, memory_length 2000, epsilon 0.2469399720445512 total_time 723.0 step_num 108\n",
      "episode 1999, reward -8.0, memory_length 2000, epsilon 0.24676717455029892 total_time 727.0 step_num 122\n",
      "episode 2000, reward 58.0, memory_length 2000, epsilon 0.24659449797196709 total_time 721.0 step_num 114\n",
      "episode 2001, reward 436.0, memory_length 2000, epsilon 0.24642194222494415 total_time 721.0 step_num 125\n",
      "episode 2002, reward 254.0, memory_length 2000, epsilon 0.24624950722467792 total_time 725.0 step_num 121\n",
      "episode 2003, reward 274.0, memory_length 2000, epsilon 0.24607719288667512 total_time 721.0 step_num 111\n",
      "episode 2004, reward 382.0, memory_length 2000, epsilon 0.24590499912650174 total_time 721.0 step_num 120\n",
      "episode 2005, reward 166.0, memory_length 2000, epsilon 0.24573292585978287 total_time 721.0 step_num 109\n",
      "episode 2006, reward 40.0, memory_length 2000, epsilon 0.2455609730022026 total_time 721.0 step_num 117\n",
      "episode 2007, reward 40.0, memory_length 2000, epsilon 0.24538914046950397 total_time 730.0 step_num 113\n",
      "episode 2008, reward 39.0, memory_length 2000, epsilon 0.2452174281774891 total_time 723.0 step_num 105\n",
      "episode 2009, reward 266.0, memory_length 2000, epsilon 0.245045836042019 total_time 728.0 step_num 115\n",
      "episode 2010, reward 235.0, memory_length 2000, epsilon 0.24487436397901335 total_time 727.0 step_num 123\n",
      "episode 2011, reward 363.0, memory_length 2000, epsilon 0.24470301190445107 total_time 723.0 step_num 116\n",
      "episode 2012, reward 287.0, memory_length 2000, epsilon 0.24453177973436943 total_time 722.0 step_num 119\n",
      "episode 2013, reward 409.0, memory_length 2000, epsilon 0.24436066738486478 total_time 730.0 step_num 111\n",
      "episode 2014, reward 79.0, memory_length 2000, epsilon 0.24418967477209208 total_time 724.0 step_num 113\n",
      "episode 2015, reward 148.0, memory_length 2000, epsilon 0.24401880181226482 total_time 730.0 step_num 114\n",
      "episode 2016, reward 160.0, memory_length 2000, epsilon 0.2438480484216554 total_time 724.0 step_num 126\n",
      "episode 2017, reward -140.0, memory_length 2000, epsilon 0.24367741451659458 total_time 721.0 step_num 119\n",
      "episode 2018, reward 448.0, memory_length 2000, epsilon 0.2435069000134717 total_time 724.0 step_num 129\n",
      "episode 2019, reward 265.0, memory_length 2000, epsilon 0.24333650482873476 total_time 721.0 step_num 112\n",
      "episode 2020, reward 222.0, memory_length 2000, epsilon 0.24316622887889003 total_time 726.0 step_num 131\n",
      "episode 2021, reward 254.0, memory_length 2000, epsilon 0.24299607208050228 total_time 725.0 step_num 108\n",
      "episode 2022, reward 157.0, memory_length 2000, epsilon 0.24282603435019476 total_time 721.0 step_num 124\n",
      "episode 2023, reward 364.0, memory_length 2000, epsilon 0.24265611560464895 total_time 721.0 step_num 113\n",
      "episode 2024, reward 199.0, memory_length 2000, epsilon 0.24248631576060453 total_time 736.0 step_num 137\n",
      "episode 2025, reward 543.0, memory_length 2000, epsilon 0.2423166347348598 total_time 723.0 step_num 139\n",
      "episode 2026, reward 107.0, memory_length 2000, epsilon 0.24214707244427092 total_time 722.0 step_num 120\n",
      "episode 2027, reward 377.0, memory_length 2000, epsilon 0.24197762880575233 total_time 722.0 step_num 119\n",
      "episode 2028, reward 301.0, memory_length 2000, epsilon 0.24180830373627674 total_time 730.0 step_num 116\n",
      "episode 2029, reward 238.0, memory_length 2000, epsilon 0.2416390971528748 total_time 721.0 step_num 121\n",
      "episode 2030, reward 67.0, memory_length 2000, epsilon 0.2414700089726353 total_time 721.0 step_num 120\n",
      "episode 2031, reward 512.0, memory_length 2000, epsilon 0.24130103911270506 total_time 722.0 step_num 117\n",
      "episode 2032, reward 381.0, memory_length 2000, epsilon 0.24113218749028878 total_time 723.0 step_num 116\n",
      "episode 2033, reward 355.0, memory_length 2000, epsilon 0.24096345402264918 total_time 721.0 step_num 122\n",
      "episode 2034, reward 120.0, memory_length 2000, epsilon 0.2407948386271069 total_time 723.0 step_num 102\n",
      "episode 2035, reward 29.0, memory_length 2000, epsilon 0.24062634122104037 total_time 725.0 step_num 100\n",
      "episode 2036, reward 251.0, memory_length 2000, epsilon 0.24045796172188583 total_time 722.0 step_num 123\n",
      "episode 2037, reward 436.0, memory_length 2000, epsilon 0.24028970004713734 total_time 721.0 step_num 111\n",
      "episode 2038, reward 112.0, memory_length 2000, epsilon 0.24012155611434668 total_time 730.0 step_num 124\n",
      "episode 2039, reward 644.0, memory_length 2000, epsilon 0.23995352984112336 total_time 728.0 step_num 109\n",
      "episode 2040, reward 283.0, memory_length 2000, epsilon 0.23978562114513446 total_time 721.0 step_num 114\n",
      "episode 2041, reward 237.0, memory_length 2000, epsilon 0.2396178299441047 total_time 723.0 step_num 114\n",
      "episode 2042, reward 235.0, memory_length 2000, epsilon 0.2394501561558164 total_time 736.0 step_num 116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2043, reward 121.0, memory_length 2000, epsilon 0.23928259969810942 total_time 721.0 step_num 118\n",
      "episode 2044, reward 229.0, memory_length 2000, epsilon 0.23911516048888107 total_time 721.0 step_num 125\n",
      "episode 2045, reward 209.0, memory_length 2000, epsilon 0.23894783844608616 total_time 725.0 step_num 123\n",
      "episode 2046, reward 145.0, memory_length 2000, epsilon 0.23878063348773687 total_time 727.0 step_num 117\n",
      "episode 2047, reward 31.0, memory_length 2000, epsilon 0.2386135455319027 total_time 721.0 step_num 121\n",
      "episode 2048, reward 344.0, memory_length 2000, epsilon 0.2384465744967107 total_time 725.0 step_num 109\n",
      "episode 2049, reward 348.0, memory_length 2000, epsilon 0.23827972030034494 total_time 726.0 step_num 107\n",
      "episode 2050, reward 348.0, memory_length 2000, epsilon 0.2381129828610469 total_time 726.0 step_num 124\n",
      "episode 2051, reward 157.0, memory_length 2000, epsilon 0.23794636209711523 total_time 721.0 step_num 114\n",
      "episode 2052, reward -354.0, memory_length 2000, epsilon 0.23777985792690576 total_time 726.0 step_num 108\n",
      "episode 2053, reward 166.0, memory_length 2000, epsilon 0.23761347026883137 total_time 730.0 step_num 125\n",
      "episode 2054, reward 283.0, memory_length 2000, epsilon 0.23744719904136222 total_time 721.0 step_num 116\n",
      "episode 2055, reward 247.0, memory_length 2000, epsilon 0.2372810441630254 total_time 721.0 step_num 111\n",
      "episode 2056, reward 255.0, memory_length 2000, epsilon 0.23711500555240486 total_time 723.0 step_num 116\n",
      "episode 2057, reward 346.0, memory_length 2000, epsilon 0.23694908312814184 total_time 721.0 step_num 132\n",
      "episode 2058, reward 210.0, memory_length 2000, epsilon 0.23678327680893432 total_time 723.0 step_num 121\n",
      "episode 2059, reward 170.0, memory_length 2000, epsilon 0.2366175865135371 total_time 722.0 step_num 114\n",
      "episode 2060, reward 345.0, memory_length 2000, epsilon 0.23645201216076206 total_time 723.0 step_num 122\n",
      "episode 2061, reward 248.0, memory_length 2000, epsilon 0.23628655366947768 total_time 728.0 step_num 121\n",
      "episode 2062, reward 227.0, memory_length 2000, epsilon 0.23612121095860936 total_time 725.0 step_num 111\n",
      "episode 2063, reward 572.0, memory_length 2000, epsilon 0.23595598394713913 total_time 728.0 step_num 119\n",
      "episode 2064, reward 467.0, memory_length 2000, epsilon 0.23579087255410572 total_time 722.0 step_num 113\n",
      "episode 2065, reward -102.0, memory_length 2000, epsilon 0.2356258766986046 total_time 726.0 step_num 113\n",
      "episode 2066, reward 107.0, memory_length 2000, epsilon 0.2354609962997878 total_time 722.0 step_num 127\n",
      "episode 2067, reward 326.0, memory_length 2000, epsilon 0.23529623127686386 total_time 734.0 step_num 105\n",
      "episode 2068, reward 382.0, memory_length 2000, epsilon 0.23513158154909797 total_time 721.0 step_num 117\n",
      "episode 2069, reward 551.0, memory_length 2000, epsilon 0.23496704703581178 total_time 725.0 step_num 110\n",
      "episode 2070, reward 294.0, memory_length 2000, epsilon 0.23480262765638327 total_time 726.0 step_num 117\n",
      "episode 2071, reward 22.0, memory_length 2000, epsilon 0.23463832333024706 total_time 721.0 step_num 108\n",
      "episode 2072, reward -86.0, memory_length 2000, epsilon 0.23447413397689396 total_time 721.0 step_num 117\n",
      "episode 2073, reward 377.0, memory_length 2000, epsilon 0.23431005951587117 total_time 722.0 step_num 107\n",
      "episode 2074, reward 354.0, memory_length 2000, epsilon 0.23414609986678228 total_time 723.0 step_num 105\n",
      "episode 2075, reward 328.0, memory_length 2000, epsilon 0.233982254949287 total_time 721.0 step_num 103\n",
      "episode 2076, reward 477.0, memory_length 2000, epsilon 0.2338185246831013 total_time 729.0 step_num 121\n",
      "episode 2077, reward 197.0, memory_length 2000, epsilon 0.23365490898799737 total_time 731.0 step_num 96\n",
      "episode 2078, reward 79.0, memory_length 2000, epsilon 0.23349140778380356 total_time 724.0 step_num 101\n",
      "episode 2079, reward 170.0, memory_length 2000, epsilon 0.2333280209904042 total_time 722.0 step_num 117\n",
      "episode 2080, reward 327.0, memory_length 2000, epsilon 0.23316474852773983 total_time 723.0 step_num 120\n",
      "episode 2081, reward 260.0, memory_length 2000, epsilon 0.2330015903158069 total_time 722.0 step_num 100\n",
      "episode 2082, reward 134.0, memory_length 2000, epsilon 0.23283854627465786 total_time 722.0 step_num 117\n",
      "episode 2083, reward 231.0, memory_length 2000, epsilon 0.23267561632440117 total_time 726.0 step_num 121\n",
      "episode 2084, reward 212.0, memory_length 2000, epsilon 0.2325128003852011 total_time 728.0 step_num 106\n",
      "episode 2085, reward -56.0, memory_length 2000, epsilon 0.2323500983772779 total_time 724.0 step_num 114\n",
      "episode 2086, reward 79.0, memory_length 2000, epsilon 0.23218751022090756 total_time 724.0 step_num 105\n",
      "episode 2087, reward 363.0, memory_length 2000, epsilon 0.23202503583642184 total_time 723.0 step_num 111\n",
      "episode 2088, reward 444.0, memory_length 2000, epsilon 0.23186267514420836 total_time 723.0 step_num 123\n",
      "episode 2089, reward 184.0, memory_length 2000, epsilon 0.23170042806471036 total_time 730.0 step_num 108\n",
      "episode 2090, reward 247.0, memory_length 2000, epsilon 0.23153829451842667 total_time 721.0 step_num 109\n",
      "episode 2091, reward -19.0, memory_length 2000, epsilon 0.231376274425912 total_time 722.0 step_num 116\n",
      "episode 2092, reward 329.0, memory_length 2000, epsilon 0.2312143677077764 total_time 728.0 step_num 121\n",
      "episode 2093, reward 301.0, memory_length 2000, epsilon 0.23105257428468556 total_time 721.0 step_num 121\n",
      "episode 2094, reward 127.0, memory_length 2000, epsilon 0.23089089407736083 total_time 727.0 step_num 113\n",
      "episode 2095, reward 560.0, memory_length 2000, epsilon 0.23072932700657878 total_time 725.0 step_num 135\n",
      "episode 2096, reward 139.0, memory_length 2000, epsilon 0.23056787299317152 total_time 721.0 step_num 119\n",
      "episode 2097, reward 260.0, memory_length 2000, epsilon 0.2304065319580267 total_time 722.0 step_num 120\n",
      "episode 2098, reward -59.0, memory_length 2000, epsilon 0.2302453038220872 total_time 730.0 step_num 120\n",
      "episode 2099, reward 462.0, memory_length 2000, epsilon 0.2300841885063511 total_time 723.0 step_num 115\n",
      "episode 2100, reward 4.0, memory_length 2000, epsilon 0.229923185931872 total_time 721.0 step_num 128\n",
      "episode 2101, reward -124.0, memory_length 2000, epsilon 0.22976229601975862 total_time 725.0 step_num 114\n",
      "episode 2102, reward 223.0, memory_length 2000, epsilon 0.22960151869117482 total_time 724.0 step_num 108\n",
      "episode 2103, reward 329.0, memory_length 2000, epsilon 0.22944085386733984 total_time 728.0 step_num 110\n",
      "episode 2104, reward 373.0, memory_length 2000, epsilon 0.22928030146952785 total_time 721.0 step_num 120\n",
      "episode 2105, reward 275.0, memory_length 2000, epsilon 0.2291198614190681 total_time 728.0 step_num 123\n",
      "episode 2106, reward 418.0, memory_length 2000, epsilon 0.22895953363734511 total_time 730.0 step_num 108\n",
      "episode 2107, reward 167.0, memory_length 2000, epsilon 0.22879931804579814 total_time 728.0 step_num 124\n",
      "episode 2108, reward 228.0, memory_length 2000, epsilon 0.22863921456592157 total_time 723.0 step_num 113\n",
      "episode 2109, reward 467.0, memory_length 2000, epsilon 0.22847922311926477 total_time 722.0 step_num 118\n",
      "episode 2110, reward 197.0, memory_length 2000, epsilon 0.22831934362743178 total_time 731.0 step_num 124\n",
      "episode 2111, reward 281.0, memory_length 2000, epsilon 0.22815957601208184 total_time 725.0 step_num 121\n",
      "episode 2112, reward 377.0, memory_length 2000, epsilon 0.22799992019492865 total_time 722.0 step_num 111\n",
      "episode 2113, reward 261.0, memory_length 2000, epsilon 0.2278403760977409 total_time 729.0 step_num 103\n",
      "episode 2114, reward 419.0, memory_length 2000, epsilon 0.22768094364234207 total_time 728.0 step_num 128\n",
      "episode 2115, reward 365.0, memory_length 2000, epsilon 0.22752162275061016 total_time 728.0 step_num 123\n",
      "episode 2116, reward 83.0, memory_length 2000, epsilon 0.22736241334447788 total_time 725.0 step_num 120\n",
      "episode 2117, reward 218.0, memory_length 2000, epsilon 0.22720331534593277 total_time 725.0 step_num 132\n",
      "episode 2118, reward 310.0, memory_length 2000, epsilon 0.2270443286770167 total_time 721.0 step_num 111\n",
      "episode 2119, reward 334.0, memory_length 2000, epsilon 0.2268854532598262 total_time 727.0 step_num 104\n",
      "episode 2120, reward 139.0, memory_length 2000, epsilon 0.22672668901651238 total_time 721.0 step_num 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2121, reward 211.0, memory_length 2000, epsilon 0.2265680358692807 total_time 730.0 step_num 100\n",
      "episode 2122, reward 256.0, memory_length 2000, epsilon 0.22640949374039107 total_time 721.0 step_num 123\n",
      "episode 2123, reward 113.0, memory_length 2000, epsilon 0.226251062552158 total_time 728.0 step_num 117\n",
      "episode 2124, reward 83.0, memory_length 2000, epsilon 0.22609274222695006 total_time 725.0 step_num 117\n",
      "episode 2125, reward 202.0, memory_length 2000, epsilon 0.2259345326871903 total_time 721.0 step_num 118\n",
      "episode 2126, reward 299.0, memory_length 2000, epsilon 0.22577643385535615 total_time 725.0 step_num 109\n",
      "episode 2127, reward 597.0, memory_length 2000, epsilon 0.22561844565397904 total_time 723.0 step_num 104\n",
      "episode 2128, reward 377.0, memory_length 2000, epsilon 0.22546056800564482 total_time 722.0 step_num 107\n",
      "episode 2129, reward 175.0, memory_length 2000, epsilon 0.22530280083299348 total_time 721.0 step_num 107\n",
      "episode 2130, reward -41.0, memory_length 2000, epsilon 0.22514514405871902 total_time 721.0 step_num 126\n",
      "episode 2131, reward 427.0, memory_length 2000, epsilon 0.22498759760556966 total_time 730.0 step_num 101\n",
      "episode 2132, reward 257.0, memory_length 2000, epsilon 0.22483016139634765 total_time 728.0 step_num 122\n",
      "episode 2133, reward 216.0, memory_length 2000, epsilon 0.2246728353539092 total_time 729.0 step_num 125\n",
      "episode 2134, reward 271.0, memory_length 2000, epsilon 0.22451561940116457 total_time 736.0 step_num 124\n",
      "episode 2135, reward 139.0, memory_length 2000, epsilon 0.22435851346107796 total_time 721.0 step_num 115\n",
      "episode 2136, reward 106.0, memory_length 2000, epsilon 0.2242015174566674 total_time 724.0 step_num 120\n",
      "episode 2137, reward -20.0, memory_length 2000, epsilon 0.2240446313110049 total_time 724.0 step_num 110\n",
      "episode 2138, reward 353.0, memory_length 2000, epsilon 0.22388785494721625 total_time 725.0 step_num 112\n",
      "episode 2139, reward 152.0, memory_length 2000, epsilon 0.22373118828848093 total_time 722.0 step_num 108\n",
      "episode 2140, reward 34.0, memory_length 2000, epsilon 0.22357463125803242 total_time 724.0 step_num 100\n",
      "episode 2141, reward 29.0, memory_length 2000, epsilon 0.22341818377915768 total_time 734.0 step_num 103\n",
      "episode 2142, reward 136.0, memory_length 2000, epsilon 0.22326184577519745 total_time 727.0 step_num 111\n",
      "episode 2143, reward 334.0, memory_length 2000, epsilon 0.22310561716954613 total_time 736.0 step_num 120\n",
      "episode 2144, reward 188.0, memory_length 2000, epsilon 0.2229494978856517 total_time 722.0 step_num 114\n",
      "episode 2145, reward 166.0, memory_length 2000, epsilon 0.22279348784701564 total_time 721.0 step_num 116\n",
      "episode 2146, reward 405.0, memory_length 2000, epsilon 0.22263758697719313 total_time 729.0 step_num 130\n",
      "episode 2147, reward 413.0, memory_length 2000, epsilon 0.22248179519979272 total_time 722.0 step_num 121\n",
      "episode 2148, reward 179.0, memory_length 2000, epsilon 0.22232611243847633 total_time 722.0 step_num 126\n",
      "episode 2149, reward 296.0, memory_length 2000, epsilon 0.22217053861695954 total_time 722.0 step_num 111\n",
      "episode 2150, reward 273.0, memory_length 2000, epsilon 0.22201507365901113 total_time 723.0 step_num 114\n",
      "episode 2151, reward 341.0, memory_length 2000, epsilon 0.2218597174884532 total_time 722.0 step_num 117\n",
      "episode 2152, reward 327.0, memory_length 2000, epsilon 0.2217044700291613 total_time 723.0 step_num 111\n",
      "episode 2153, reward 537.0, memory_length 2000, epsilon 0.22154933120506418 total_time 726.0 step_num 115\n",
      "episode 2154, reward 88.0, memory_length 2000, epsilon 0.22139430094014373 total_time 724.0 step_num 111\n",
      "episode 2155, reward 149.0, memory_length 2000, epsilon 0.22123937915843522 total_time 728.0 step_num 119\n",
      "episode 2156, reward 339.0, memory_length 2000, epsilon 0.22108456578402694 total_time 726.0 step_num 136\n",
      "episode 2157, reward 499.0, memory_length 2000, epsilon 0.22092986074106022 total_time 721.0 step_num 111\n",
      "episode 2158, reward 199.0, memory_length 2000, epsilon 0.2207752639537298 total_time 727.0 step_num 125\n",
      "episode 2159, reward 490.0, memory_length 2000, epsilon 0.22062077534628302 total_time 721.0 step_num 114\n",
      "episode 2160, reward 357.0, memory_length 2000, epsilon 0.22046639484302064 total_time 726.0 step_num 106\n",
      "episode 2161, reward 428.0, memory_length 2000, epsilon 0.22031212236829617 total_time 728.0 step_num 107\n",
      "episode 2162, reward 470.0, memory_length 2000, epsilon 0.220157957846516 total_time 725.0 step_num 113\n",
      "episode 2163, reward 328.0, memory_length 2000, epsilon 0.22000390120213964 total_time 721.0 step_num 122\n",
      "episode 2164, reward -41.0, memory_length 2000, epsilon 0.21984995235967927 total_time 721.0 step_num 118\n",
      "episode 2165, reward 321.0, memory_length 2000, epsilon 0.2196961112436999 total_time 735.0 step_num 115\n",
      "episode 2166, reward 395.0, memory_length 2000, epsilon 0.21954237777881946 total_time 722.0 step_num 121\n",
      "episode 2167, reward 51.0, memory_length 2000, epsilon 0.21938875188970855 total_time 726.0 step_num 106\n",
      "episode 2168, reward 601.0, memory_length 2000, epsilon 0.21923523350109042 total_time 724.0 step_num 109\n",
      "episode 2169, reward -59.0, memory_length 2000, epsilon 0.2190818225377411 total_time 721.0 step_num 121\n",
      "episode 2170, reward 395.0, memory_length 2000, epsilon 0.21892851892448925 total_time 722.0 step_num 118\n",
      "episode 2171, reward 235.0, memory_length 2000, epsilon 0.218775322586216 total_time 727.0 step_num 104\n",
      "episode 2172, reward 516.0, memory_length 2000, epsilon 0.21862223344785525 total_time 723.0 step_num 125\n",
      "episode 2173, reward 245.0, memory_length 2000, epsilon 0.21846925143439322 total_time 725.0 step_num 104\n",
      "episode 2174, reward 163.0, memory_length 2000, epsilon 0.21831637647086874 total_time 727.0 step_num 119\n",
      "episode 2175, reward 292.0, memory_length 2000, epsilon 0.21816360848237315 total_time 721.0 step_num 121\n",
      "episode 2176, reward 346.0, memory_length 2000, epsilon 0.2180109473940501 total_time 721.0 step_num 137\n",
      "episode 2177, reward 13.0, memory_length 2000, epsilon 0.21785839313109556 total_time 721.0 step_num 114\n",
      "episode 2178, reward 267.0, memory_length 2000, epsilon 0.21770594561875806 total_time 726.0 step_num 114\n",
      "episode 2179, reward 337.0, memory_length 2000, epsilon 0.2175536047823383 total_time 721.0 step_num 120\n",
      "episode 2180, reward 481.0, memory_length 2000, epsilon 0.21740137054718917 total_time 721.0 step_num 117\n",
      "episode 2181, reward 347.0, memory_length 2000, epsilon 0.21724924283871597 total_time 728.0 step_num 113\n",
      "episode 2182, reward -5.0, memory_length 2000, epsilon 0.2170972215823761 total_time 721.0 step_num 115\n",
      "episode 2183, reward 94.0, memory_length 2000, epsilon 0.21694530670367917 total_time 721.0 step_num 103\n",
      "episode 2184, reward 383.0, memory_length 2000, epsilon 0.2167934981281869 total_time 728.0 step_num 118\n",
      "episode 2185, reward 144.0, memory_length 2000, epsilon 0.216641795781513 total_time 729.0 step_num 117\n",
      "episode 2186, reward 422.0, memory_length 2000, epsilon 0.21649019958932336 total_time 722.0 step_num 127\n",
      "episode 2187, reward 265.0, memory_length 2000, epsilon 0.2163387094773359 total_time 730.0 step_num 116\n",
      "episode 2188, reward 3.0, memory_length 2000, epsilon 0.21618732537132038 total_time 723.0 step_num 116\n",
      "episode 2189, reward 310.0, memory_length 2000, epsilon 0.21603604719709862 total_time 721.0 step_num 109\n",
      "episode 2190, reward 751.0, memory_length 2000, epsilon 0.21588487488054434 total_time 721.0 step_num 117\n",
      "episode 2191, reward 26.0, memory_length 2000, epsilon 0.21573380834758302 total_time 722.0 step_num 121\n",
      "episode 2192, reward 353.0, memory_length 2000, epsilon 0.21558284752419213 total_time 725.0 step_num 102\n",
      "episode 2193, reward 170.0, memory_length 2000, epsilon 0.21543199233640087 total_time 722.0 step_num 111\n",
      "episode 2194, reward 436.0, memory_length 2000, epsilon 0.21528124271029012 total_time 721.0 step_num 113\n",
      "episode 2195, reward 386.0, memory_length 2000, epsilon 0.21513059857199265 total_time 722.0 step_num 116\n",
      "episode 2196, reward 206.0, memory_length 2000, epsilon 0.21498005984769278 total_time 722.0 step_num 124\n",
      "episode 2197, reward 400.0, memory_length 2000, epsilon 0.21482962646362647 total_time 721.0 step_num 115\n",
      "episode 2198, reward 157.0, memory_length 2000, epsilon 0.2146792983460815 total_time 721.0 step_num 103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2199, reward 366.0, memory_length 2000, epsilon 0.214529075421397 total_time 726.0 step_num 107\n",
      "episode 2200, reward 418.0, memory_length 2000, epsilon 0.21437895761596368 total_time 721.0 step_num 112\n",
      "episode 2201, reward -149.0, memory_length 2000, epsilon 0.21422894485622396 total_time 721.0 step_num 111\n",
      "episode 2202, reward 226.0, memory_length 2000, epsilon 0.21407903706867148 total_time 727.0 step_num 119\n",
      "episode 2203, reward 75.0, memory_length 2000, epsilon 0.2139292341798514 total_time 723.0 step_num 109\n",
      "episode 2204, reward 233.0, memory_length 2000, epsilon 0.21377953611636044 total_time 722.0 step_num 121\n",
      "episode 2205, reward 395.0, memory_length 2000, epsilon 0.2136299428048464 total_time 722.0 step_num 108\n",
      "episode 2206, reward 319.0, memory_length 2000, epsilon 0.21348045417200862 total_time 721.0 step_num 130\n",
      "episode 2207, reward 340.0, memory_length 2000, epsilon 0.21333107014459768 total_time 724.0 step_num 113\n",
      "episode 2208, reward 445.0, memory_length 2000, epsilon 0.2131817906494153 total_time 721.0 step_num 112\n",
      "episode 2209, reward 346.0, memory_length 2000, epsilon 0.21303261561331469 total_time 721.0 step_num 127\n",
      "episode 2210, reward 260.0, memory_length 2000, epsilon 0.21288354496319997 total_time 722.0 step_num 125\n",
      "episode 2211, reward 26.0, memory_length 2000, epsilon 0.21273457862602652 total_time 722.0 step_num 117\n",
      "episode 2212, reward 228.0, memory_length 2000, epsilon 0.21258571652880087 total_time 723.0 step_num 124\n",
      "episode 2213, reward 86.0, memory_length 2000, epsilon 0.21243695859858058 total_time 728.0 step_num 117\n",
      "episode 2214, reward 336.0, memory_length 2000, epsilon 0.21228830476247423 total_time 723.0 step_num 114\n",
      "episode 2215, reward 292.0, memory_length 2000, epsilon 0.21213975494764148 total_time 730.0 step_num 114\n",
      "episode 2216, reward 102.0, memory_length 2000, epsilon 0.2119913090812929 total_time 723.0 step_num 108\n",
      "episode 2217, reward 476.0, memory_length 2000, epsilon 0.21184296709068998 total_time 722.0 step_num 115\n",
      "episode 2218, reward 235.0, memory_length 2000, epsilon 0.21169472890314522 total_time 727.0 step_num 111\n",
      "episode 2219, reward 155.0, memory_length 2000, epsilon 0.21154659444602184 total_time 725.0 step_num 98\n",
      "episode 2220, reward 145.0, memory_length 2000, epsilon 0.21139856364673396 total_time 727.0 step_num 123\n",
      "episode 2221, reward 328.0, memory_length 2000, epsilon 0.2112506364327465 total_time 721.0 step_num 97\n",
      "episode 2222, reward 199.0, memory_length 2000, epsilon 0.21110281273157513 total_time 727.0 step_num 124\n",
      "episode 2223, reward 429.0, memory_length 2000, epsilon 0.21095509247078617 total_time 726.0 step_num 112\n",
      "episode 2224, reward 273.0, memory_length 2000, epsilon 0.21080747557799684 total_time 723.0 step_num 110\n",
      "episode 2225, reward 284.0, memory_length 2000, epsilon 0.21065996198087472 total_time 728.0 step_num 115\n",
      "episode 2226, reward 364.0, memory_length 2000, epsilon 0.2105125516071381 total_time 721.0 step_num 121\n",
      "episode 2227, reward 293.0, memory_length 2000, epsilon 0.2103652443845561 total_time 728.0 step_num 127\n",
      "episode 2228, reward 92.0, memory_length 2000, epsilon 0.21021804024094803 total_time 725.0 step_num 116\n",
      "episode 2229, reward 490.0, memory_length 2000, epsilon 0.21007093910418384 total_time 721.0 step_num 117\n",
      "episode 2230, reward 364.0, memory_length 2000, epsilon 0.20992394090218403 total_time 721.0 step_num 121\n",
      "episode 2231, reward 194.0, memory_length 2000, epsilon 0.20977704556291946 total_time 728.0 step_num 109\n",
      "episode 2232, reward 327.0, memory_length 2000, epsilon 0.20963025301441143 total_time 723.0 step_num 118\n",
      "episode 2233, reward 123.0, memory_length 2000, epsilon 0.20948356318473157 total_time 726.0 step_num 118\n",
      "episode 2234, reward 121.0, memory_length 2000, epsilon 0.20933697600200182 total_time 730.0 step_num 111\n",
      "episode 2235, reward 132.0, memory_length 2000, epsilon 0.20919049139439458 total_time 726.0 step_num 118\n",
      "episode 2236, reward 196.0, memory_length 2000, epsilon 0.20904410929013229 total_time 724.0 step_num 111\n",
      "episode 2237, reward 289.0, memory_length 2000, epsilon 0.20889782961748765 total_time 727.0 step_num 123\n",
      "episode 2238, reward 379.0, memory_length 2000, epsilon 0.2087516523047838 total_time 727.0 step_num 132\n",
      "episode 2239, reward 121.0, memory_length 2000, epsilon 0.20860557728039372 total_time 721.0 step_num 113\n",
      "episode 2240, reward 291.0, memory_length 2000, epsilon 0.20845960447274064 total_time 723.0 step_num 119\n",
      "episode 2241, reward 242.0, memory_length 2000, epsilon 0.20831373381029797 total_time 722.0 step_num 112\n",
      "episode 2242, reward 236.0, memory_length 2000, epsilon 0.2081679652215891 total_time 725.0 step_num 114\n",
      "episode 2243, reward 247.0, memory_length 2000, epsilon 0.2080222986351872 total_time 721.0 step_num 105\n",
      "episode 2244, reward 160.0, memory_length 2000, epsilon 0.2078767339797159 total_time 724.0 step_num 103\n",
      "episode 2245, reward 625.0, memory_length 2000, epsilon 0.2077312711838484 total_time 721.0 step_num 121\n",
      "episode 2246, reward 401.0, memory_length 2000, epsilon 0.20758591017630787 total_time 728.0 step_num 102\n",
      "episode 2247, reward 237.0, memory_length 2000, epsilon 0.20744065088586758 total_time 723.0 step_num 107\n",
      "episode 2248, reward 303.0, memory_length 2000, epsilon 0.20729549324135033 total_time 726.0 step_num 118\n",
      "episode 2249, reward 285.0, memory_length 2000, epsilon 0.20715043717162887 total_time 726.0 step_num 120\n",
      "episode 2250, reward 503.0, memory_length 2000, epsilon 0.20700548260562585 total_time 722.0 step_num 102\n",
      "episode 2251, reward 319.0, memory_length 2000, epsilon 0.2068606294723134 total_time 730.0 step_num 113\n",
      "episode 2252, reward 197.0, memory_length 2000, epsilon 0.20671587770071354 total_time 722.0 step_num 122\n",
      "episode 2253, reward 501.0, memory_length 2000, epsilon 0.20657122721989787 total_time 726.0 step_num 117\n",
      "episode 2254, reward 342.0, memory_length 2000, epsilon 0.20642667795898767 total_time 729.0 step_num 111\n",
      "episode 2255, reward 318.0, memory_length 2000, epsilon 0.20628222984715383 total_time 723.0 step_num 120\n",
      "episode 2256, reward 168.0, memory_length 2000, epsilon 0.20613788281361675 total_time 726.0 step_num 107\n",
      "episode 2257, reward 119.0, memory_length 2000, epsilon 0.20599363678764632 total_time 725.0 step_num 114\n",
      "episode 2258, reward 402.0, memory_length 2000, epsilon 0.2058494916985621 total_time 726.0 step_num 120\n",
      "episode 2259, reward 241.0, memory_length 2000, epsilon 0.2057054474757329 total_time 724.0 step_num 111\n",
      "episode 2260, reward 605.0, memory_length 2000, epsilon 0.20556150404857707 total_time 725.0 step_num 121\n",
      "episode 2261, reward 151.0, memory_length 2000, epsilon 0.20541766134656234 total_time 724.0 step_num 121\n",
      "episode 2262, reward 320.0, memory_length 2000, epsilon 0.20527391929920583 total_time 728.0 step_num 115\n",
      "episode 2263, reward 344.0, memory_length 2000, epsilon 0.2051302778360738 total_time 725.0 step_num 122\n",
      "episode 2264, reward 184.0, memory_length 2000, epsilon 0.20498673688678207 total_time 721.0 step_num 110\n",
      "episode 2265, reward 756.0, memory_length 2000, epsilon 0.20484329638099552 total_time 729.0 step_num 121\n",
      "episode 2266, reward 176.0, memory_length 2000, epsilon 0.20469995624842824 total_time 728.0 step_num 108\n",
      "episode 2267, reward 220.0, memory_length 2000, epsilon 0.20455671641884368 total_time 721.0 step_num 115\n",
      "episode 2268, reward 301.0, memory_length 2000, epsilon 0.20441357682205424 total_time 721.0 step_num 108\n",
      "episode 2269, reward 333.0, memory_length 2000, epsilon 0.2042705373879215 total_time 729.0 step_num 112\n",
      "episode 2270, reward 139.0, memory_length 2000, epsilon 0.20412759804635622 total_time 721.0 step_num 110\n",
      "episode 2271, reward 317.0, memory_length 2000, epsilon 0.20398475872731806 total_time 725.0 step_num 111\n",
      "episode 2272, reward 255.0, memory_length 2000, epsilon 0.2038420193608157 total_time 723.0 step_num 131\n",
      "episode 2273, reward 426.0, memory_length 2000, epsilon 0.20369937987690695 total_time 723.0 step_num 116\n",
      "episode 2274, reward 70.0, memory_length 2000, epsilon 0.20355684020569842 total_time 724.0 step_num 112\n",
      "episode 2275, reward 122.0, memory_length 2000, epsilon 0.20341440027734561 total_time 728.0 step_num 112\n",
      "episode 2276, reward 291.0, memory_length 2000, epsilon 0.20327206002205309 total_time 723.0 step_num 127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2277, reward 139.0, memory_length 2000, epsilon 0.20312981937007396 total_time 721.0 step_num 112\n",
      "episode 2278, reward 74.0, memory_length 2000, epsilon 0.20298767825171046 total_time 734.0 step_num 106\n",
      "episode 2279, reward 374.0, memory_length 2000, epsilon 0.20284563659731333 total_time 728.0 step_num 103\n",
      "episode 2280, reward 346.0, memory_length 2000, epsilon 0.20270369433728216 total_time 721.0 step_num 121\n",
      "episode 2281, reward 274.0, memory_length 2000, epsilon 0.20256185140206537 total_time 730.0 step_num 116\n",
      "episode 2282, reward 500.0, memory_length 2000, epsilon 0.20242010772215974 total_time 728.0 step_num 122\n",
      "episode 2283, reward 382.0, memory_length 2000, epsilon 0.20227846322811097 total_time 721.0 step_num 123\n",
      "episode 2284, reward 267.0, memory_length 2000, epsilon 0.2021369178505132 total_time 726.0 step_num 120\n",
      "episode 2285, reward 355.0, memory_length 2000, epsilon 0.20199547152000927 total_time 721.0 step_num 118\n",
      "episode 2286, reward -53.0, memory_length 2000, epsilon 0.20185412416729034 total_time 727.0 step_num 119\n",
      "episode 2287, reward 332.0, memory_length 2000, epsilon 0.20171287572309637 total_time 722.0 step_num 113\n",
      "episode 2288, reward 166.0, memory_length 2000, epsilon 0.20157172611821556 total_time 721.0 step_num 119\n",
      "episode 2289, reward 448.0, memory_length 2000, epsilon 0.20143067528348452 total_time 724.0 step_num 123\n",
      "episode 2290, reward 391.0, memory_length 2000, epsilon 0.20128972314978844 total_time 721.0 step_num 120\n",
      "episode 2291, reward -60.0, memory_length 2000, epsilon 0.2011488696480607 total_time 723.0 step_num 113\n",
      "episode 2292, reward 447.0, memory_length 2000, epsilon 0.20100811470928312 total_time 726.0 step_num 118\n",
      "episode 2293, reward 67.0, memory_length 2000, epsilon 0.2008674582644858 total_time 721.0 step_num 120\n",
      "episode 2294, reward 490.0, memory_length 2000, epsilon 0.20072690024474701 total_time 721.0 step_num 121\n",
      "episode 2295, reward 179.0, memory_length 2000, epsilon 0.20058644058119335 total_time 722.0 step_num 128\n",
      "episode 2296, reward 497.0, memory_length 2000, epsilon 0.2004460792049996 total_time 725.0 step_num 111\n",
      "episode 2297, reward 245.0, memory_length 2000, epsilon 0.20030581604738867 total_time 725.0 step_num 112\n",
      "episode 2298, reward 394.0, memory_length 2000, epsilon 0.20016565103963163 total_time 724.0 step_num 125\n",
      "episode 2299, reward 212.0, memory_length 2000, epsilon 0.2000255841130476 total_time 728.0 step_num 109\n",
      "episode 2300, reward 229.0, memory_length 2000, epsilon 0.19988561519900377 total_time 721.0 step_num 118\n",
      "episode 2301, reward 220.0, memory_length 2000, epsilon 0.1997457442289154 total_time 721.0 step_num 105\n",
      "episode 2302, reward -132.0, memory_length 2000, epsilon 0.1996059711342457 total_time 723.0 step_num 101\n",
      "episode 2303, reward 504.0, memory_length 2000, epsilon 0.1994662958465058 total_time 729.0 step_num 115\n",
      "episode 2304, reward 173.0, memory_length 2000, epsilon 0.19932671829725493 total_time 725.0 step_num 113\n",
      "episode 2305, reward 272.0, memory_length 2000, epsilon 0.1991872384181 total_time 725.0 step_num 106\n",
      "episode 2306, reward 53.0, memory_length 2000, epsilon 0.19904785614069584 total_time 722.0 step_num 127\n",
      "episode 2307, reward 120.0, memory_length 2000, epsilon 0.1989085713967452 total_time 723.0 step_num 114\n",
      "episode 2308, reward 290.0, memory_length 2000, epsilon 0.19876938411799852 total_time 725.0 step_num 126\n",
      "episode 2309, reward 4.0, memory_length 2000, epsilon 0.19863029423625403 total_time 721.0 step_num 112\n",
      "episode 2310, reward 298.0, memory_length 2000, epsilon 0.1984913016833577 total_time 727.0 step_num 104\n",
      "episode 2311, reward 682.0, memory_length 2000, epsilon 0.19835240639120316 total_time 724.0 step_num 123\n",
      "episode 2312, reward 544.0, memory_length 2000, epsilon 0.1982136082917317 total_time 721.0 step_num 124\n",
      "episode 2313, reward 51.0, memory_length 2000, epsilon 0.1980749073169323 total_time 726.0 step_num 105\n",
      "episode 2314, reward 139.0, memory_length 2000, epsilon 0.19793630339884147 total_time 721.0 step_num 102\n",
      "episode 2315, reward 431.0, memory_length 2000, epsilon 0.19779779646954324 total_time 722.0 step_num 129\n",
      "episode 2316, reward 166.0, memory_length 2000, epsilon 0.1976593864611692 total_time 730.0 step_num 114\n",
      "episode 2317, reward 67.0, memory_length 2000, epsilon 0.19752107330589852 total_time 721.0 step_num 116\n",
      "episode 2318, reward 517.0, memory_length 2000, epsilon 0.1973828569359577 total_time 721.0 step_num 113\n",
      "episode 2319, reward 175.0, memory_length 2000, epsilon 0.19724473728362077 total_time 721.0 step_num 122\n",
      "episode 2320, reward 407.0, memory_length 2000, epsilon 0.19710671428120902 total_time 725.0 step_num 118\n",
      "episode 2321, reward 89.0, memory_length 2000, epsilon 0.19696878786109118 total_time 722.0 step_num 113\n",
      "episode 2322, reward 323.0, memory_length 2000, epsilon 0.1968309579556834 total_time 722.0 step_num 129\n",
      "episode 2323, reward 256.0, memory_length 2000, epsilon 0.19669322449744892 total_time 721.0 step_num 128\n",
      "episode 2324, reward 271.0, memory_length 2000, epsilon 0.19655558741889836 total_time 727.0 step_num 114\n",
      "episode 2325, reward 166.0, memory_length 2000, epsilon 0.1964180466525896 total_time 721.0 step_num 109\n",
      "episode 2326, reward 372.0, memory_length 2000, epsilon 0.19628060213112755 total_time 723.0 step_num 129\n",
      "episode 2327, reward 227.0, memory_length 2000, epsilon 0.19614325378716457 total_time 725.0 step_num 128\n",
      "episode 2328, reward 44.0, memory_length 2000, epsilon 0.19600600155339987 total_time 731.0 step_num 106\n",
      "episode 2329, reward 121.0, memory_length 2000, epsilon 0.19586884536257979 total_time 721.0 step_num 131\n",
      "episode 2330, reward 507.0, memory_length 2000, epsilon 0.1957317851474979 total_time 723.0 step_num 113\n",
      "episode 2331, reward 58.0, memory_length 2000, epsilon 0.19559482084099464 total_time 721.0 step_num 114\n",
      "episode 2332, reward 354.0, memory_length 2000, epsilon 0.19545795237595748 total_time 723.0 step_num 105\n",
      "episode 2333, reward 274.0, memory_length 2000, epsilon 0.19532117968532095 total_time 721.0 step_num 114\n",
      "episode 2334, reward 299.0, memory_length 2000, epsilon 0.19518450270206633 total_time 725.0 step_num 117\n",
      "episode 2335, reward 121.0, memory_length 2000, epsilon 0.19504792135922194 total_time 721.0 step_num 111\n",
      "episode 2336, reward 215.0, memory_length 2000, epsilon 0.19491143558986293 total_time 722.0 step_num 125\n",
      "episode 2337, reward 196.0, memory_length 2000, epsilon 0.1947750453271113 total_time 724.0 step_num 119\n",
      "episode 2338, reward 232.0, memory_length 2000, epsilon 0.19463875050413568 total_time 724.0 step_num 110\n",
      "episode 2339, reward 291.0, memory_length 2000, epsilon 0.1945025510541518 total_time 723.0 step_num 124\n",
      "episode 2340, reward 251.0, memory_length 2000, epsilon 0.19436644691042176 total_time 722.0 step_num 113\n",
      "episode 2341, reward 427.0, memory_length 2000, epsilon 0.1942304380062546 total_time 721.0 step_num 99\n",
      "episode 2342, reward 287.0, memory_length 2000, epsilon 0.19409452427500598 total_time 722.0 step_num 111\n",
      "episode 2343, reward 143.0, memory_length 2000, epsilon 0.19395870565007817 total_time 722.0 step_num 128\n",
      "episode 2344, reward 382.0, memory_length 2000, epsilon 0.19382298206491994 total_time 721.0 step_num 121\n",
      "episode 2345, reward 152.0, memory_length 2000, epsilon 0.19368735345302682 total_time 722.0 step_num 129\n",
      "episode 2346, reward 508.0, memory_length 2000, epsilon 0.1935518197479408 total_time 721.0 step_num 118\n",
      "episode 2347, reward 164.0, memory_length 2000, epsilon 0.19341638088325028 total_time 725.0 step_num 117\n",
      "episode 2348, reward 271.0, memory_length 2000, epsilon 0.1932810367925903 total_time 727.0 step_num 108\n",
      "episode 2349, reward 74.0, memory_length 2000, epsilon 0.19314578740964222 total_time 725.0 step_num 112\n",
      "episode 2350, reward 467.0, memory_length 2000, epsilon 0.19301063266813379 total_time 722.0 step_num 107\n",
      "episode 2351, reward 168.0, memory_length 2000, epsilon 0.19287557250183926 total_time 726.0 step_num 105\n",
      "episode 2352, reward 409.0, memory_length 2000, epsilon 0.19274060684457908 total_time 721.0 step_num 102\n",
      "episode 2353, reward 272.0, memory_length 2000, epsilon 0.19260573563022015 total_time 725.0 step_num 115\n",
      "episode 2354, reward 490.0, memory_length 2000, epsilon 0.19247095879267556 total_time 730.0 step_num 115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2355, reward 220.0, memory_length 2000, epsilon 0.19233627626590455 total_time 721.0 step_num 109\n",
      "episode 2356, reward 364.0, memory_length 2000, epsilon 0.19220168798391282 total_time 721.0 step_num 107\n",
      "episode 2357, reward 110.0, memory_length 2000, epsilon 0.19206719388075205 total_time 725.0 step_num 110\n",
      "episode 2358, reward 142.0, memory_length 2000, epsilon 0.19193279389052006 total_time 724.0 step_num 116\n",
      "episode 2359, reward 137.0, memory_length 2000, epsilon 0.191798487947361 total_time 725.0 step_num 121\n",
      "episode 2360, reward 67.0, memory_length 2000, epsilon 0.19166427598546482 total_time 721.0 step_num 102\n",
      "episode 2361, reward 337.0, memory_length 2000, epsilon 0.1915301579390677 total_time 739.0 step_num 104\n",
      "episode 2362, reward 202.0, memory_length 2000, epsilon 0.19139613374245185 total_time 721.0 step_num 115\n",
      "episode 2363, reward 200.0, memory_length 2000, epsilon 0.19126220332994534 total_time 725.0 step_num 121\n",
      "episode 2364, reward 397.0, memory_length 2000, epsilon 0.19112836663592225 total_time 727.0 step_num 111\n",
      "episode 2365, reward -29.0, memory_length 2000, epsilon 0.1909946235948027 total_time 724.0 step_num 101\n",
      "episode 2366, reward 485.0, memory_length 2000, epsilon 0.19086097414105252 total_time 722.0 step_num 107\n",
      "episode 2367, reward 526.0, memory_length 2000, epsilon 0.19072741820918343 total_time 730.0 step_num 102\n",
      "episode 2368, reward 35.0, memory_length 2000, epsilon 0.19059395573375315 total_time 722.0 step_num 134\n",
      "episode 2369, reward 426.0, memory_length 2000, epsilon 0.19046058664936497 total_time 723.0 step_num 116\n",
      "episode 2370, reward 219.0, memory_length 2000, epsilon 0.19032731089066804 total_time 723.0 step_num 124\n",
      "episode 2371, reward 355.0, memory_length 2000, epsilon 0.19019412839235725 total_time 730.0 step_num 105\n",
      "episode 2372, reward 431.0, memory_length 2000, epsilon 0.19006103908917324 total_time 722.0 step_num 114\n",
      "episode 2373, reward 623.0, memory_length 2000, epsilon 0.1899280429159021 total_time 725.0 step_num 114\n",
      "episode 2374, reward 140.0, memory_length 2000, epsilon 0.18979513980737583 total_time 728.0 step_num 120\n",
      "episode 2375, reward 135.0, memory_length 2000, epsilon 0.18966232969847183 total_time 729.0 step_num 112\n",
      "episode 2376, reward 182.0, memory_length 2000, epsilon 0.18952961252411324 total_time 725.0 step_num 119\n",
      "episode 2377, reward 148.0, memory_length 2000, epsilon 0.18939698821926856 total_time 721.0 step_num 113\n",
      "episode 2378, reward 357.0, memory_length 2000, epsilon 0.18926445671895187 total_time 726.0 step_num 108\n",
      "episode 2379, reward -66.0, memory_length 2000, epsilon 0.1891320179582228 total_time 726.0 step_num 115\n",
      "episode 2380, reward 370.0, memory_length 2000, epsilon 0.18899967187218628 total_time 736.0 step_num 116\n",
      "episode 2381, reward 525.0, memory_length 2000, epsilon 0.18886741839599275 total_time 723.0 step_num 103\n",
      "episode 2382, reward 69.0, memory_length 2000, epsilon 0.18873525746483805 total_time 726.0 step_num 97\n",
      "episode 2383, reward 377.0, memory_length 2000, epsilon 0.18860318901396328 total_time 722.0 step_num 114\n",
      "episode 2384, reward 143.0, memory_length 2000, epsilon 0.18847121297865485 total_time 722.0 step_num 120\n",
      "episode 2385, reward 382.0, memory_length 2000, epsilon 0.1883393292942446 total_time 721.0 step_num 110\n",
      "episode 2386, reward 269.0, memory_length 2000, epsilon 0.18820753789610947 total_time 722.0 step_num 117\n",
      "episode 2387, reward 180.0, memory_length 2000, epsilon 0.18807583871967165 total_time 738.0 step_num 117\n",
      "episode 2388, reward 188.0, memory_length 2000, epsilon 0.1879442317003986 total_time 722.0 step_num 115\n",
      "episode 2389, reward 440.0, memory_length 2000, epsilon 0.18781271677380282 total_time 722.0 step_num 112\n",
      "episode 2390, reward 377.0, memory_length 2000, epsilon 0.18768129387544197 total_time 722.0 step_num 126\n",
      "episode 2391, reward 467.0, memory_length 2000, epsilon 0.18754996294091894 total_time 722.0 step_num 112\n",
      "episode 2392, reward 463.0, memory_length 2000, epsilon 0.18741872390588152 total_time 721.0 step_num 107\n",
      "episode 2393, reward 132.0, memory_length 2000, epsilon 0.1872875767060225 total_time 726.0 step_num 112\n",
      "episode 2394, reward -28.0, memory_length 2000, epsilon 0.18715652127707985 total_time 722.0 step_num 129\n",
      "episode 2395, reward 319.0, memory_length 2000, epsilon 0.18702555755483638 total_time 721.0 step_num 104\n",
      "episode 2396, reward 148.0, memory_length 2000, epsilon 0.1868946854751198 total_time 721.0 step_num 115\n",
      "episode 2397, reward 419.0, memory_length 2000, epsilon 0.1867639049738029 total_time 728.0 step_num 106\n",
      "episode 2398, reward 467.0, memory_length 2000, epsilon 0.18663321598680316 total_time 722.0 step_num 111\n",
      "episode 2399, reward 278.0, memory_length 2000, epsilon 0.18650261845008298 total_time 722.0 step_num 107\n",
      "episode 2400, reward 260.0, memory_length 2000, epsilon 0.1863721122996496 total_time 722.0 step_num 117\n",
      "episode 2401, reward 429.0, memory_length 2000, epsilon 0.1862416974715549 total_time 726.0 step_num 110\n",
      "episode 2402, reward 101.0, memory_length 2000, epsilon 0.18611137390189575 total_time 725.0 step_num 111\n",
      "episode 2403, reward 111.0, memory_length 2000, epsilon 0.18598114152681355 total_time 723.0 step_num 122\n",
      "episode 2404, reward 37.0, memory_length 2000, epsilon 0.18585100028249438 total_time 727.0 step_num 114\n",
      "episode 2405, reward 22.0, memory_length 2000, epsilon 0.1857209501051691 total_time 730.0 step_num 119\n",
      "episode 2406, reward 89.0, memory_length 2000, epsilon 0.1855909909311131 total_time 722.0 step_num 125\n",
      "episode 2407, reward 362.0, memory_length 2000, epsilon 0.18546112269664627 total_time 725.0 step_num 117\n",
      "episode 2408, reward 372.0, memory_length 2000, epsilon 0.18533134533813336 total_time 723.0 step_num 117\n",
      "episode 2409, reward 184.0, memory_length 2000, epsilon 0.18520165879198336 total_time 730.0 step_num 114\n",
      "episode 2410, reward 681.0, memory_length 2000, epsilon 0.18507206299464984 total_time 726.0 step_num 120\n",
      "episode 2411, reward 449.0, memory_length 2000, epsilon 0.18494255788263095 total_time 722.0 step_num 125\n",
      "episode 2412, reward 209.0, memory_length 2000, epsilon 0.1848131433924691 total_time 725.0 step_num 112\n",
      "episode 2413, reward 178.0, memory_length 2000, epsilon 0.1846838194607512 total_time 724.0 step_num 117\n",
      "episode 2414, reward 248.0, memory_length 2000, epsilon 0.1845545860241085 total_time 728.0 step_num 125\n",
      "episode 2415, reward 393.0, memory_length 2000, epsilon 0.1844254430192167 total_time 726.0 step_num 118\n",
      "episode 2416, reward 643.0, memory_length 2000, epsilon 0.18429639038279563 total_time 721.0 step_num 110\n",
      "episode 2417, reward 490.0, memory_length 2000, epsilon 0.18416742805160957 total_time 721.0 step_num 112\n",
      "episode 2418, reward 479.0, memory_length 2000, epsilon 0.18403855596246693 total_time 725.0 step_num 115\n",
      "episode 2419, reward 319.0, memory_length 2000, epsilon 0.18390977405222037 total_time 730.0 step_num 119\n",
      "episode 2420, reward -100.0, memory_length 2000, epsilon 0.1837810822577668 total_time 722.0 step_num 116\n",
      "episode 2421, reward 589.0, memory_length 2000, epsilon 0.18365248051604718 total_time 721.0 step_num 117\n",
      "episode 2422, reward 319.0, memory_length 2000, epsilon 0.1835239687640467 total_time 721.0 step_num 117\n",
      "episode 2423, reward 286.0, memory_length 2000, epsilon 0.18339554693879462 total_time 724.0 step_num 106\n",
      "episode 2424, reward 466.0, memory_length 2000, epsilon 0.18326721497736415 total_time 724.0 step_num 125\n",
      "episode 2425, reward 327.0, memory_length 2000, epsilon 0.18313897281687272 total_time 723.0 step_num 119\n",
      "episode 2426, reward 176.0, memory_length 2000, epsilon 0.18301082039448166 total_time 728.0 step_num 118\n",
      "episode 2427, reward 316.0, memory_length 2000, epsilon 0.18288275764739623 total_time 727.0 step_num 108\n",
      "episode 2428, reward 409.0, memory_length 2000, epsilon 0.18275478451286573 total_time 721.0 step_num 121\n",
      "episode 2429, reward 427.0, memory_length 2000, epsilon 0.1826269009281833 total_time 721.0 step_num 115\n",
      "episode 2430, reward 363.0, memory_length 2000, epsilon 0.1824991068306859 total_time 723.0 step_num 113\n",
      "episode 2431, reward 202.0, memory_length 2000, epsilon 0.18237140215775455 total_time 721.0 step_num 120\n",
      "episode 2432, reward 149.0, memory_length 2000, epsilon 0.18224378684681394 total_time 728.0 step_num 117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2433, reward 271.0, memory_length 2000, epsilon 0.18211626083533247 total_time 727.0 step_num 111\n",
      "episode 2434, reward 165.0, memory_length 2000, epsilon 0.1819888240608225 total_time 723.0 step_num 111\n",
      "episode 2435, reward 193.0, memory_length 2000, epsilon 0.18186147646083997 total_time 730.0 step_num 115\n",
      "episode 2436, reward 168.0, memory_length 2000, epsilon 0.18173421797298447 total_time 726.0 step_num 116\n",
      "episode 2437, reward 385.0, memory_length 2000, epsilon 0.1816070485348995 total_time 733.0 step_num 119\n",
      "episode 2438, reward 412.0, memory_length 2000, epsilon 0.18147996808427191 total_time 724.0 step_num 123\n",
      "episode 2439, reward -28.0, memory_length 2000, epsilon 0.18135297655883229 total_time 722.0 step_num 113\n",
      "episode 2440, reward 94.0, memory_length 2000, epsilon 0.18122607389635484 total_time 730.0 step_num 111\n",
      "episode 2441, reward 280.0, memory_length 2000, epsilon 0.18109926003465723 total_time 727.0 step_num 124\n",
      "episode 2442, reward 130.0, memory_length 2000, epsilon 0.18097253491160062 total_time 721.0 step_num 108\n",
      "episode 2443, reward 202.0, memory_length 2000, epsilon 0.1808458984650898 total_time 721.0 step_num 105\n",
      "episode 2444, reward 255.0, memory_length 2000, epsilon 0.18071935063307282 total_time 723.0 step_num 114\n",
      "episode 2445, reward -31.0, memory_length 2000, epsilon 0.18059289135354123 total_time 728.0 step_num 117\n",
      "episode 2446, reward 341.0, memory_length 2000, epsilon 0.18046652056453005 total_time 722.0 step_num 110\n",
      "episode 2447, reward 320.0, memory_length 2000, epsilon 0.18034023820411754 total_time 728.0 step_num 123\n",
      "episode 2448, reward 172.0, memory_length 2000, epsilon 0.1802140442104254 total_time 727.0 step_num 116\n",
      "episode 2449, reward 418.0, memory_length 2000, epsilon 0.1800879385216185 total_time 721.0 step_num 104\n",
      "episode 2450, reward 35.0, memory_length 2000, epsilon 0.17996192107590506 total_time 722.0 step_num 112\n",
      "episode 2451, reward 346.0, memory_length 2000, epsilon 0.1798359918115366 total_time 721.0 step_num 115\n",
      "episode 2452, reward 341.0, memory_length 2000, epsilon 0.17971015066680768 total_time 722.0 step_num 118\n",
      "episode 2453, reward 154.0, memory_length 2000, epsilon 0.17958439758005615 total_time 727.0 step_num 109\n",
      "episode 2454, reward 184.0, memory_length 2000, epsilon 0.1794587324896631 total_time 721.0 step_num 111\n",
      "episode 2455, reward 366.0, memory_length 2000, epsilon 0.17933315533405256 total_time 726.0 step_num 126\n",
      "episode 2456, reward 220.0, memory_length 2000, epsilon 0.17920766605169167 total_time 721.0 step_num 112\n",
      "episode 2457, reward 107.0, memory_length 2000, epsilon 0.17908226458109075 total_time 722.0 step_num 118\n",
      "episode 2458, reward 382.0, memory_length 2000, epsilon 0.1789569508608031 total_time 721.0 step_num 124\n",
      "episode 2459, reward -10.0, memory_length 2000, epsilon 0.17883172482942486 total_time 722.0 step_num 115\n",
      "episode 2460, reward 275.0, memory_length 2000, epsilon 0.17870658642559545 total_time 728.0 step_num 105\n",
      "episode 2461, reward 65.0, memory_length 2000, epsilon 0.17858153558799694 total_time 725.0 step_num 120\n",
      "episode 2462, reward 302.0, memory_length 2000, epsilon 0.1784565722553544 total_time 728.0 step_num 108\n",
      "episode 2463, reward 183.0, memory_length 2000, epsilon 0.1783316963664359 total_time 723.0 step_num 133\n",
      "episode 2464, reward 380.0, memory_length 2000, epsilon 0.17820690786005217 total_time 725.0 step_num 119\n",
      "episode 2465, reward 370.0, memory_length 2000, epsilon 0.1780822066750568 total_time 727.0 step_num 125\n",
      "episode 2466, reward 158.0, memory_length 2000, epsilon 0.17795759275034634 total_time 728.0 step_num 120\n",
      "episode 2467, reward 272.0, memory_length 2000, epsilon 0.17783306602485988 total_time 725.0 step_num 113\n",
      "episode 2468, reward 295.0, memory_length 2000, epsilon 0.1777086264375793 total_time 724.0 step_num 119\n",
      "episode 2469, reward 404.0, memory_length 2000, epsilon 0.17758427392752923 total_time 722.0 step_num 116\n",
      "episode 2470, reward 449.0, memory_length 2000, epsilon 0.17746000843377693 total_time 722.0 step_num 112\n",
      "episode 2471, reward 357.0, memory_length 2000, epsilon 0.17733582989543234 total_time 726.0 step_num 119\n",
      "episode 2472, reward 331.0, memory_length 2000, epsilon 0.17721173825164796 total_time 724.0 step_num 110\n",
      "episode 2473, reward 490.0, memory_length 2000, epsilon 0.17708773344161882 total_time 721.0 step_num 111\n",
      "episode 2474, reward 363.0, memory_length 2000, epsilon 0.17696381540458264 total_time 723.0 step_num 108\n",
      "episode 2475, reward 263.0, memory_length 2000, epsilon 0.17683998407981957 total_time 725.0 step_num 112\n",
      "episode 2476, reward 272.0, memory_length 2000, epsilon 0.17671623940665218 total_time 725.0 step_num 106\n",
      "episode 2477, reward 363.0, memory_length 2000, epsilon 0.1765925813244457 total_time 723.0 step_num 114\n",
      "episode 2478, reward 409.0, memory_length 2000, epsilon 0.17646900977260757 total_time 721.0 step_num 131\n",
      "episode 2479, reward 362.0, memory_length 2000, epsilon 0.17634552469058773 total_time 725.0 step_num 112\n",
      "episode 2480, reward 21.0, memory_length 2000, epsilon 0.17622212601787854 total_time 723.0 step_num 120\n",
      "episode 2481, reward 364.0, memory_length 2000, epsilon 0.17609881369401464 total_time 721.0 step_num 110\n",
      "episode 2482, reward 256.0, memory_length 2000, epsilon 0.17597558765857296 total_time 721.0 step_num 114\n",
      "episode 2483, reward 265.0, memory_length 2000, epsilon 0.1758524478511728 total_time 721.0 step_num 118\n",
      "episode 2484, reward 516.0, memory_length 2000, epsilon 0.17572939421147554 total_time 723.0 step_num 110\n",
      "episode 2485, reward 4.0, memory_length 2000, epsilon 0.17560642667918497 total_time 721.0 step_num 120\n",
      "episode 2486, reward 571.0, memory_length 2000, epsilon 0.17548354519404702 total_time 721.0 step_num 107\n",
      "episode 2487, reward 227.0, memory_length 2000, epsilon 0.1753607496958497 total_time 725.0 step_num 109\n",
      "episode 2488, reward 452.0, memory_length 2000, epsilon 0.17523804012442323 total_time 725.0 step_num 105\n",
      "episode 2489, reward 520.0, memory_length 2000, epsilon 0.17511541641963996 total_time 724.0 step_num 108\n",
      "episode 2490, reward 175.0, memory_length 2000, epsilon 0.17499287852141424 total_time 730.0 step_num 115\n",
      "episode 2491, reward 152.0, memory_length 2000, epsilon 0.17487042636970246 total_time 722.0 step_num 110\n",
      "episode 2492, reward 348.0, memory_length 2000, epsilon 0.17474805990450312 total_time 726.0 step_num 124\n",
      "episode 2493, reward 1.0, memory_length 2000, epsilon 0.17462577906585663 total_time 727.0 step_num 122\n",
      "episode 2494, reward 258.0, memory_length 2000, epsilon 0.17450358379384537 total_time 726.0 step_num 114\n",
      "episode 2495, reward 395.0, memory_length 2000, epsilon 0.17438147402859366 total_time 731.0 step_num 107\n",
      "episode 2496, reward 517.0, memory_length 2000, epsilon 0.17425944971026772 total_time 730.0 step_num 114\n",
      "episode 2497, reward 517.0, memory_length 2000, epsilon 0.1741375107790756 total_time 721.0 step_num 124\n",
      "episode 2498, reward 143.0, memory_length 2000, epsilon 0.17401565717526732 total_time 722.0 step_num 111\n",
      "episode 2499, reward 3.0, memory_length 2000, epsilon 0.17389388883913445 total_time 723.0 step_num 116\n",
      "episode 2500, reward 260.0, memory_length 2000, epsilon 0.17377220571101065 total_time 722.0 step_num 108\n",
      "episode 2501, reward 418.0, memory_length 2000, epsilon 0.17365060773127108 total_time 730.0 step_num 107\n",
      "episode 2502, reward 372.0, memory_length 2000, epsilon 0.1735290948403328 total_time 723.0 step_num 114\n",
      "episode 2503, reward 409.0, memory_length 2000, epsilon 0.17340766697865445 total_time 721.0 step_num 123\n",
      "episode 2504, reward 349.0, memory_length 2000, epsilon 0.17328632408673642 total_time 724.0 step_num 111\n",
      "episode 2505, reward 223.0, memory_length 2000, epsilon 0.1731650661051206 total_time 724.0 step_num 124\n",
      "episode 2506, reward 535.0, memory_length 2000, epsilon 0.17304389297439068 total_time 721.0 step_num 115\n",
      "episode 2507, reward 202.0, memory_length 2000, epsilon 0.1729228046351718 total_time 721.0 step_num 103\n",
      "episode 2508, reward 257.0, memory_length 2000, epsilon 0.17280180102813059 total_time 728.0 step_num 116\n",
      "episode 2509, reward 318.0, memory_length 2000, epsilon 0.1726808820939754 total_time 723.0 step_num 120\n",
      "episode 2510, reward 8.0, memory_length 2000, epsilon 0.17256004777345588 total_time 722.0 step_num 110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2511, reward -163.0, memory_length 2000, epsilon 0.17243929800736318 total_time 722.0 step_num 124\n",
      "episode 2512, reward 292.0, memory_length 2000, epsilon 0.17231863273653 total_time 721.0 step_num 129\n",
      "episode 2513, reward 202.0, memory_length 2000, epsilon 0.17219805190183032 total_time 721.0 step_num 98\n",
      "episode 2514, reward 544.0, memory_length 2000, epsilon 0.17207755544417944 total_time 721.0 step_num 115\n",
      "episode 2515, reward 368.0, memory_length 2000, epsilon 0.17195714330453424 total_time 731.0 step_num 115\n",
      "episode 2516, reward 379.0, memory_length 2000, epsilon 0.1718368154238927 total_time 727.0 step_num 127\n",
      "episode 2517, reward 222.0, memory_length 2000, epsilon 0.1717165717432941 total_time 726.0 step_num 110\n",
      "episode 2518, reward 206.0, memory_length 2000, epsilon 0.17159641220381913 total_time 722.0 step_num 118\n",
      "episode 2519, reward 137.0, memory_length 2000, epsilon 0.17147633674658957 total_time 725.0 step_num 120\n",
      "episode 2520, reward 571.0, memory_length 2000, epsilon 0.17135634531276844 total_time 730.0 step_num 126\n",
      "episode 2521, reward 76.0, memory_length 2000, epsilon 0.17123643784355996 total_time 730.0 step_num 115\n",
      "episode 2522, reward 239.0, memory_length 2000, epsilon 0.1711166142802094 total_time 728.0 step_num 124\n",
      "episode 2523, reward 331.0, memory_length 2000, epsilon 0.17099687456400334 total_time 724.0 step_num 121\n",
      "episode 2524, reward 118.0, memory_length 2000, epsilon 0.1708772186362692 total_time 727.0 step_num 109\n",
      "episode 2525, reward 391.0, memory_length 2000, epsilon 0.17075764643837557 total_time 721.0 step_num 109\n",
      "episode 2526, reward 451.0, memory_length 2000, epsilon 0.17063815791173215 total_time 727.0 step_num 115\n",
      "episode 2527, reward 314.0, memory_length 2000, epsilon 0.17051875299778957 total_time 722.0 step_num 116\n",
      "episode 2528, reward 85.0, memory_length 2000, epsilon 0.17039943163803928 total_time 721.0 step_num 103\n",
      "episode 2529, reward 722.0, memory_length 2000, epsilon 0.17028019377401396 total_time 725.0 step_num 124\n",
      "episode 2530, reward 301.0, memory_length 2000, epsilon 0.170161039347287 total_time 721.0 step_num 127\n",
      "episode 2531, reward 490.0, memory_length 2000, epsilon 0.17004196829947266 total_time 721.0 step_num 109\n",
      "episode 2532, reward 390.0, memory_length 2000, epsilon 0.16992298057222624 total_time 723.0 step_num 103\n",
      "episode 2533, reward 352.0, memory_length 2000, epsilon 0.1698040761072437 total_time 727.0 step_num 115\n",
      "episode 2534, reward 305.0, memory_length 2000, epsilon 0.16968525484626182 total_time 722.0 step_num 111\n",
      "episode 2535, reward 241.0, memory_length 2000, epsilon 0.16956651673105824 total_time 724.0 step_num 111\n",
      "episode 2536, reward -15.0, memory_length 2000, epsilon 0.16944786170345127 total_time 723.0 step_num 116\n",
      "episode 2537, reward 233.0, memory_length 2000, epsilon 0.16932928970529987 total_time 722.0 step_num 122\n",
      "episode 2538, reward 176.0, memory_length 2000, epsilon 0.16921080067850383 total_time 728.0 step_num 116\n",
      "episode 2539, reward -39.0, memory_length 2000, epsilon 0.16909239456500355 total_time 726.0 step_num 109\n",
      "episode 2540, reward 328.0, memory_length 2000, epsilon 0.16897407130677994 total_time 721.0 step_num 120\n",
      "episode 2541, reward 278.0, memory_length 2000, epsilon 0.16885583084585468 total_time 722.0 step_num 126\n",
      "episode 2542, reward 566.0, memory_length 2000, epsilon 0.16873767312428986 total_time 722.0 step_num 117\n",
      "episode 2543, reward 253.0, memory_length 2000, epsilon 0.1686195980841883 total_time 727.0 step_num 106\n",
      "episode 2544, reward 382.0, memory_length 2000, epsilon 0.16850160566769318 total_time 721.0 step_num 116\n",
      "episode 2545, reward 245.0, memory_length 2000, epsilon 0.16838369581698817 total_time 725.0 step_num 109\n",
      "episode 2546, reward 416.0, memory_length 2000, epsilon 0.16826586847429753 total_time 725.0 step_num 110\n",
      "episode 2547, reward 440.0, memory_length 2000, epsilon 0.1681481235818858 total_time 722.0 step_num 106\n",
      "episode 2548, reward 210.0, memory_length 2000, epsilon 0.16803046108205794 total_time 723.0 step_num 118\n",
      "episode 2549, reward 223.0, memory_length 2000, epsilon 0.16791288091715942 total_time 724.0 step_num 120\n",
      "episode 2550, reward 277.0, memory_length 2000, epsilon 0.16779538302957592 total_time 724.0 step_num 119\n",
      "episode 2551, reward 185.0, memory_length 2000, epsilon 0.16767796736173338 total_time 728.0 step_num 110\n",
      "episode 2552, reward 256.0, memory_length 2000, epsilon 0.1675606338560983 total_time 721.0 step_num 107\n",
      "episode 2553, reward 58.0, memory_length 2000, epsilon 0.1674433824551771 total_time 721.0 step_num 111\n",
      "episode 2554, reward -10.0, memory_length 2000, epsilon 0.16732621310151666 total_time 722.0 step_num 120\n",
      "episode 2555, reward 306.0, memory_length 2000, epsilon 0.16720912573770402 total_time 729.0 step_num 112\n",
      "episode 2556, reward 269.0, memory_length 2000, epsilon 0.16709212030636633 total_time 722.0 step_num 105\n",
      "episode 2557, reward 232.0, memory_length 2000, epsilon 0.16697519675017092 total_time 724.0 step_num 119\n",
      "episode 2558, reward 51.0, memory_length 2000, epsilon 0.16685835501182525 total_time 726.0 step_num 99\n",
      "episode 2559, reward 451.0, memory_length 2000, epsilon 0.16674159503407687 total_time 736.0 step_num 121\n",
      "episode 2560, reward 219.0, memory_length 2000, epsilon 0.1666249167597134 total_time 723.0 step_num 115\n",
      "episode 2561, reward 424.0, memory_length 2000, epsilon 0.1665083201315625 total_time 727.0 step_num 110\n",
      "episode 2562, reward 260.0, memory_length 2000, epsilon 0.1663918050924918 total_time 722.0 step_num 112\n",
      "episode 2563, reward 287.0, memory_length 2000, epsilon 0.16627537158540887 total_time 722.0 step_num 113\n",
      "episode 2564, reward 195.0, memory_length 2000, epsilon 0.1661590195532614 total_time 726.0 step_num 120\n",
      "episode 2565, reward 530.0, memory_length 2000, epsilon 0.1660427489390368 total_time 722.0 step_num 121\n",
      "episode 2566, reward 573.0, memory_length 2000, epsilon 0.1659265596857625 total_time 726.0 step_num 119\n",
      "episode 2567, reward 308.0, memory_length 2000, epsilon 0.1658104517365058 total_time 725.0 step_num 112\n",
      "episode 2568, reward 256.0, memory_length 2000, epsilon 0.16569442503437373 total_time 721.0 step_num 113\n",
      "episode 2569, reward 340.0, memory_length 2000, epsilon 0.16557847952251328 total_time 724.0 step_num 109\n",
      "episode 2570, reward 214.0, memory_length 2000, epsilon 0.1654626151441111 total_time 724.0 step_num 112\n",
      "episode 2571, reward -149.0, memory_length 2000, epsilon 0.16534683184239363 total_time 721.0 step_num 104\n",
      "episode 2572, reward 93.0, memory_length 2000, epsilon 0.16523112956062708 total_time 723.0 step_num 124\n",
      "episode 2573, reward 300.0, memory_length 2000, epsilon 0.16511550824211735 total_time 723.0 step_num 111\n",
      "episode 2574, reward 76.0, memory_length 2000, epsilon 0.16499996783020987 total_time 730.0 step_num 111\n",
      "episode 2575, reward 247.0, memory_length 2000, epsilon 0.16488450826829004 total_time 721.0 step_num 126\n",
      "episode 2576, reward 588.0, memory_length 2000, epsilon 0.16476912949978254 total_time 723.0 step_num 118\n",
      "episode 2577, reward 337.0, memory_length 2000, epsilon 0.1646538314681517 total_time 721.0 step_num 106\n",
      "episode 2578, reward 177.0, memory_length 2000, epsilon 0.16453861411690168 total_time 726.0 step_num 123\n",
      "episode 2579, reward -13.0, memory_length 2000, epsilon 0.16442347738957583 total_time 728.0 step_num 114\n",
      "episode 2580, reward 256.0, memory_length 2000, epsilon 0.16430842122975717 total_time 721.0 step_num 110\n",
      "episode 2581, reward 497.0, memory_length 2000, epsilon 0.16419344558106821 total_time 725.0 step_num 113\n",
      "episode 2582, reward 22.0, memory_length 2000, epsilon 0.1640785503871709 total_time 721.0 step_num 108\n",
      "episode 2583, reward 103.0, memory_length 2000, epsilon 0.16396373559176655 total_time 721.0 step_num 109\n",
      "episode 2584, reward 391.0, memory_length 2000, epsilon 0.1638490011385959 total_time 721.0 step_num 118\n",
      "episode 2585, reward 265.0, memory_length 2000, epsilon 0.16373434697143913 total_time 721.0 step_num 113\n",
      "episode 2586, reward 341.0, memory_length 2000, epsilon 0.1636197730341156 total_time 722.0 step_num 112\n",
      "episode 2587, reward 465.0, memory_length 2000, epsilon 0.16350527927048417 total_time 726.0 step_num 112\n",
      "episode 2588, reward 259.0, memory_length 2000, epsilon 0.16339086562444283 total_time 724.0 step_num 114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2589, reward 383.0, memory_length 2000, epsilon 0.1632765320399289 total_time 728.0 step_num 119\n",
      "episode 2590, reward 645.0, memory_length 2000, epsilon 0.16316227846091896 total_time 726.0 step_num 122\n",
      "episode 2591, reward 334.0, memory_length 2000, epsilon 0.16304810483142873 total_time 727.0 step_num 113\n",
      "episode 2592, reward 546.0, memory_length 2000, epsilon 0.16293401109551311 total_time 726.0 step_num 111\n",
      "episode 2593, reward 452.0, memory_length 2000, epsilon 0.16281999719726623 total_time 734.0 step_num 112\n",
      "episode 2594, reward -69.0, memory_length 2000, epsilon 0.1627060630808212 total_time 723.0 step_num 116\n",
      "episode 2595, reward 172.0, memory_length 2000, epsilon 0.16259220869035035 total_time 727.0 step_num 111\n",
      "episode 2596, reward 260.0, memory_length 2000, epsilon 0.162478433970065 total_time 722.0 step_num 110\n",
      "episode 2597, reward 376.0, memory_length 2000, epsilon 0.16236473886421554 total_time 724.0 step_num 119\n",
      "episode 2598, reward 362.0, memory_length 2000, epsilon 0.16225112331709138 total_time 725.0 step_num 128\n",
      "episode 2599, reward 494.0, memory_length 2000, epsilon 0.1621375872730209 total_time 722.0 step_num 114\n",
      "episode 2600, reward 269.0, memory_length 2000, epsilon 0.16202413067637142 total_time 722.0 step_num 104\n",
      "episode 2601, reward 359.0, memory_length 2000, epsilon 0.16191075347154923 total_time 722.0 step_num 121\n",
      "episode 2602, reward 166.0, memory_length 2000, epsilon 0.1617974556029995 total_time 721.0 step_num 107\n",
      "episode 2603, reward 283.0, memory_length 2000, epsilon 0.16168423701520618 total_time 721.0 step_num 115\n",
      "episode 2604, reward 678.0, memory_length 2000, epsilon 0.16157109765269229 total_time 723.0 step_num 113\n",
      "episode 2605, reward 177.0, memory_length 2000, epsilon 0.16145803746001947 total_time 726.0 step_num 116\n",
      "episode 2606, reward 197.0, memory_length 2000, epsilon 0.16134505638178823 total_time 722.0 step_num 120\n",
      "episode 2607, reward 346.0, memory_length 2000, epsilon 0.16123215436263785 total_time 721.0 step_num 118\n",
      "episode 2608, reward 130.0, memory_length 2000, epsilon 0.16111933134724632 total_time 721.0 step_num 103\n",
      "episode 2609, reward 345.0, memory_length 2000, epsilon 0.16100658728033038 total_time 723.0 step_num 112\n",
      "episode 2610, reward 427.0, memory_length 2000, epsilon 0.16089392210664544 total_time 730.0 step_num 118\n",
      "episode 2611, reward 265.0, memory_length 2000, epsilon 0.16078133577098555 total_time 721.0 step_num 117\n",
      "episode 2612, reward 607.0, memory_length 2000, epsilon 0.1606688282181834 total_time 721.0 step_num 116\n",
      "episode 2613, reward 565.0, memory_length 2000, epsilon 0.16055639939311028 total_time 724.0 step_num 117\n",
      "episode 2614, reward 131.0, memory_length 2000, epsilon 0.1604440492406761 total_time 728.0 step_num 112\n",
      "episode 2615, reward 300.0, memory_length 2000, epsilon 0.16033177770582924 total_time 723.0 step_num 105\n",
      "episode 2616, reward 12.0, memory_length 2000, epsilon 0.16021958473355666 total_time 723.0 step_num 101\n",
      "episode 2617, reward 673.0, memory_length 2000, epsilon 0.16010747026888378 total_time 724.0 step_num 109\n",
      "episode 2618, reward 376.0, memory_length 2000, epsilon 0.1599954342568746 total_time 724.0 step_num 125\n",
      "episode 2619, reward 185.0, memory_length 2000, epsilon 0.1598834766426314 total_time 728.0 step_num 109\n",
      "episode 2620, reward 118.0, memory_length 2000, epsilon 0.1597715973712949 total_time 727.0 step_num 110\n",
      "episode 2621, reward 337.0, memory_length 2000, epsilon 0.15965979638804434 total_time 721.0 step_num 106\n",
      "episode 2622, reward -44.0, memory_length 2000, epsilon 0.1595480736380972 total_time 727.0 step_num 108\n",
      "episode 2623, reward 325.0, memory_length 2000, epsilon 0.15943642906670935 total_time 727.0 step_num 119\n",
      "episode 2624, reward 386.0, memory_length 2000, epsilon 0.1593248626191749 total_time 722.0 step_num 108\n",
      "episode 2625, reward 312.0, memory_length 2000, epsilon 0.15921337424082638 total_time 726.0 step_num 104\n",
      "episode 2626, reward 260.0, memory_length 2000, epsilon 0.15910196387703435 total_time 722.0 step_num 109\n",
      "episode 2627, reward 130.0, memory_length 2000, epsilon 0.15899063147320786 total_time 721.0 step_num 127\n",
      "episode 2628, reward 125.0, memory_length 2000, epsilon 0.15887937697479396 total_time 722.0 step_num 110\n",
      "episode 2629, reward 643.0, memory_length 2000, epsilon 0.1587682003272779 total_time 721.0 step_num 117\n",
      "episode 2630, reward 71.0, memory_length 2000, epsilon 0.15865710147618325 total_time 722.0 step_num 129\n",
      "episode 2631, reward 350.0, memory_length 2000, epsilon 0.1585460803670715 total_time 722.0 step_num 110\n",
      "episode 2632, reward 433.0, memory_length 2000, epsilon 0.15843513694554223 total_time 727.0 step_num 110\n",
      "episode 2633, reward 177.0, memory_length 2000, epsilon 0.1583242711572333 total_time 726.0 step_num 90\n",
      "episode 2634, reward 213.0, memory_length 2000, epsilon 0.15821348294782042 total_time 726.0 step_num 113\n",
      "episode 2635, reward 484.0, memory_length 2000, epsilon 0.15810277226301725 total_time 724.0 step_num 116\n",
      "episode 2636, reward -3.0, memory_length 2000, epsilon 0.15799213904857573 total_time 735.0 step_num 115\n",
      "episode 2637, reward 463.0, memory_length 2000, epsilon 0.15788158325028553 total_time 721.0 step_num 122\n",
      "episode 2638, reward 490.0, memory_length 2000, epsilon 0.1577711048139742 total_time 721.0 step_num 116\n",
      "episode 2639, reward 338.0, memory_length 2000, epsilon 0.15766070368550747 total_time 728.0 step_num 118\n",
      "episode 2640, reward 469.0, memory_length 2000, epsilon 0.15755037981078862 total_time 727.0 step_num 111\n",
      "episode 2641, reward 377.0, memory_length 2000, epsilon 0.15744013313575908 total_time 722.0 step_num 119\n",
      "episode 2642, reward 553.0, memory_length 2000, epsilon 0.15732996360639792 total_time 721.0 step_num 106\n",
      "episode 2643, reward 202.0, memory_length 2000, epsilon 0.15721987116872202 total_time 721.0 step_num 115\n",
      "episode 2644, reward 573.0, memory_length 2000, epsilon 0.15710985576878622 total_time 726.0 step_num 113\n",
      "episode 2645, reward 93.0, memory_length 2000, epsilon 0.15699991735268287 total_time 723.0 step_num 116\n",
      "episode 2646, reward 168.0, memory_length 2000, epsilon 0.15689005586654214 total_time 726.0 step_num 117\n",
      "episode 2647, reward 425.0, memory_length 2000, epsilon 0.15678027125653193 total_time 725.0 step_num 132\n",
      "episode 2648, reward 201.0, memory_length 2000, epsilon 0.1566705634688578 total_time 723.0 step_num 122\n",
      "episode 2649, reward -109.0, memory_length 2000, epsilon 0.15656093244976285 total_time 722.0 step_num 119\n",
      "episode 2650, reward 431.0, memory_length 2000, epsilon 0.156451378145528 total_time 722.0 step_num 107\n",
      "episode 2651, reward 220.0, memory_length 2000, epsilon 0.15634190050247154 total_time 721.0 step_num 113\n",
      "episode 2652, reward 483.0, memory_length 2000, epsilon 0.15623249946694942 total_time 726.0 step_num 111\n",
      "episode 2653, reward 563.0, memory_length 2000, epsilon 0.15612317498535522 total_time 728.0 step_num 128\n",
      "episode 2654, reward 193.0, memory_length 2000, epsilon 0.15601392700411987 total_time 721.0 step_num 120\n",
      "episode 2655, reward 472.0, memory_length 2000, epsilon 0.15590475546971183 total_time 730.0 step_num 111\n",
      "episode 2656, reward 289.0, memory_length 2000, epsilon 0.15579566032863715 total_time 727.0 step_num 119\n",
      "episode 2657, reward 397.0, memory_length 2000, epsilon 0.15568664152743913 total_time 727.0 step_num 106\n",
      "episode 2658, reward 138.0, memory_length 2000, epsilon 0.15557769901269855 total_time 723.0 step_num 110\n",
      "episode 2659, reward 408.0, memory_length 2000, epsilon 0.15546883273103365 total_time 723.0 step_num 114\n",
      "episode 2660, reward 330.0, memory_length 2000, epsilon 0.15536004262909986 total_time 726.0 step_num 112\n",
      "episode 2661, reward 301.0, memory_length 2000, epsilon 0.15525132865359004 total_time 721.0 step_num 131\n",
      "episode 2662, reward 609.0, memory_length 2000, epsilon 0.15514269075123444 total_time 726.0 step_num 110\n",
      "episode 2663, reward -5.0, memory_length 2000, epsilon 0.15503412886880033 total_time 721.0 step_num 108\n",
      "episode 2664, reward 229.0, memory_length 2000, epsilon 0.15492564295309252 total_time 730.0 step_num 115\n",
      "episode 2665, reward 499.0, memory_length 2000, epsilon 0.15481723295095287 total_time 721.0 step_num 114\n",
      "episode 2666, reward 344.0, memory_length 2000, epsilon 0.15470889880926042 total_time 725.0 step_num 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2667, reward 62.0, memory_length 2000, epsilon 0.1546006404749315 total_time 722.0 step_num 104\n",
      "episode 2668, reward -16.0, memory_length 2000, epsilon 0.1544924578949195 total_time 734.0 step_num 111\n",
      "episode 2669, reward 417.0, memory_length 2000, epsilon 0.15438435101621498 total_time 723.0 step_num 110\n",
      "episode 2670, reward 264.0, memory_length 2000, epsilon 0.15427631978584552 total_time 723.0 step_num 118\n",
      "episode 2671, reward 156.0, memory_length 2000, epsilon 0.15416836415087587 total_time 723.0 step_num 126\n",
      "episode 2672, reward 520.0, memory_length 2000, epsilon 0.1540604840584077 total_time 724.0 step_num 121\n",
      "episode 2673, reward 165.0, memory_length 2000, epsilon 0.15395267945557983 total_time 723.0 step_num 112\n",
      "episode 2674, reward 521.0, memory_length 2000, epsilon 0.153844950289568 total_time 722.0 step_num 107\n",
      "episode 2675, reward 400.0, memory_length 2000, epsilon 0.15373729650758486 total_time 721.0 step_num 123\n",
      "episode 2676, reward 255.0, memory_length 2000, epsilon 0.15362971805688008 total_time 723.0 step_num 105\n",
      "episode 2677, reward 449.0, memory_length 2000, epsilon 0.15352221488474024 total_time 722.0 step_num 118\n",
      "episode 2678, reward 58.0, memory_length 2000, epsilon 0.15341478693848873 total_time 721.0 step_num 107\n",
      "episode 2679, reward 32.0, memory_length 2000, epsilon 0.1533074341654859 total_time 728.0 step_num 122\n",
      "episode 2680, reward 121.0, memory_length 2000, epsilon 0.1532001565131289 total_time 721.0 step_num 122\n",
      "episode 2681, reward 307.0, memory_length 2000, epsilon 0.15309295392885164 total_time 727.0 step_num 108\n",
      "episode 2682, reward 499.0, memory_length 2000, epsilon 0.15298582636012487 total_time 730.0 step_num 115\n",
      "episode 2683, reward 179.0, memory_length 2000, epsilon 0.1528787737544561 total_time 722.0 step_num 118\n",
      "episode 2684, reward 308.0, memory_length 2000, epsilon 0.15277179605938948 total_time 725.0 step_num 111\n",
      "episode 2685, reward 389.0, memory_length 2000, epsilon 0.15266489322250604 total_time 725.0 step_num 117\n",
      "episode 2686, reward 310.0, memory_length 2000, epsilon 0.15255806519142334 total_time 721.0 step_num 117\n",
      "episode 2687, reward 157.0, memory_length 2000, epsilon 0.15245131191379557 total_time 721.0 step_num 122\n",
      "episode 2688, reward 672.0, memory_length 2000, epsilon 0.15234463333731374 total_time 726.0 step_num 110\n",
      "episode 2689, reward 172.0, memory_length 2000, epsilon 0.15223802940970524 total_time 727.0 step_num 115\n",
      "episode 2690, reward -178.0, memory_length 2000, epsilon 0.15213150007873424 total_time 734.0 step_num 114\n",
      "episode 2691, reward 292.0, memory_length 2000, epsilon 0.15202504529220134 total_time 721.0 step_num 110\n",
      "episode 2692, reward 472.0, memory_length 2000, epsilon 0.15191866499794363 total_time 730.0 step_num 108\n",
      "episode 2693, reward 400.0, memory_length 2000, epsilon 0.1518123591438348 total_time 721.0 step_num 107\n",
      "episode 2694, reward 264.0, memory_length 2000, epsilon 0.15170612767778505 total_time 723.0 step_num 103\n",
      "episode 2695, reward 379.0, memory_length 2000, epsilon 0.15159997054774085 total_time 727.0 step_num 107\n",
      "episode 2696, reward 250.0, memory_length 2000, epsilon 0.1514938877016853 total_time 724.0 step_num 112\n",
      "episode 2697, reward 316.0, memory_length 2000, epsilon 0.15138787908763773 total_time 727.0 step_num 105\n",
      "episode 2698, reward 429.0, memory_length 2000, epsilon 0.1512819446536539 total_time 726.0 step_num 116\n",
      "episode 2699, reward 317.0, memory_length 2000, epsilon 0.15117608434782603 total_time 725.0 step_num 108\n",
      "episode 2700, reward 193.0, memory_length 2000, epsilon 0.15107029811828251 total_time 730.0 step_num 131\n",
      "episode 2701, reward 373.0, memory_length 2000, epsilon 0.15096458591318804 total_time 721.0 step_num 111\n",
      "episode 2702, reward 764.0, memory_length 2000, epsilon 0.15085894768074373 total_time 722.0 step_num 112\n",
      "episode 2703, reward 200.0, memory_length 2000, epsilon 0.1507533833691868 total_time 725.0 step_num 113\n",
      "episode 2704, reward 204.0, memory_length 2000, epsilon 0.15064789292679073 total_time 726.0 step_num 118\n",
      "episode 2705, reward 553.0, memory_length 2000, epsilon 0.15054247630186524 total_time 721.0 step_num 110\n",
      "episode 2706, reward 574.0, memory_length 2000, epsilon 0.15043713344275614 total_time 724.0 step_num 107\n",
      "episode 2707, reward -37.0, memory_length 2000, epsilon 0.1503318642978454 total_time 722.0 step_num 118\n",
      "episode 2708, reward 624.0, memory_length 2000, epsilon 0.1502266688155512 total_time 723.0 step_num 112\n",
      "episode 2709, reward 157.0, memory_length 2000, epsilon 0.15012154694432772 total_time 721.0 step_num 106\n",
      "episode 2710, reward 140.0, memory_length 2000, epsilon 0.15001649863266522 total_time 728.0 step_num 98\n",
      "episode 2711, reward 440.0, memory_length 2000, epsilon 0.1499115238290901 total_time 722.0 step_num 115\n",
      "episode 2712, reward 137.0, memory_length 2000, epsilon 0.14980662248216461 total_time 725.0 step_num 114\n",
      "episode 2713, reward 348.0, memory_length 2000, epsilon 0.14970179454048718 total_time 726.0 step_num 107\n",
      "episode 2714, reward 321.0, memory_length 2000, epsilon 0.14959703995269205 total_time 726.0 step_num 98\n",
      "episode 2715, reward 582.0, memory_length 2000, epsilon 0.14949235866744945 total_time 726.0 step_num 113\n",
      "episode 2716, reward 186.0, memory_length 2000, epsilon 0.14938775063346563 total_time 726.0 step_num 107\n",
      "episode 2717, reward 26.0, memory_length 2000, epsilon 0.14928321579948264 total_time 722.0 step_num 111\n",
      "episode 2718, reward 290.0, memory_length 2000, epsilon 0.1491787541142783 total_time 725.0 step_num 130\n",
      "episode 2719, reward 413.0, memory_length 2000, epsilon 0.14907436552666653 total_time 722.0 step_num 108\n",
      "episode 2720, reward 260.0, memory_length 2000, epsilon 0.14897004998549682 total_time 722.0 step_num 106\n",
      "episode 2721, reward 346.0, memory_length 2000, epsilon 0.14886580743965455 total_time 721.0 step_num 110\n",
      "episode 2722, reward -41.0, memory_length 2000, epsilon 0.14876163783806098 total_time 721.0 step_num 116\n",
      "episode 2723, reward 383.0, memory_length 2000, epsilon 0.1486575411296729 total_time 728.0 step_num 113\n",
      "episode 2724, reward 493.0, memory_length 2000, epsilon 0.1485535172634829 total_time 724.0 step_num 107\n",
      "episode 2725, reward 235.0, memory_length 2000, epsilon 0.14844956618851937 total_time 736.0 step_num 117\n",
      "episode 2726, reward 383.0, memory_length 2000, epsilon 0.14834568785384628 total_time 728.0 step_num 116\n",
      "episode 2727, reward 266.0, memory_length 2000, epsilon 0.14824188220856313 total_time 728.0 step_num 115\n",
      "episode 2728, reward 296.0, memory_length 2000, epsilon 0.14813814920180526 total_time 722.0 step_num 115\n",
      "episode 2729, reward 125.0, memory_length 2000, epsilon 0.1480344887827435 total_time 722.0 step_num 120\n",
      "episode 2730, reward 545.0, memory_length 2000, epsilon 0.14793090090058417 total_time 728.0 step_num 101\n",
      "episode 2731, reward 214.0, memory_length 2000, epsilon 0.14782738550456925 total_time 724.0 step_num 111\n",
      "episode 2732, reward 294.0, memory_length 2000, epsilon 0.1477239425439762 total_time 726.0 step_num 105\n",
      "episode 2733, reward 272.0, memory_length 2000, epsilon 0.1476205719681179 total_time 725.0 step_num 127\n",
      "episode 2734, reward 282.0, memory_length 2000, epsilon 0.14751727372634285 total_time 723.0 step_num 122\n",
      "episode 2735, reward 326.0, memory_length 2000, epsilon 0.14741404776803485 total_time 725.0 step_num 122\n",
      "episode 2736, reward 204.0, memory_length 2000, epsilon 0.14731089404261324 total_time 726.0 step_num 115\n",
      "episode 2737, reward 206.0, memory_length 2000, epsilon 0.14720781249953266 total_time 722.0 step_num 112\n",
      "episode 2738, reward 132.0, memory_length 2000, epsilon 0.14710480308828314 total_time 726.0 step_num 106\n",
      "episode 2739, reward 238.0, memory_length 2000, epsilon 0.14700186575839008 total_time 721.0 step_num 112\n",
      "episode 2740, reward 296.0, memory_length 2000, epsilon 0.1468990004594142 total_time 722.0 step_num 111\n",
      "episode 2741, reward 402.0, memory_length 2000, epsilon 0.14679620714095146 total_time 735.0 step_num 117\n",
      "episode 2742, reward 35.0, memory_length 2000, epsilon 0.14669348575263316 total_time 722.0 step_num 118\n",
      "episode 2743, reward 210.0, memory_length 2000, epsilon 0.14659083624412583 total_time 723.0 step_num 124\n",
      "episode 2744, reward 78.0, memory_length 2000, epsilon 0.14648825856513115 total_time 726.0 step_num 113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2745, reward 175.0, memory_length 2000, epsilon 0.14638575266538614 total_time 721.0 step_num 106\n",
      "episode 2746, reward 282.0, memory_length 2000, epsilon 0.14628331849466286 total_time 723.0 step_num 112\n",
      "episode 2747, reward 310.0, memory_length 2000, epsilon 0.14618095600276854 total_time 721.0 step_num 109\n",
      "episode 2748, reward 751.0, memory_length 2000, epsilon 0.14607866513954562 total_time 721.0 step_num 116\n",
      "episode 2749, reward 400.0, memory_length 2000, epsilon 0.14597644585487154 total_time 721.0 step_num 135\n",
      "episode 2750, reward 530.0, memory_length 2000, epsilon 0.14587429809865882 total_time 722.0 step_num 113\n",
      "episode 2751, reward 175.0, memory_length 2000, epsilon 0.1457722218208551 total_time 721.0 step_num 111\n",
      "episode 2752, reward 560.0, memory_length 2000, epsilon 0.14567021697144303 total_time 725.0 step_num 119\n",
      "episode 2753, reward 323.0, memory_length 2000, epsilon 0.14556828350044013 total_time 722.0 step_num 115\n",
      "episode 2754, reward 289.0, memory_length 2000, epsilon 0.14546642135789908 total_time 727.0 step_num 108\n",
      "episode 2755, reward 265.0, memory_length 2000, epsilon 0.14536463049390744 total_time 721.0 step_num 115\n",
      "episode 2756, reward 557.0, memory_length 2000, epsilon 0.14526291085858759 total_time 722.0 step_num 128\n",
      "episode 2757, reward 210.0, memory_length 2000, epsilon 0.14516126240209698 total_time 723.0 step_num 112\n",
      "episode 2758, reward 229.0, memory_length 2000, epsilon 0.1450596850746279 total_time 721.0 step_num 107\n",
      "episode 2759, reward 183.0, memory_length 2000, epsilon 0.14495817882640735 total_time 723.0 step_num 122\n",
      "episode 2760, reward 135.0, memory_length 2000, epsilon 0.14485674360769737 total_time 729.0 step_num 118\n",
      "episode 2761, reward 449.0, memory_length 2000, epsilon 0.14475537936879462 total_time 722.0 step_num 109\n",
      "episode 2762, reward 272.0, memory_length 2000, epsilon 0.1446540860600307 total_time 725.0 step_num 105\n",
      "episode 2763, reward 377.0, memory_length 2000, epsilon 0.1445528636317718 total_time 722.0 step_num 116\n",
      "episode 2764, reward 339.0, memory_length 2000, epsilon 0.14445171203441898 total_time 726.0 step_num 102\n",
      "episode 2765, reward 434.0, memory_length 2000, epsilon 0.14435063121840797 total_time 734.0 step_num 106\n",
      "episode 2766, reward 139.0, memory_length 2000, epsilon 0.14424962113420914 total_time 721.0 step_num 106\n",
      "episode 2767, reward 359.0, memory_length 2000, epsilon 0.14414868173232753 total_time 722.0 step_num 113\n",
      "episode 2768, reward 472.0, memory_length 2000, epsilon 0.14404781296330285 total_time 721.0 step_num 122\n",
      "episode 2769, reward 364.0, memory_length 2000, epsilon 0.14394701477770944 total_time 721.0 step_num 117\n",
      "episode 2770, reward 331.0, memory_length 2000, epsilon 0.14384628712615613 total_time 724.0 step_num 115\n",
      "episode 2771, reward 245.0, memory_length 2000, epsilon 0.1437456299592864 total_time 725.0 step_num 108\n",
      "episode 2772, reward 242.0, memory_length 2000, epsilon 0.14364504322777824 total_time 722.0 step_num 114\n",
      "episode 2773, reward 431.0, memory_length 2000, epsilon 0.14354452688234406 total_time 722.0 step_num 125\n",
      "episode 2774, reward 202.0, memory_length 2000, epsilon 0.14344408087373103 total_time 721.0 step_num 109\n",
      "episode 2775, reward 418.0, memory_length 2000, epsilon 0.14334370515272044 total_time 730.0 step_num 116\n",
      "episode 2776, reward 481.0, memory_length 2000, epsilon 0.14324339967012822 total_time 721.0 step_num 115\n",
      "episode 2777, reward 273.0, memory_length 2000, epsilon 0.14314316437680477 total_time 723.0 step_num 111\n",
      "episode 2778, reward 607.0, memory_length 2000, epsilon 0.14304299922363467 total_time 721.0 step_num 117\n",
      "episode 2779, reward 335.0, memory_length 2000, epsilon 0.14294290416153707 total_time 725.0 step_num 117\n",
      "episode 2780, reward 101.0, memory_length 2000, epsilon 0.14284287914146537 total_time 725.0 step_num 101\n",
      "episode 2781, reward 589.0, memory_length 2000, epsilon 0.14274292411440734 total_time 721.0 step_num 115\n",
      "episode 2782, reward 44.0, memory_length 2000, epsilon 0.14264303903138492 total_time 722.0 step_num 106\n",
      "episode 2783, reward 65.0, memory_length 2000, epsilon 0.14254322384345453 total_time 734.0 step_num 123\n",
      "episode 2784, reward 584.0, memory_length 2000, epsilon 0.14244347850170663 total_time 722.0 step_num 113\n",
      "episode 2785, reward 395.0, memory_length 2000, epsilon 0.1423438029572661 total_time 722.0 step_num 114\n",
      "episode 2786, reward 337.0, memory_length 2000, epsilon 0.14224419716129186 total_time 721.0 step_num 114\n",
      "episode 2787, reward 292.0, memory_length 2000, epsilon 0.14214466106497703 total_time 730.0 step_num 128\n",
      "episode 2788, reward 354.0, memory_length 2000, epsilon 0.142045194619549 total_time 723.0 step_num 100\n",
      "episode 2789, reward 142.0, memory_length 2000, epsilon 0.1419457977762692 total_time 724.0 step_num 110\n",
      "episode 2790, reward 372.0, memory_length 2000, epsilon 0.14184647048643306 total_time 723.0 step_num 120\n",
      "episode 2791, reward 264.0, memory_length 2000, epsilon 0.1417472127013704 total_time 732.0 step_num 119\n",
      "episode 2792, reward 25.0, memory_length 2000, epsilon 0.14164802437244475 total_time 724.0 step_num 113\n",
      "episode 2793, reward 352.0, memory_length 2000, epsilon 0.14154890545105386 total_time 727.0 step_num 119\n",
      "episode 2794, reward 273.0, memory_length 2000, epsilon 0.14144985588862952 total_time 723.0 step_num 111\n",
      "episode 2795, reward 161.0, memory_length 2000, epsilon 0.14135087563663737 total_time 722.0 step_num 123\n",
      "episode 2796, reward 256.0, memory_length 2000, epsilon 0.14125196464657708 total_time 721.0 step_num 111\n",
      "episode 2797, reward 437.0, memory_length 2000, epsilon 0.14115312286998236 total_time 728.0 step_num 106\n",
      "episode 2798, reward 337.0, memory_length 2000, epsilon 0.1410543502584206 total_time 721.0 step_num 115\n",
      "episode 2799, reward 318.0, memory_length 2000, epsilon 0.14095564676349334 total_time 723.0 step_num 117\n",
      "episode 2800, reward 272.0, memory_length 2000, epsilon 0.14085701233683579 total_time 725.0 step_num 107\n",
      "episode 2801, reward 119.0, memory_length 2000, epsilon 0.14075844693011713 total_time 725.0 step_num 99\n",
      "episode 2802, reward 427.0, memory_length 2000, epsilon 0.14065995049504024 total_time 721.0 step_num 108\n",
      "episode 2803, reward 247.0, memory_length 2000, epsilon 0.14056152298334193 total_time 730.0 step_num 117\n",
      "episode 2804, reward 260.0, memory_length 2000, epsilon 0.1404631643467927 total_time 722.0 step_num 115\n",
      "episode 2805, reward 199.0, memory_length 2000, epsilon 0.1403648745371968 total_time 727.0 step_num 118\n",
      "episode 2806, reward 438.0, memory_length 2000, epsilon 0.14026665350639225 total_time 726.0 step_num 110\n",
      "episode 2807, reward 299.0, memory_length 2000, epsilon 0.14016850120625068 total_time 734.0 step_num 134\n",
      "episode 2808, reward 206.0, memory_length 2000, epsilon 0.14007041758867755 total_time 722.0 step_num 112\n",
      "episode 2809, reward 34.0, memory_length 2000, epsilon 0.13997240260561183 total_time 724.0 step_num 114\n",
      "episode 2810, reward 537.0, memory_length 2000, epsilon 0.13987445620902617 total_time 726.0 step_num 126\n",
      "episode 2811, reward 391.0, memory_length 2000, epsilon 0.13977657835092688 total_time 730.0 step_num 118\n",
      "episode 2812, reward 92.0, memory_length 2000, epsilon 0.1396787689833538 total_time 725.0 step_num 111\n",
      "episode 2813, reward 368.0, memory_length 2000, epsilon 0.1395810280583802 total_time 722.0 step_num 103\n",
      "episode 2814, reward 512.0, memory_length 2000, epsilon 0.13948335552811328 total_time 722.0 step_num 111\n",
      "episode 2815, reward 339.0, memory_length 2000, epsilon 0.1393857513446933 total_time 726.0 step_num 113\n",
      "episode 2816, reward 214.0, memory_length 2000, epsilon 0.13928821546029424 total_time 724.0 step_num 104\n",
      "episode 2817, reward 213.0, memory_length 2000, epsilon 0.1391907478271236 total_time 726.0 step_num 112\n",
      "episode 2818, reward 589.0, memory_length 2000, epsilon 0.13909334839742216 total_time 721.0 step_num 118\n",
      "episode 2819, reward 344.0, memory_length 2000, epsilon 0.13899601712346418 total_time 725.0 step_num 97\n",
      "episode 2820, reward 340.0, memory_length 2000, epsilon 0.1388987539575574 total_time 724.0 step_num 120\n",
      "episode 2821, reward -14.0, memory_length 2000, epsilon 0.13880155885204287 total_time 721.0 step_num 105\n",
      "episode 2822, reward 144.0, memory_length 2000, epsilon 0.1387044317592949 total_time 729.0 step_num 118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2823, reward 454.0, memory_length 2000, epsilon 0.13860737263172132 total_time 721.0 step_num 117\n",
      "episode 2824, reward 211.0, memory_length 2000, epsilon 0.13851038142176306 total_time 721.0 step_num 109\n",
      "episode 2825, reward 518.0, memory_length 2000, epsilon 0.13841345808189448 total_time 737.0 step_num 109\n",
      "episode 2826, reward 398.0, memory_length 2000, epsilon 0.13831660256462316 total_time 725.0 step_num 110\n",
      "episode 2827, reward 346.0, memory_length 2000, epsilon 0.13821981482248982 total_time 721.0 step_num 112\n",
      "episode 2828, reward 581.0, memory_length 2000, epsilon 0.13812309480806853 total_time 728.0 step_num 112\n",
      "episode 2829, reward 151.0, memory_length 2000, epsilon 0.13802644247396645 total_time 724.0 step_num 118\n",
      "episode 2830, reward 306.0, memory_length 2000, epsilon 0.13792985777282396 total_time 729.0 step_num 114\n",
      "episode 2831, reward 362.0, memory_length 2000, epsilon 0.13783334065731448 total_time 725.0 step_num 109\n",
      "episode 2832, reward 391.0, memory_length 2000, epsilon 0.13773689108014475 total_time 721.0 step_num 116\n",
      "episode 2833, reward 211.0, memory_length 2000, epsilon 0.1376405089940544 total_time 721.0 step_num 118\n",
      "episode 2834, reward 409.0, memory_length 2000, epsilon 0.1375441943518162 total_time 721.0 step_num 112\n",
      "episode 2835, reward 571.0, memory_length 2000, epsilon 0.13744794710623595 total_time 721.0 step_num 117\n",
      "episode 2836, reward 218.0, memory_length 2000, epsilon 0.13735176721015255 total_time 725.0 step_num 115\n",
      "episode 2837, reward 418.0, memory_length 2000, epsilon 0.13725565461643785 total_time 721.0 step_num 122\n",
      "episode 2838, reward 206.0, memory_length 2000, epsilon 0.13715960927799667 total_time 722.0 step_num 115\n",
      "episode 2839, reward 481.0, memory_length 2000, epsilon 0.13706363114776673 total_time 721.0 step_num 117\n",
      "episode 2840, reward 89.0, memory_length 2000, epsilon 0.13696772017871883 total_time 722.0 step_num 111\n",
      "episode 2841, reward 431.0, memory_length 2000, epsilon 0.13687187632385658 total_time 722.0 step_num 111\n",
      "episode 2842, reward 480.0, memory_length 2000, epsilon 0.13677609953621642 total_time 723.0 step_num 101\n",
      "episode 2843, reward 157.0, memory_length 2000, epsilon 0.13668038976886782 total_time 721.0 step_num 116\n",
      "episode 2844, reward 454.0, memory_length 2000, epsilon 0.13658474697491288 total_time 721.0 step_num 120\n",
      "episode 2845, reward 67.0, memory_length 2000, epsilon 0.1364891711074867 total_time 721.0 step_num 114\n",
      "episode 2846, reward 397.0, memory_length 2000, epsilon 0.13639366211975712 total_time 727.0 step_num 112\n",
      "episode 2847, reward 364.0, memory_length 2000, epsilon 0.13629821996492475 total_time 721.0 step_num 102\n",
      "episode 2848, reward 278.0, memory_length 2000, epsilon 0.1362028445962228 total_time 722.0 step_num 120\n",
      "episode 2849, reward 58.0, memory_length 2000, epsilon 0.1361075359669175 total_time 721.0 step_num 118\n",
      "episode 2850, reward 287.0, memory_length 2000, epsilon 0.1360122940303075 total_time 722.0 step_num 115\n",
      "episode 2851, reward 259.0, memory_length 2000, epsilon 0.1359171187397243 total_time 724.0 step_num 107\n",
      "episode 2852, reward 365.0, memory_length 2000, epsilon 0.13582201004853206 total_time 728.0 step_num 107\n",
      "episode 2853, reward 286.0, memory_length 2000, epsilon 0.1357269679101274 total_time 724.0 step_num 109\n",
      "episode 2854, reward 26.0, memory_length 2000, epsilon 0.13563199227793973 total_time 722.0 step_num 101\n",
      "episode 2855, reward 268.0, memory_length 2000, epsilon 0.13553708310543103 total_time 724.0 step_num 105\n",
      "episode 2856, reward 221.0, memory_length 2000, epsilon 0.1354422403460957 total_time 728.0 step_num 122\n",
      "episode 2857, reward 506.0, memory_length 2000, epsilon 0.13534746395346092 total_time 725.0 step_num 107\n",
      "episode 2858, reward 305.0, memory_length 2000, epsilon 0.13525275388108618 total_time 722.0 step_num 105\n",
      "episode 2859, reward 379.0, memory_length 2000, epsilon 0.1351581100825635 total_time 727.0 step_num 114\n",
      "episode 2860, reward -82.0, memory_length 2000, epsilon 0.1350635325115175 total_time 722.0 step_num 117\n",
      "episode 2861, reward 354.0, memory_length 2000, epsilon 0.1349690211216051 total_time 723.0 step_num 109\n",
      "episode 2862, reward 348.0, memory_length 2000, epsilon 0.13487457586651577 total_time 726.0 step_num 125\n",
      "episode 2863, reward 418.0, memory_length 2000, epsilon 0.13478019669997138 total_time 721.0 step_num 122\n",
      "episode 2864, reward 629.0, memory_length 2000, epsilon 0.13468588357572597 total_time 722.0 step_num 116\n",
      "episode 2865, reward 431.0, memory_length 2000, epsilon 0.13459163644756622 total_time 722.0 step_num 109\n",
      "episode 2866, reward 265.0, memory_length 2000, epsilon 0.1344974552693111 total_time 721.0 step_num 119\n",
      "episode 2867, reward 395.0, memory_length 2000, epsilon 0.13440333999481166 total_time 722.0 step_num 115\n",
      "episode 2868, reward -37.0, memory_length 2000, epsilon 0.13430929057795152 total_time 722.0 step_num 110\n",
      "episode 2869, reward 409.0, memory_length 2000, epsilon 0.13421530697264644 total_time 721.0 step_num 115\n",
      "episode 2870, reward 426.0, memory_length 2000, epsilon 0.13412138913284455 total_time 723.0 step_num 108\n",
      "episode 2871, reward 265.0, memory_length 2000, epsilon 0.13402753701252595 total_time 721.0 step_num 117\n",
      "episode 2872, reward 658.0, memory_length 2000, epsilon 0.13393375056570317 total_time 727.0 step_num 130\n",
      "episode 2873, reward 53.0, memory_length 2000, epsilon 0.13384002974642087 total_time 722.0 step_num 125\n",
      "episode 2874, reward 404.0, memory_length 2000, epsilon 0.13374637450875582 total_time 722.0 step_num 103\n",
      "episode 2875, reward 26.0, memory_length 2000, epsilon 0.13365278480681692 total_time 722.0 step_num 117\n",
      "episode 2876, reward 256.0, memory_length 2000, epsilon 0.13355926059474532 total_time 721.0 step_num 114\n",
      "episode 2877, reward 315.0, memory_length 2000, epsilon 0.13346580182671403 total_time 729.0 step_num 112\n",
      "episode 2878, reward 408.0, memory_length 2000, epsilon 0.1333724084569283 total_time 723.0 step_num 114\n",
      "episode 2879, reward 355.0, memory_length 2000, epsilon 0.13327908043962544 total_time 721.0 step_num 112\n",
      "episode 2880, reward 292.0, memory_length 2000, epsilon 0.1331858177290746 total_time 721.0 step_num 110\n",
      "episode 2881, reward 373.0, memory_length 2000, epsilon 0.1330926202795771 total_time 721.0 step_num 116\n",
      "episode 2882, reward 121.0, memory_length 2000, epsilon 0.1329994880454663 total_time 721.0 step_num 113\n",
      "episode 2883, reward 574.0, memory_length 2000, epsilon 0.1329064209811072 total_time 724.0 step_num 101\n",
      "episode 2884, reward 317.0, memory_length 2000, epsilon 0.13281341904089705 total_time 725.0 step_num 107\n",
      "episode 2885, reward 208.0, memory_length 2000, epsilon 0.132720482179265 total_time 727.0 step_num 99\n",
      "episode 2886, reward 76.0, memory_length 2000, epsilon 0.13262761035067175 total_time 721.0 step_num 109\n",
      "episode 2887, reward 370.0, memory_length 2000, epsilon 0.13253480350961025 total_time 727.0 step_num 116\n",
      "episode 2888, reward 335.0, memory_length 2000, epsilon 0.13244206161060515 total_time 725.0 step_num 105\n",
      "episode 2889, reward 352.0, memory_length 2000, epsilon 0.13234938460821286 total_time 727.0 step_num 116\n",
      "episode 2890, reward 157.0, memory_length 2000, epsilon 0.1322567724570217 total_time 721.0 step_num 114\n",
      "episode 2891, reward 224.0, memory_length 2000, epsilon 0.13216422511165168 total_time 731.0 step_num 109\n",
      "episode 2892, reward -19.0, memory_length 2000, epsilon 0.1320717425267546 total_time 722.0 step_num 117\n",
      "episode 2893, reward 104.0, memory_length 2000, epsilon 0.131979324657014 total_time 728.0 step_num 107\n",
      "episode 2894, reward 373.0, memory_length 2000, epsilon 0.13188697145714517 total_time 721.0 step_num 107\n",
      "episode 2895, reward 247.0, memory_length 2000, epsilon 0.13179468288189494 total_time 721.0 step_num 118\n",
      "episode 2896, reward 372.0, memory_length 2000, epsilon 0.13170245888604196 total_time 723.0 step_num 108\n",
      "episode 2897, reward 328.0, memory_length 2000, epsilon 0.13161029942439653 total_time 721.0 step_num 125\n",
      "episode 2898, reward 411.0, memory_length 2000, epsilon 0.13151820445180037 total_time 726.0 step_num 106\n",
      "episode 2899, reward 328.0, memory_length 2000, epsilon 0.13142617392312703 total_time 721.0 step_num 114\n",
      "episode 2900, reward 366.0, memory_length 2000, epsilon 0.13133420779328164 total_time 726.0 step_num 108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2901, reward 232.0, memory_length 2000, epsilon 0.13124230601720058 total_time 724.0 step_num 120\n",
      "episode 2902, reward 65.0, memory_length 2000, epsilon 0.13115046854985213 total_time 725.0 step_num 118\n",
      "episode 2903, reward 645.0, memory_length 2000, epsilon 0.13105869534623596 total_time 726.0 step_num 124\n",
      "episode 2904, reward 182.0, memory_length 2000, epsilon 0.13096698636138304 total_time 725.0 step_num 104\n",
      "episode 2905, reward 6.0, memory_length 2000, epsilon 0.13087534155035607 total_time 726.0 step_num 107\n",
      "episode 2906, reward 326.0, memory_length 2000, epsilon 0.13078376086824914 total_time 725.0 step_num 119\n",
      "episode 2907, reward 597.0, memory_length 2000, epsilon 0.1306922442701876 total_time 723.0 step_num 118\n",
      "episode 2908, reward 197.0, memory_length 2000, epsilon 0.13060079171132838 total_time 722.0 step_num 111\n",
      "episode 2909, reward 460.0, memory_length 2000, epsilon 0.13050940314685974 total_time 727.0 step_num 111\n",
      "episode 2910, reward 130.0, memory_length 2000, epsilon 0.13041807853200124 total_time 721.0 step_num 114\n",
      "episode 2911, reward 460.0, memory_length 2000, epsilon 0.13032681782200375 total_time 727.0 step_num 111\n",
      "episode 2912, reward 292.0, memory_length 2000, epsilon 0.13023562097214975 total_time 721.0 step_num 114\n",
      "episode 2913, reward 222.0, memory_length 2000, epsilon 0.13014448793775252 total_time 726.0 step_num 110\n",
      "episode 2914, reward 637.0, memory_length 2000, epsilon 0.13005341867415698 total_time 724.0 step_num 121\n",
      "episode 2915, reward 319.0, memory_length 2000, epsilon 0.12996241313673929 total_time 721.0 step_num 113\n",
      "episode 2916, reward 422.0, memory_length 2000, epsilon 0.12987147128090654 total_time 722.0 step_num 120\n",
      "episode 2917, reward 173.0, memory_length 2000, epsilon 0.12978059306209733 total_time 725.0 step_num 130\n",
      "episode 2918, reward 587.0, memory_length 2000, epsilon 0.1296897784357813 total_time 725.0 step_num 117\n",
      "episode 2919, reward 266.0, memory_length 2000, epsilon 0.1295990273574594 total_time 728.0 step_num 119\n",
      "episode 2920, reward 127.0, memory_length 2000, epsilon 0.1295083397826634 total_time 727.0 step_num 116\n",
      "episode 2921, reward 189.0, memory_length 2000, epsilon 0.1294177156669565 total_time 729.0 step_num 105\n",
      "episode 2922, reward 638.0, memory_length 2000, epsilon 0.12932715496593292 total_time 722.0 step_num 116\n",
      "episode 2923, reward 376.0, memory_length 2000, epsilon 0.1292366576352178 total_time 724.0 step_num 119\n",
      "episode 2924, reward 156.0, memory_length 2000, epsilon 0.12914622363046752 total_time 723.0 step_num 112\n",
      "episode 2925, reward 224.0, memory_length 2000, epsilon 0.12905585290736946 total_time 722.0 step_num 111\n",
      "episode 2926, reward 409.0, memory_length 2000, epsilon 0.12896554542164185 total_time 721.0 step_num 109\n",
      "episode 2927, reward 346.0, memory_length 2000, epsilon 0.12887530112903406 total_time 721.0 step_num 109\n",
      "episode 2928, reward 85.0, memory_length 2000, epsilon 0.12878511998532646 total_time 721.0 step_num 119\n",
      "episode 2929, reward 94.0, memory_length 2000, epsilon 0.12869500194633018 total_time 730.0 step_num 102\n",
      "episode 2930, reward 130.0, memory_length 2000, epsilon 0.12860494696788743 total_time 721.0 step_num 115\n",
      "episode 2931, reward -59.0, memory_length 2000, epsilon 0.12851495500587135 total_time 721.0 step_num 113\n",
      "episode 2932, reward 641.0, memory_length 2000, epsilon 0.1284250260161857 total_time 725.0 step_num 113\n",
      "episode 2933, reward 454.0, memory_length 2000, epsilon 0.12833515995476535 total_time 730.0 step_num 119\n",
      "episode 2934, reward 391.0, memory_length 2000, epsilon 0.12824535677757604 total_time 721.0 step_num 114\n",
      "episode 2935, reward 496.0, memory_length 2000, epsilon 0.12815561644061407 total_time 727.0 step_num 116\n",
      "episode 2936, reward 371.0, memory_length 2000, epsilon 0.1280659388999067 total_time 734.0 step_num 112\n",
      "episode 2937, reward 8.0, memory_length 2000, epsilon 0.12797632411151202 total_time 722.0 step_num 105\n",
      "episode 2938, reward 300.0, memory_length 2000, epsilon 0.12788677203151866 total_time 723.0 step_num 99\n",
      "episode 2939, reward 400.0, memory_length 2000, epsilon 0.12779728261604614 total_time 721.0 step_num 118\n",
      "episode 2940, reward 541.0, memory_length 2000, epsilon 0.1277078558212447 total_time 727.0 step_num 111\n",
      "episode 2941, reward 257.0, memory_length 2000, epsilon 0.12761849160329514 total_time 728.0 step_num 118\n",
      "episode 2942, reward 382.0, memory_length 2000, epsilon 0.12752918991840903 total_time 721.0 step_num 121\n",
      "episode 2943, reward -25.0, memory_length 2000, epsilon 0.12743995072282854 total_time 725.0 step_num 115\n",
      "episode 2944, reward 651.0, memory_length 2000, epsilon 0.12735077397282643 total_time 723.0 step_num 114\n",
      "episode 2945, reward 467.0, memory_length 2000, epsilon 0.12726165962470612 total_time 722.0 step_num 120\n",
      "episode 2946, reward 345.0, memory_length 2000, epsilon 0.12717260763480162 total_time 723.0 step_num 121\n",
      "episode 2947, reward 530.0, memory_length 2000, epsilon 0.12708361795947734 total_time 722.0 step_num 119\n",
      "episode 2948, reward 391.0, memory_length 2000, epsilon 0.1269946905551284 total_time 721.0 step_num 115\n",
      "episode 2949, reward 229.0, memory_length 2000, epsilon 0.12690582537818043 total_time 721.0 step_num 114\n",
      "episode 2950, reward 716.0, memory_length 2000, epsilon 0.12681702238508943 total_time 728.0 step_num 112\n",
      "episode 2951, reward 111.0, memory_length 2000, epsilon 0.1267282815323419 total_time 723.0 step_num 111\n",
      "episode 2952, reward 32.0, memory_length 2000, epsilon 0.1266396027764549 total_time 728.0 step_num 111\n",
      "episode 2953, reward 319.0, memory_length 2000, epsilon 0.12655098607397575 total_time 721.0 step_num 110\n",
      "episode 2954, reward 38.0, memory_length 2000, epsilon 0.1264624313814823 total_time 725.0 step_num 111\n",
      "episode 2955, reward 440.0, memory_length 2000, epsilon 0.1263739386555828 total_time 722.0 step_num 119\n",
      "episode 2956, reward 254.0, memory_length 2000, epsilon 0.12628550785291573 total_time 725.0 step_num 113\n",
      "episode 2957, reward 410.0, memory_length 2000, epsilon 0.12619713893015005 total_time 728.0 step_num 109\n",
      "episode 2958, reward 110.0, memory_length 2000, epsilon 0.12610883184398503 total_time 725.0 step_num 115\n",
      "episode 2959, reward 121.0, memory_length 2000, epsilon 0.12602058655115003 total_time 721.0 step_num 118\n",
      "episode 2960, reward 337.0, memory_length 2000, epsilon 0.125932403008405 total_time 721.0 step_num 108\n",
      "episode 2961, reward 268.0, memory_length 2000, epsilon 0.12584428117254 total_time 724.0 step_num 109\n",
      "episode 2962, reward 159.0, memory_length 2000, epsilon 0.12575622100037528 total_time 726.0 step_num 114\n",
      "episode 2963, reward 563.0, memory_length 2000, epsilon 0.12566822244876133 total_time 728.0 step_num 107\n",
      "episode 2964, reward 209.0, memory_length 2000, epsilon 0.12558028547457892 total_time 725.0 step_num 122\n",
      "episode 2965, reward 545.0, memory_length 2000, epsilon 0.12549241003473893 total_time 728.0 step_num 104\n",
      "episode 2966, reward 555.0, memory_length 2000, epsilon 0.12540459608618235 total_time 726.0 step_num 109\n",
      "episode 2967, reward 444.0, memory_length 2000, epsilon 0.1253168435858803 total_time 723.0 step_num 112\n",
      "episode 2968, reward 721.0, memory_length 2000, epsilon 0.12522915249083424 total_time 727.0 step_num 119\n",
      "episode 2969, reward 394.0, memory_length 2000, epsilon 0.1251415227580753 total_time 724.0 step_num 106\n",
      "episode 2970, reward 85.0, memory_length 2000, epsilon 0.125053954344665 total_time 721.0 step_num 118\n",
      "episode 2971, reward 332.0, memory_length 2000, epsilon 0.12496644720769495 total_time 722.0 step_num 120\n",
      "episode 2972, reward 400.0, memory_length 2000, epsilon 0.12487900130428645 total_time 721.0 step_num 111\n",
      "episode 2973, reward 355.0, memory_length 2000, epsilon 0.12479161659159108 total_time 721.0 step_num 115\n",
      "episode 2974, reward 67.0, memory_length 2000, epsilon 0.1247042930267904 total_time 721.0 step_num 98\n",
      "episode 2975, reward 354.0, memory_length 2000, epsilon 0.12461703056709574 total_time 723.0 step_num 121\n",
      "episode 2976, reward 142.0, memory_length 2000, epsilon 0.12452982916974854 total_time 724.0 step_num 122\n",
      "episode 2977, reward 111.0, memory_length 2000, epsilon 0.1244426887920202 total_time 723.0 step_num 115\n",
      "episode 2978, reward 95.0, memory_length 2000, epsilon 0.12435560939121178 total_time 728.0 step_num 115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 2979, reward 310.0, memory_length 2000, epsilon 0.12426859092465448 total_time 721.0 step_num 116\n",
      "episode 2980, reward 355.0, memory_length 2000, epsilon 0.12418163334970925 total_time 721.0 step_num 102\n",
      "episode 2981, reward 105.0, memory_length 2000, epsilon 0.1240947366237668 total_time 735.0 step_num 112\n",
      "episode 2982, reward -111.0, memory_length 2000, epsilon 0.12400790070424778 total_time 726.0 step_num 122\n",
      "episode 2983, reward 617.0, memory_length 2000, epsilon 0.12392112554860264 total_time 728.0 step_num 104\n",
      "episode 2984, reward 350.0, memory_length 2000, epsilon 0.12383441111431144 total_time 722.0 step_num 119\n",
      "episode 2985, reward 258.0, memory_length 2000, epsilon 0.12374775735888416 total_time 726.0 step_num 109\n",
      "episode 2986, reward 136.0, memory_length 2000, epsilon 0.12366116423986051 total_time 727.0 step_num 115\n",
      "episode 2987, reward 40.0, memory_length 2000, epsilon 0.12357463171480979 total_time 721.0 step_num 107\n",
      "episode 2988, reward 184.0, memory_length 2000, epsilon 0.12348815974133105 total_time 721.0 step_num 116\n",
      "episode 2989, reward 578.0, memory_length 2000, epsilon 0.12340174827705312 total_time 734.0 step_num 114\n",
      "episode 2990, reward 415.0, memory_length 2000, epsilon 0.12331539727963425 total_time 727.0 step_num 114\n",
      "episode 2991, reward 392.0, memory_length 2000, epsilon 0.12322910670676254 total_time 728.0 step_num 111\n",
      "episode 2992, reward 453.0, memory_length 2000, epsilon 0.12314287651615562 total_time 723.0 step_num 112\n",
      "episode 2993, reward 408.0, memory_length 2000, epsilon 0.12305670666556061 total_time 723.0 step_num 119\n",
      "episode 2994, reward -15.0, memory_length 2000, epsilon 0.1229705971127543 total_time 723.0 step_num 119\n",
      "episode 2995, reward 526.0, memory_length 2000, epsilon 0.12288454781554313 total_time 730.0 step_num 109\n",
      "episode 2996, reward 79.0, memory_length 2000, epsilon 0.12279855873176276 total_time 724.0 step_num 111\n",
      "episode 2997, reward 236.0, memory_length 2000, epsilon 0.12271262981927865 total_time 725.0 step_num 119\n",
      "episode 2998, reward 193.0, memory_length 2000, epsilon 0.12262676103598565 total_time 721.0 step_num 126\n",
      "episode 2999, reward 121.0, memory_length 2000, epsilon 0.12254095233980797 total_time 721.0 step_num 110\n",
      "2923.165934085846\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "score_tracked = []\n",
    "num_hits = 0\n",
    "num_track = 0\n",
    "num_train = 0\n",
    "num_track_train = 0\n",
    "for episode in range(n_episodes):\n",
    "\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    # reset at the start of each episode\n",
    "    env = CabDriver()\n",
    "    action_space, state_space, state = env.reset()\n",
    "    state_size = m+t+d\n",
    "    action_size = len(action_space)\n",
    "    #agent = DQNAgent(state_size, action_size)\n",
    "    #print(state)\n",
    "    #print(state_space)\n",
    "    total_time = 0\n",
    "    step_num = 0\n",
    "    while not done:\n",
    "        step_num = step_num + 1\n",
    "        #print(step_num)\n",
    "        # get action for the current state and take a step in the environment\n",
    "        action_index, action = agent.get_action(state)\n",
    "        if ((state_space.index(state) == 0) and (action_index == 2)):\n",
    "            num_hits = num_hits + 1\n",
    "        #print(state, action)\n",
    "        reward, next_state, step_time = env.step(state, action, Time_matrix)\n",
    "        #print(state, next_state, reward)\n",
    "        total_time += step_time\n",
    "        if (total_time > episode_time):\n",
    "            done = True\n",
    "            #reward = 0\n",
    "        # save the sample <s, a, r, s', done> to the replay memory\n",
    "        agent.append_sample(state, action_index, reward, next_state, done)\n",
    "\n",
    "        # train after each step\n",
    "        agent.train_model()\n",
    "\n",
    "        # add reward to the total score of this episode\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "\n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "\n",
    "    # epsilon decay\n",
    "    agent.epsilon = (1 - 0.00001) * np.exp(agent.epsilon_decay * episode)\n",
    "    #agent.epsilon = agent.epsilon * 0.999 # for 2k\n",
    "    #(1 - 0.0001) * np.exp(-0.003*i)\n",
    "    #if agent.epsilon > agent.epsilon_min:\n",
    "    #    agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "    # every episode:\n",
    "    if (episode % 1 == 0):\n",
    "        print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3} total_time {4} step_num {5}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon, total_time, step_num))\n",
    "        agent.save_tracking_states()\n",
    "        score_tracked.append(score) \n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "#save_obj(States_track,'States_tracked')   \n",
    "print(elapsed_time)\n",
    "    # every few episodes:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "\n",
    "        # save model weights\n",
    "        #agent.save_model_weights(name=\"model_weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363348 3000 3226 101\n"
     ]
    }
   ],
   "source": [
    "#print(agent.num_train, agent.num_track, agent.num_train_track, num_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157256 206124\n"
     ]
    }
   ],
   "source": [
    "#print(agent.explore, agent.exploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[0][4][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[4][2][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[2][0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[0][2][4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[2][1][6][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[1][0][16][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[0][3][20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[3][2][20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[2][3][23][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.state_get_loc(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99149.46,\n",
       " 1581659.8,\n",
       " 3216233.8,\n",
       " 9315618.0,\n",
       " 5167148.0,\n",
       " 3311686.8,\n",
       " 2124847.5,\n",
       " 1616586.6,\n",
       " 1202202.5,\n",
       " 968029.8,\n",
       " 789514.25,\n",
       " 688619.7,\n",
       " 599574.3,\n",
       " 533746.56,\n",
       " 483160.6,\n",
       " 436283.9,\n",
       " 392371.2,\n",
       " 358120.4,\n",
       " 329846.84,\n",
       " 306272.2,\n",
       " 282099.7,\n",
       " 267863.4,\n",
       " 250904.72,\n",
       " 235365.6,\n",
       " 219905.94,\n",
       " 208356.22,\n",
       " 194240.53,\n",
       " 180475.56,\n",
       " 171918.66,\n",
       " 163763.52,\n",
       " 152170.95,\n",
       " 140949.23,\n",
       " 130902.88,\n",
       " 118461.34,\n",
       " 108831.055,\n",
       " 99094.53,\n",
       " 90200.82,\n",
       " 81096.414,\n",
       " 70639.74,\n",
       " 62178.484,\n",
       " 53857.707,\n",
       " 46035.098,\n",
       " 38658.98,\n",
       " 30366.822,\n",
       " 25183.135,\n",
       " 31572.105,\n",
       " 23245.83,\n",
       " 16571.29,\n",
       " 12210.69,\n",
       " 9075.968,\n",
       " 6662.5522,\n",
       " 4932.812,\n",
       " 3525.9058,\n",
       " 2843.1038,\n",
       " 2258.1401,\n",
       " 1882.0881,\n",
       " 1497.0312,\n",
       " 1233.4332,\n",
       " 1010.155,\n",
       " 822.8226,\n",
       " 677.025,\n",
       " 534.1947,\n",
       " 421.83884,\n",
       " 362.95117,\n",
       " 314.8531,\n",
       " 267.3944,\n",
       " 244.5459,\n",
       " 225.01059,\n",
       " 209.6759,\n",
       " 196.69893,\n",
       " 196.05911,\n",
       " 201.43996,\n",
       " 216.00261,\n",
       " 237.74619,\n",
       " 256.6898,\n",
       " 281.848,\n",
       " 305.02014,\n",
       " 342.98386,\n",
       " 362.47403,\n",
       " 397.03864,\n",
       " 437.39478,\n",
       " 446.36066,\n",
       " 409.97446,\n",
       " 425.8562,\n",
       " 453.74207,\n",
       " 507.51352,\n",
       " 571.2832,\n",
       " 607.12537,\n",
       " 534.6895,\n",
       " 458.6414,\n",
       " 450.3768,\n",
       " 488.00037,\n",
       " 363.387,\n",
       " 301.7866,\n",
       " 308.89465,\n",
       " 352.4785,\n",
       " 365.57925,\n",
       " 287.24207,\n",
       " 211.34926,\n",
       " 219.27681,\n",
       " 170.06348,\n",
       " 205.87015,\n",
       " 169.62695,\n",
       " 149.35187,\n",
       " 151.05945,\n",
       " 141.32735,\n",
       " 127.670784,\n",
       " 114.62888,\n",
       " 116.94877,\n",
       " 103.8726,\n",
       " 117.57372,\n",
       " 131.15848,\n",
       " 122.82061,\n",
       " 127.64321,\n",
       " 137.943,\n",
       " 154.07578,\n",
       " 149.87996,\n",
       " 141.3878,\n",
       " 142.60771,\n",
       " 138.10988,\n",
       " 129.95456,\n",
       " 132.74728,\n",
       " 117.483894,\n",
       " 124.94234,\n",
       " 136.945,\n",
       " 127.26583,\n",
       " 120.801544,\n",
       " 128.91873,\n",
       " 120.028824,\n",
       " 144.97397,\n",
       " 143.13501,\n",
       " 134.67558,\n",
       " 128.00455,\n",
       " 157.83278,\n",
       " 125.285034,\n",
       " 170.00981,\n",
       " 147.1869,\n",
       " 144.00626,\n",
       " 132.95428,\n",
       " 213.37717,\n",
       " 226.01877,\n",
       " 123.48333,\n",
       " 113.82279,\n",
       " 145.52396,\n",
       " 128.29332,\n",
       " 173.46716,\n",
       " 131.62108,\n",
       " 149.69934,\n",
       " 134.91405,\n",
       " 100.413826,\n",
       " 120.57932,\n",
       " 160.13045,\n",
       " 146.76802,\n",
       " 132.2941,\n",
       " 133.34766,\n",
       " 84.876854,\n",
       " 156.3368,\n",
       " 170.06723,\n",
       " 133.21126,\n",
       " 132.6946,\n",
       " 140.44902,\n",
       " 222.49069,\n",
       " 110.13372,\n",
       " 261.74728,\n",
       " 97.8073,\n",
       " 99.554985,\n",
       " 242.01314,\n",
       " 166.44006,\n",
       " 159.33138,\n",
       " 195.40057,\n",
       " 163.3516,\n",
       " 131.9154,\n",
       " 197.51797,\n",
       " 133.18211,\n",
       " 191.17749,\n",
       " 421.4515,\n",
       " 154.14308,\n",
       " 207.95003,\n",
       " 251.85368,\n",
       " 262.57306,\n",
       " 242.28949,\n",
       " 87.00015,\n",
       " 142.97263,\n",
       " 187.49335,\n",
       " 268.08835,\n",
       " 110.22048,\n",
       " 123.53558,\n",
       " 123.19208,\n",
       " 62.17394,\n",
       " 160.6679,\n",
       " 100.98169,\n",
       " 254.43437,\n",
       " 154.82314,\n",
       " 147.425,\n",
       " 70.464325,\n",
       " 156.39485,\n",
       " 103.158745,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.states_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13f2fda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "#plt.subplot(221)\n",
    "plt.title('state [2,4,6]  action index 2')\n",
    "xaxis = np.asarray(range(0, len(agent.states_tracked)))\n",
    "plt.plot(xaxis,np.asarray(agent.states_tracked))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tracked_sample = [score_tracked[i] for i in range(len(score_tracked)) if (i % 4 == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14c74588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0, figsize=(16,7))\n",
    "#plt.subplot(221)\n",
    "plt.title('state [2,4,6]  action index 2')\n",
    "xaxis = np.asarray(range(0, len(score_tracked_sample)))\n",
    "plt.plot(xaxis,np.asarray(score_tracked_sample))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x539ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,3000)\n",
    "epsilon = []\n",
    "for i in range(0,3000):\n",
    "    epsilon.append(0 + (1 - 0.00001) * np.exp(-0.0007*i))\n",
    "    z = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,3000)\n",
    "epsilon = []\n",
    "epsilon_c = 1\n",
    "for i in range(0,3000):\n",
    "    epsilon.append(epsilon_c)\n",
    "    epsilon_c = epsilon_c * 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl8VOW9x/HPLzuELGSBLAQIO1H2gCyu1SpYBW1dcCtaK3qt9Xpr9+1a7+21trUuFWvVYq2tC9ZWqUpRrCsiEGTfw5qQQBJCAgRISPLcP2awEQMZIMmZmXzfr1demTnzZPJ7POOXJ885zznmnENERMJLhNcFiIhI61O4i4iEIYW7iEgYUriLiIQhhbuISBhSuIuIhCGFu4hIGFK4i4iEIYW7iEgYivLqF6elpbnevXt79etFRELSkiVLKpxz6S218yzce/fuTUFBgVe/XkQkJJnZtkDaaVpGRCQMKdxFRMKQwl1EJAwp3EVEwpDCXUQkDLUY7mY208zKzGzVMV43M3vEzArNbIWZjWz9MkVE5EQEMnL/IzDxOK9PAvr7v6YDvzv1skRE5FS0GO7OufeByuM0mQL8yfl8DCSbWWZrFXi0VTuquf+f69DtAUVEjq015tyzgaImz4v92z7HzKabWYGZFZSXl5/UL/tk+x5+9+4mFmzafVI/LyLSEbRGuFsz25odVjvnnnDO5Tvn8tPTW1w926yr8nPISIzjoXkbNXoXETmG1gj3YiCnyfMeQEkrvG+z4qIjuf28vizaWqnRu4jIMbRGuM8Gvuo/a2YsUO2cK22F9z0mjd5FRI4vkFMhnwcWAAPNrNjMbjaz28zsNn+TN4DNQCHwJHB7m1Xrp9G7iMjxtXhVSOfcNS287oBvtFpFAboqP4fH3tnEQ/M2Mq5vKmbNTf2LiHRMIbtCVaN3EZFjC9lwB829i4gcS0iHu0bvIiLNC+lwB43eRUSaE/Lh3nT0/sHGCq/LEREJCiEf7gBXj84hO7kTv35zvUbvIiKESbjHRkVy1wX9WVFczdzVO70uR0TEc2ER7gCXj8imb3o8v35zAw2NGr2LSMcWNuEeFRnBty8cSGHZfv6+dIfX5YiIeCpswh1g4ukZDMlO4sG3NlBb3+B1OSIingmrcDczvnPRQHZUHeSFRUUt/4CISJgKq3AHOKt/GmfkpvDbfxVyoK7e63JERDwRduFuZnx34kAq9tfy9PytXpcjIuKJsAt3gFG9Ujh/UDd+/94mqg7UeV2OiEi7C8twB/jOxIHsq61nxjuFXpciItLuwjbcB2UkcsXIHjzz0TaKKg94XY6ISLsK23AHuPvCgUREwC/nrve6FBGRdhXW4Z6RFMctZ/XhH8tLWFZU5XU5IiLtJqzDHeDWc/qS1iWG/3t9rS4qJiIdRtiHe5fYKO66YACLtlby1ppdXpcjItIuwj7cAaaOzqFvejy/mLOOww2NXpcjItLmOkS4R0VG8INJg9lcUcMLi7Z7XY6ISJvrEOEOcP7gbpyRm8JD8zay79Bhr8sREWlTHSbczYwffWkwu2vqePRfWtgkIuGtw4Q7wNAeyVw5qgcz529hS0WN1+WIiLSZDhXu4LssQWxUJP/72hqvSxERaTMdLty7JcTxzS/04+11Zby7vszrckRE2kSHC3eAmybkkpsWz72vraGuXqdGikj46ZDhHhMVwU8uGczm8hr+tGCr1+WIiLS6DhnuAOcN7MY5A9J5eN5GyvfVel2OiEir6rDhbmb85JI8Dh5u4IE3ddVIEQkvHTbcAfp168KN43vzYkERK4urvS5HRKTVBBTuZjbRzNabWaGZfb+Z13ua2TtmttTMVpjZxa1fatu484L+pMbH8ONXV9HQqKtGikh4aDHczSwSmAFMAvKAa8ws76hmPwZmOedGAFOBx1q70LaSGBfNj740mOVFVbywWNedEZHwEMjIfQxQ6Jzb7JyrA14AphzVxgGJ/sdJQEnrldj2Lhuezdg+Kdw/Zx0V+3VwVURCXyDhng0UNXle7N/W1D3A9WZWDLwBfLNVqmsnZsb/XnY6Bw83cN8b67wuR0TklAUS7tbMtqMnp68B/uic6wFcDDxrZp97bzObbmYFZlZQXl5+4tW2oX7dErjlrD68/EkxCzfv9rocEZFTEki4FwM5TZ734PPTLjcDswCccwuAOCDt6Ddyzj3hnMt3zuWnp6efXMVt6Jtf6E92cid+/MoqrVwVkZAWSLgvBvqbWa6ZxeA7YDr7qDbbgfMBzGwwvnAPrqF5ADrFRPKzyaexsWw/M+dv8bocEZGT1mK4O+fqgTuAucBafGfFrDaze81ssr/Z3cAtZrYceB640YXo3agvyOvOF/O68/C8jRTvOeB1OSIiJ8W8yuD8/HxXUFDgye9uyY6qg1zwwHuM75vKU9PyMWvusIOISPszsyXOufyW2nXoFarHkp3cibsvHMDb68p4bUWp1+WIiJwwhfsx3Di+N0N7JHHP7NXsqanzuhwRkROicD+GqMgI7v/KUKoPHuZ/X1/rdTkiIidE4X4cgzMTue2cvrz8STHvbwi5k39EpANTuLfgji/0o096PD/8+0pqauu9LkdEJCAK9xbERUfyiy8PpXjPQR54c4PX5YiIBEThHoAxuSlcP7YnT3+0haXb93hdjohIixTuAfrexEF0T4jjey+voLa+wetyRESOS+EeoIS4aO778hA27NrPg29t9LocEZHjUrifgPMGdePq/ByeeH8TS7ZpekZEgpfC/QT9+JLBZCZ14tsvLedgnaZnRCQ4KdxPUEJcNL+6YihbKmr45Vzd2ENEgpPC/SSM75fGtHG9eHr+VhZs0o09RCT4KNxP0vcmDaJ3ame+89fl7NfiJhEJMgr3k9Q5JopfXzmMHVUH+b83dO0ZEQkuCvdTkN87heln9eG5hdt5e+0ur8sREfmUwv0UfevCAQzOTOS7f11B2b5DXpcjIgIo3E9ZbFQkj0wdzv7aer7z0goaG0Py7oIiEmYU7q2gf/cEfvylwby3oZw/frTV63JERBTureX6sb24YHA3fjFnHWtL93pdjoh0cAr3VmJm3P+VoSR2iuY/X1jKocNavSoi3lG4t6LULrE8cNUwNuzaz306PVJEPKRwb2XnDEjnaxNyeWbBNp0eKSKeUbi3ge9OHEheZiJ3v7ScHVUHvS5HRDoghXsbiIuO5LHrRlLf4LjjuU+oq2/0uiQR6WAU7m2kd1o8v/jKEJZur+JXunqkiLQzhXsbumRoFjeM7cWTH2zhrTWafxeR9qNwb2M/vmQwp2cncvesZRRVHvC6HBHpIBTubSw2KpIZ147EObjj+aWafxeRdqFwbwe9UuP55RVDWV5UxX1zdP67iLQ9hXs7mTQkk5sm9Obp+Vt5ddkOr8sRkTCncG9HP7x4MGNyU/jeyytYXVLtdTkiEsYU7u0oOjKCGdeOJLlTDLf9eQlVB+q8LklEwlRA4W5mE81svZkVmtn3j9HmKjNbY2arzey51i0zfKQnxPK760eyq7qWbz6/lAZd/11E2kCL4W5mkcAMYBKQB1xjZnlHtekP/ACY4Jw7DbirDWoNGyN6duVnU07jg40VPPDmeq/LEZEwFMjIfQxQ6Jzb7JyrA14AphzV5hZghnNuD4Bzrqx1yww/14zpyTVjcnjs3U38c1Wp1+WISJgJJNyzgaImz4v925oaAAwws/lm9rGZTWzujcxsupkVmFlBeXn5yVUcRu6ZfBrDc5K5e9Zy1u3UDT5EpPUEEu7WzLajJ4qjgP7AucA1wFNmlvy5H3LuCedcvnMuPz09/URrDTuxUZE8fv0o4mOjuPmPBVTsr/W6JBEJE4GEezGQ0+R5D6CkmTavOucOO+e2AOvxhb20ICMpjie/mk/F/lpufXYJtfW6g5OInLpAwn0x0N/Mcs0sBpgKzD6qzSvAeQBmloZvmmZzaxYazoblJPPAVcNYsm0PP/jbSpzTGTQicmpaDHfnXD1wBzAXWAvMcs6tNrN7zWyyv9lcYLeZrQHeAb7jnNvdVkWHo0uGZvFfFwzgb5/s4PH39O+iiJwa82qUmJ+f7woKCjz53cHKOcedLyzjtRUlPH79KC46LcPrkkQkyJjZEudcfkvttEI1iJgZv7piKEN7JHPXC8tYtUOXKBCRk6NwDzJx0ZE8ecMounaO5uZnFuserCJyUhTuQahbYhxP3zSGA3UN3DhzEdUHDntdkoiEGIV7kBqYkcDvbxjF1t01TH+2QKdIisgJUbgHsfF90/j1lcNYuKWSb7+0gkZdZExEAhTldQFyfFOGZ7Oz+hD3zVlHZlIcP7x4sNcliUgIULiHgOln96Gk6iBPvL+ZzKQ4bpqQ63VJIhLkFO4hwMz46aWnUVp9iHtfW0Nql1gmD8vyuiwRCWKacw8RkRHGI9eMYEzvFL714jLeWaerKovIsSncQ0hcdCRPTctnUGYCt/15CYu2VHpdkogEKYV7iEmIi+aZm8bQo2snbv7jYq1iFZFmKdxDUGqXWJ69+QwSO0UzbeYiNpXv97okEQkyCvcQlZXciT9//QzM4IanFuoyBSLyGQr3EJabFs+fvnYG+2rrufbJj9lZfcjrkkQkSCjcQ1xeViLPfG0Mu/fXcc2TH1O2VwEvIgr3sDCyZ1ee+dpoyvYe8gX8PgW8SEencA8To3ql8PRNYyitPsR1Ty7UzbZFOjiFexgZk5vCzBtHU7TnANc9uZDdCniRDkvhHmbG9kll5rTRbN1dw3VPLaSyps7rkkTEAwr3MDS+Xxp/mDaaLRU1TH1igQ6yinRACvcwdWb/NJ6+aTTFew5y9RMfU6Lz4EU6FIV7GBvfN41nbx5Dxb5arnx8Adt213hdkoi0E4V7mBvVK4XnbhlLTV09V/1+AYVlulSBSEegcO8AhvRI4sXp42hohKt/v4A1JXu9LklE2pjCvYMYmJHArFvHEhMVwdQnFlCwVZcLFglnCvcOpE96F2bdOo7ULrFc99RC5q3Z5XVJItJGFO4dTE5KZ/562zgGZiRw65+XMGtxkdcliUgbULh3QKldYnn+lrGM75vKd19ewYx3CnHOeV2WiLQihXsHFR8bxR+mjWbK8Cx+NXc9P/vHGhobFfAi4SLK6wLEOzFRETx41XBS42OZOX8L5ftreeDKYcRFR3pdmoicIoV7BxcRYfzkksF0T4zlvjnrKK06yJNfzSe1S6zXpYnIKdC0jGBm3HpOXx67biSrS/Zy2WPzKSzb53VZInIKAgp3M5toZuvNrNDMvn+cdleYmTOz/NYrUdrLxUMyeWH6WA7WNXD5Yx/xUWGF1yWJyElqMdzNLBKYAUwC8oBrzCyvmXYJwJ3AwtYuUtrPiJ5d+fvtE8hIjOOrMxfpVEmREBXIyH0MUOic2+ycqwNeAKY00+5/gF8Cur5siMtJ6czLt49nnP9UyfvmrKVBZ9KIhJRAwj0baDp8K/Zv+5SZjQBynHOvtWJt4qHEuGhm3jia687oye/f28zNzyym+uBhr8sSkQAFEu7WzLZPh3FmFgE8CNzd4huZTTezAjMrKC8vD7xK8UR0ZAQ/v3wIP7/8dOYXVnDZjPls3KUDrSKhIJBwLwZymjzvAZQ0eZ4AnA68a2ZbgbHA7OYOqjrnnnDO5Tvn8tPT00++amlX153Ri+duGcu+Q/Vc/thHvLl6p9cliUgLAgn3xUB/M8s1sxhgKjD7yIvOuWrnXJpzrrdzrjfwMTDZOVfQJhWLJ0b3TuEf35xAn/R4pj+7hIfmbdCKVpEg1mK4O+fqgTuAucBaYJZzbrWZ3Wtmk9u6QAkemUmdmHXrOL48IpuH5m1k+rNLqD6geXiRYGReXTAqPz/fFRRocB+KnHP88aOt/Pz1tWQmx/HYtaMY0iPJ67JEOgQzW+Kca3EtkVaoygkzM26akMus28bR0OD4yu8+4tkFW3VlSZEgonCXkzayZ1dev/MsxvdL5SevrubOF5axv7be67JEBIW7nKKu8THMnDaa71w0kNdXlDD50Q9Zt1P3aBXxmsJdTllEhPGN8/rxl6/7Tpec8uh8/rRA0zQiXlK4S6sZ1zeVN+48i3F9U/npq6v5+jMF7N5f63VZIh2Swl1aVXpCLE/fOJr/vjSPDworuOihD3hvg1Yji7Q3hbu0uiNn08y+YwIp8dFMm7mI/3ltDbX1DV6XJtJhKNylzQzKSGT2HWcybVwv/vDhFqY8Op81JTrYKtIeFO7SpuKiI/nZlNOZeWM+FfvrmPzohzzy9kYONzR6XZpIWFO4S7v4wqDuvPVfZ/OloZn85q0NfPmxj1i/U1eYFGkrCndpN13jY3h46gh+d91ISqoOculvP+Sxdwup1yhepNUp3KXdTRqSyZv/dTYX5HXjl/9cz1ceX8AGXSdepFUp3MUTqV1ieey6UTx67Qi2767hS498wANvrufQYZ1RI9IaFO7iqUuGZvH23edy6bAsfvuvQiY9/AEfbarwuiyRkKdwF8+lxMfwm6uG8+ebz6DROa59ciHffmk5e2rqvC5NJGQp3CVonNk/jbl3nc3t5/bllaU7OP837/HykmJdo0bkJCjcJajERUfy3YmDeO3OM+mV2pm7X1rOlY8vYHVJtdeliYQUhbsEpUEZibx823ju/8oQNlfUcOlvP+THr6yk6oCmakQCoXCXoBURYVw9uifv3H0uXx3Xm+cWbue8X7/LXxZuo0E35xY5LoW7BL2kztHcM/k0Xr/zLPp3T+BHf1/FlBkfsnhrpdeliQQthbuEjMGZibw4fSyPXDOCin11XPn4Am59toDN5fu9Lk0k6CjcJaSYGZOHZfGvb5/D3V8cwIcbK7jwwff571dX6cYgIk2YV6eZ5efnu4KCAk9+t4SP8n21PDRvA88v2k58TBS3n9ePmyb0Ji460uvSRNqEmS1xzuW31E4jdwlp6Qmx/PzyIcy962zG5KZw/z/Xcf4D7zGroEgXJJMOTeEuYaF/9wT+cONonrvlDFK7xPDdv67gwgffZ/byEhp1Zo10QAp3CSvj+6bx6jcm8PsbRhEdGcGdzy9l0sMfMHf1Tq10lQ5F4S5hx8y46LQM5vznWTw8dTh1DY3c+uwSpsyYz3sbyhXy0iHogKqEvfqGRv62dAcPz9vIjqqDDM9J5o7z+nH+4G6YmdfliZyQQA+oKtylw6itb+ClgmIef28TxXsOMigjgTu+0I9Jp2cSGaGQl9CgcBc5hsMNjby6rITH3i1kc3kNfdLjuf3cfkwZnkV0pGYqJbgp3EVa0NDo+OeqnTz6TiFrS/fSo2snbjmrD1fm96BzTJTX5Yk0S+EuEiDnHP9aV8aMdwr5ZHsVSZ2iue6Mnkwb35vuiXFelyfyGQp3kZOwZFslT32whbmrdxIZYUwels3Xz8plcGai16WJAIGHe0B/e5rZROBhIBJ4yjn3i6Ne/xbwdaAeKAe+5pzbdsJVi3hsVK8URvVKYdvuGp6ev5VZBUW8/EkxZ/ZL4+azcjmnfzoROvgqIaDFkbuZRQIbgC8CxcBi4Brn3Jombc4DFjrnDpjZfwDnOueuPt77auQuoaD6wGH+smgbz3y0lV17a+md2pnrx/biilE9SO4c43V50gG12rSMmY0D7nHOXeR//gMA59x9x2g/AnjUOTfheO+rcJdQUlffyJxVpfz5420s3rqH2KgIpgzP4oaxvRnSI8nr8qQDac1pmWygqMnzYuCM47S/GZgTwPuKhIyYqAimDM9myvBs1pTs5dmPt/HK0h3MKihmeE4yN4ztxZeGZupqlBI0Ajmpt7kJxmaH+2Z2PZAP/OoYr083swIzKygvLw+8SpEgkpeVyH1fHsLHPzyf/740j72HDnP3S8sZ8/N5/PTVVazaoZt5i/dabVrGzC4Afguc45wra+kXa1pGwoVzjo827ebFxUX8c/VO6uobOS0rkatH5zBlWDZJnaO9LlHCSGvOuUfhO6B6PrAD3wHVa51zq5u0GQH8FZjonNsYSIEKdwlHVQfqeHVZCS8uLmJN6V5ioiKYdHoGV+XnMK5Pqs60kVPWque5m9nFwEP4ToWc6Zz7uZndCxQ452ab2TxgCFDq/5HtzrnJx3tPhbuEu1U7qplVUMQrS3ew91A9WUlxTB6ezWUjshiUofPm5eRoEZNIkDh0uIG5q3fy6rIS3ttQTkOjY1BGApeNyGbysCyykjt5XaKEEIW7SBDavb+W11eW8srSHXyyvQozGNM7hctHZDPp9EzNz0uLFO4iQW7b7hpeXVbCK8t2sLm8hqgIY0K/NC4eksEX8zJIidciKfk8hbtIiHDOsXJHNW+s3MkbK0vZXnmAyAhjXJ9UJg3J4KLTMkjrEut1mRIkFO4iIcg5x+qSvcxZVcobK3eypaKGCIMxuSlMOj2TC/K6k605+g5N4S4S4pxzrN+1jzdW7mTOylI2lu0HYFBGAl/M6875g7szNDtJp1d2MAp3kTCzqXw/b6/dxby1ZRRsraTRQXpCLOcP6sb5g7tzZr80OsXo8gfhTuEuEsb21NTx7oYy5q0t4/315eyrrSc2KoLxfVM5e0A6Zw9Ip09avG4AHoYU7iIdRF19I4u3VvLWml28t6GcLRU1AGQnd+LsAWmc1T+dCX3TdJplmFC4i3RQRZUHeG9DOR9sLOejwt3sq60nwmB4TjJn9U/n7AFpDO2RrJuBhyiFu4hwuKGRZUVVvL+hnPc3VrCiuArnoHNMJPm9UxjbJ4VxfVIZkp1ElMI+JCjcReRz9tTUsWDzbj7evJsFm3Z/egZOfEwko3N9QT+2TyqnZSUq7IOUwl1EWlS+r5aFW3xh//HmSgr9YZ8QG8XIXl3J79WVUb26MrxnMp1jArrlsrQxhbuInLCyfYdYuLmSBZt3s2TrHjaU7cM5iIww8jITGeUP+1G9uuqCZx5RuIvIKas+eJil2/ewZNseCrbuYVlRFQcPNwCQlRTHqN4pDM9JZmiPJE7PStJ59u2gNe+hKiIdVFKnaM4d2I1zB3YDoL6hkbWl+1iyrZKCbXso2FrJP5aXABBhMKB7AkN7JDG0RzLDeiQzMCOBmCjN3XtBI3cROSVlew+xoriaFcVVLC+uZnlxFVUHDgO+G4sPzkxkWI8khmQnkZeVSP9uCvxToWkZEfGEc46iyoOs2FHFiuJqlhdVsWpHNTV1vumc6EijX7cEBmcmkJeZSF5WInmZiSR31iWOA6FpGRHxhJnRM7UzPVM7c8nQLAAaGh1bKmpYW7qXNaV7WVOylw83VvC3T3Z8+nNZSXHkZSUyONP3NaB7F3qlxmux1UlSuItIm4uMMPp160K/bl24dFjWp9vL99WytnTvZ0L/nfW+WxGCb5SfmxZP/+4J9O/WhQHdExT6AVK4i4hn0hNiSU/wXejsiEOHGygs28/Gsn1s2LWfjbv2sWpHNW+sLOXILPLRod83vQu5afHkpsUTH6tYA4W7iASZuOhITs9O4vTspM9sP1jXwKby44c+QPfEWH/Qd6GPP/Bz0+PJ6dq5Qx3IVbiLSEjoFNN86B863MDW3TVsKa9hc0UNW/xfc1fvpLKm7tN2kRFGTtdO5KbF0ys1npyUzvRM6UxOSidyunYOuxF/ePVGRDqcuOhIBmUkMigj8XOvVR2o+zTst1T4wn9zeQ2LtlR+evbOEanxMeSkdPaHvi/we/qfZybFhdy1dhTuIhK2kjvHMKJnDCN6dv3Mduccew4cpqjyANsrD1C05wBFlQcoqjzI8qIq5qwspb7x33M9kRFGZlIcWUmdyEyOIyu5E1lJcWT6n2cndyKpU3RQ3RxF4S4iHY6ZkRIfQ0p8DMNykj/3en1DI6XVhz4N/e2VB9ix5yAl1Yf4ZPse3lhZyuGGz64R6hQd+WnQZ/qDPyvZ9717YhwZiXEkdopqt38AFO4iIkeJioz4dIqGvp9/vbHRUbG/lpLqQ5RUHaSk6iClRx5XH2L9znLK99dy9BrRuOgIMhLj+NaFA5nc5JTQNulDm767iEgYiogwuiXG0S0xjuHNjPzBd/vDXXsPUVp9iF17//21c28tqfFtvxpX4S4i0gZiopqM/j0QWod/RUQkIAp3EZEwpHAXEQlDCncRkTCkcBcRCUMBhbuZTTSz9WZWaGbfb+b1WDN70f/6QjPr3dqFiohI4FoMdzOLBGYAk4A84Bozyzuq2c3AHudcP+BB4P7WLlRERAIXyMh9DFDonNvsnKsDXgCmHNVmCvCM//FfgfMtmC6yICLSwQSyiCkbKGryvBg441htnHP1ZlYNpAIVTRuZ2XRguv/pfjNbfzJFA2lHv3cIU1+CU7j0JVz6AerLEb0CaRRIuDc3Aj/6rtqBtME59wTwRAC/8/gFmRUEcoPYUKC+BKdw6Uu49APUlxMVyLRMMZDT5HkPoORYbcwsCkgCKlujQBEROXGBhPtioL+Z5ZpZDDAVmH1Um9nANP/jK4B/OXf09dBERKS9tDgt459DvwOYC0QCM51zq83sXqDAOTcb+APwrJkV4huxT23LommFqZ0gor4Ep3DpS7j0A9SXE2IaYIuIhB+tUBURCUMhF+4trZYNNma21cxWmtkyMyvwb0sxs7fMbKP/e1f/djOzR/x9W2FmIz2ufaaZlZnZqibbTrh2M5vmb7/RzKY197s86ss9ZrbDv2+WmdnFTV77gb8v683soibbPf38mVmOmb1jZmvNbLWZ/ad/e8jtl+P0JRT3S5yZLTKz5f6+/My/Pde/an+j+Vbxx/i3H3NV/7H6eMKccyHzhW/OfxPQB4gBlgN5XtfVQs1bgbSjtv0S+L7/8feB+/2PLwbm4Du1dCyw0OPazwZGAqtOtnYgBdjs/97V/7hrkPTlHuDbzbTN83+2YoFc/2cuMhg+f0AmMNL/OAHY4K835PbLcfoSivvFgC7+x9HAQv9/71nAVP/2x4H/8D++HXjc/3gq8OLx+ngyNYXayD2Q1bKhoOmK3meAy5ps/5Pz+RhINrNMLwoEcM69z+dPaT3R2i8C3nLOVTrn9gBvARPbvvrPOkZfjmUK8IJzrtY5twUoxPfZ8/zz55wrdc594n+8D1iLbxFhyO2X4/TlWIJ5vzjn3H7/02j/lwO+gG/VPnx+vzS3qv9YfTxhoRbuza2WPd6HIRg44E0zW2K+FboA3Z1zauDaAAACU0lEQVRzpeD7gAPd/NtDoX8nWnuw9+kO/3TFzCNTGYRIX/x/yo/AN0oM6f1yVF8gBPeLmUWa2TKgDN8/lpuAKudcfTN1fWZVP3BkVX+r9SXUwj2glbBBZoJzbiS+C699w8zOPk7bUOzfEceqPZj79Dt897YfDpQCD/i3B31fzKwL8DJwl3Nu7/GaNrMt2PsSkvvFOdfgnBuOb6HnGGBwc83839u8L6EW7oGslg0qzrkS//cy4O/4dvquI9Mt/u9l/uah0L8TrT1o++Sc2+X/H7IReJJ///kb1H0xs2h8YfgX59zf/JtDcr8015dQ3S9HOOeqgHfxzbknm2/V/tF1HWtVf6v1JdTCPZDVskHDzOLNLOHIY+BCYBWfXdE7DXjV/3g28FX/GQ5jgeojf2oHkROtfS5woZl19f95faF/m+eOOp5xOb59A76+TPWf0ZAL9AcWEQSfP/+87B+Atc653zR5KeT2y7H6EqL7Jd3Mkv2POwEX4DuG8A6+Vfvw+f3S3Kr+Y/XxxLXnEeXW+MJ39H8DvvmsH3ldTwu19sF35Hs5sPpIvfjm1t4GNvq/p7h/H3Gf4e/bSiDf4/qfx/dn8WF8I4qbT6Z24Gv4DgwVAjcFUV+e9de6wv8/VWaT9j/y92U9MClYPn/Amfj+TF8BLPN/XRyK++U4fQnF/TIUWOqveRXwU//2PvjCuRB4CYj1b4/zPy/0v96npT6e6JdWqIqIhKFQm5YREZEAKNxFRMKQwl1EJAwp3EVEwpDCXUQkDCncRUTCkMJdRCQMKdxFRMLQ/wOCijjQ2ajclgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5446400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method randrange in module random:\n",
      "\n",
      "randrange(start, stop=None, step=1, _int=<class 'int'>) method of random.Random instance\n",
      "    Choose a random item from range(start, stop[, step]).\n",
      "    \n",
      "    This fixes the problem with randint() which includes the\n",
      "    endpoint; in Python this is usually not what you want.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(random.randrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
